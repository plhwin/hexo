{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"source/sitemap.txt","path":"sitemap.txt","modified":0},{"_id":"source/robots.txt","path":"robots.txt","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","path":"vendors/velocity/velocity.ui.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","path":"vendors/velocity/velocity.ui.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","path":"vendors/velocity/velocity.min.js","modified":0},{"_id":"themes/next/source/vendors/velocity/velocity.js","path":"vendors/velocity/velocity.js","modified":0},{"_id":"themes/next/source/vendors/velocity/bower.json","path":"vendors/velocity/bower.json","modified":0},{"_id":"themes/next/source/vendors/jquery/index.js","path":"vendors/jquery/index.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","path":"vendors/fancybox/source/jquery.fancybox.pack.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","path":"vendors/fancybox/source/jquery.fancybox.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","path":"vendors/fancybox/source/jquery.fancybox.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","path":"vendors/fancybox/source/helpers/fancybox_buttons.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","path":"vendors/fancybox/source/fancybox_sprite@2x.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","path":"vendors/fancybox/source/fancybox_sprite.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","path":"vendors/fancybox/source/fancybox_overlay.png","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","path":"vendors/fancybox/source/fancybox_loading@2x.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","path":"vendors/fancybox/source/fancybox_loading.gif","modified":0},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","path":"vendors/fancybox/source/blank.gif","modified":0},{"_id":"themes/next/source/js/ua-parser.min.js","path":"js/ua-parser.min.js","modified":0},{"_id":"themes/next/source/js/search-toggle.js","path":"js/search-toggle.js","modified":0},{"_id":"themes/next/source/js/motion_global.js","path":"js/motion_global.js","modified":0},{"_id":"themes/next/source/js/motion_fallback.js","path":"js/motion_fallback.js","modified":0},{"_id":"themes/next/source/js/lazyload.js","path":"js/lazyload.js","modified":0},{"_id":"themes/next/source/js/hook-duoshuo.js","path":"js/hook-duoshuo.js","modified":0},{"_id":"themes/next/source/js/helpers.js","path":"js/helpers.js","modified":0},{"_id":"themes/next/source/js/fancy-box.js","path":"js/fancy-box.js","modified":0},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","path":"js/bootstrap.scrollspy.js","modified":0},{"_id":"themes/next/source/images/wechat.jpg","path":"images/wechat.jpg","modified":0},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0},{"_id":"themes/next/source/images/qifuguang.jpg","path":"images/qifuguang.jpg","modified":0},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0},{"_id":"themes/next/source/images/it.jpg","path":"images/it.jpg","modified":0},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","path":"images/bkdefault_avatar.jpg","modified":0},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.woff","path":"fonts/icon-winwill2012/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.ttf","path":"fonts/icon-winwill2012/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.svg","path":"fonts/icon-winwill2012/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.eot","path":"fonts/icon-winwill2012/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","path":"fonts/icon-linecons/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","path":"fonts/icon-linecons/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","path":"fonts/icon-linecons/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","path":"fonts/icon-linecons/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","path":"fonts/icon-icomoon/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","path":"fonts/icon-icomoon/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","path":"fonts/icon-icomoon/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","path":"fonts/icon-icomoon/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","path":"fonts/icon-fifty-shades/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","path":"fonts/icon-fifty-shades/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","path":"fonts/icon-fifty-shades/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","path":"fonts/icon-fifty-shades/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","path":"fonts/icon-feather/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","path":"fonts/icon-feather/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","path":"fonts/icon-feather/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","path":"fonts/icon-feather/icomoon.eot","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","path":"fonts/icon-default/icomoon.woff","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","path":"fonts/icon-default/icomoon.ttf","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","path":"fonts/icon-default/icomoon.svg","modified":0},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","path":"fonts/icon-default/icomoon.eot","modified":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0},{"_id":"themes/next/source/404.html","path":"404.html","modified":0},{"_id":"source/CNAME","path":"CNAME","modified":0}],"Cache":[{"_id":"source/_posts/A记录与CNAME记录介绍.md","shasum":"9ebff6b03f0717f403f6bc621ece5aeeae0e3fe0","modified":1441334544000},{"_id":"source/_posts/IntelliJ远程调试教程.md","shasum":"43af68b0249c25d2397e06b44e9a6932bc082b0a","modified":1444716391000},{"_id":"source/_posts/Redis-3-0新特性.md","shasum":"1a405df093ccc3192f94d270d6c9605dba1ce14c","modified":1443417534000},{"_id":"source/_posts/Redis主从复制.md","shasum":"a573119c15f3b0fb3bf1939b47606e18003b7728","modified":1445146956000},{"_id":"source/_posts/Redis事务介绍.md","shasum":"ad2de74b29d3f76399bab856315f078a5bd4f3bb","modified":1443545115000},{"_id":"source/_posts/Redis五种数据类型介绍.md","shasum":"9d3a10d6f18a0ce85a986cd6efd33715ab2a71b1","modified":1443457334000},{"_id":"source/_posts/Redis持久化.md","shasum":"0068bc52b8e41d3daced9475c678c73c7f148954","modified":1444877695000},{"_id":"source/_posts/Redis过期机制介绍.md","shasum":"f13e0025ad32921b8f677376bb360ecaa1c0213e","modified":1443584423000},{"_id":"source/_posts/Shell特殊字符简介.md","shasum":"b92fd14e0ff153a62798f8d15336d8aae3160abb","modified":1442938529000},{"_id":"source/_posts/Thrift入门教程.md","shasum":"3a4193cf40ece37823fa9aa87d9f7fd94ba3f82b","modified":1444716299000},{"_id":"source/_posts/UTF8编码.md","shasum":"95d95b751d3fc03f10e9f972e5dd66f663b44184","modified":1444716089000},{"_id":"source/_posts/ZooKeeper使用场景.md","shasum":"2d22774c8a4fed5d53f5c96dc8ed28ab27030889","modified":1444452848000},{"_id":"source/_posts/[Docker学习一]Docker简介.md","shasum":"5ecfcf7828ec46801dc55226a74a2698639d1087","modified":1440143415000},{"_id":"source/_posts/[Docker学习三]Docker入门.md","shasum":"99d39700a4f4faaf2a781908c887d26061659c43","modified":1440146164000},{"_id":"source/_posts/[Docker学习二]Ubuntu系统安装Docker.md","shasum":"2e6ebbfd0cbbb36ea49138c93c2e2aaf71bf5076","modified":1440143523000},{"_id":"source/_posts/[JDK工具学习一]jps命令使用.md","shasum":"cc186f8ffa3b4b45a52de91efe69c9c49eb54d40","modified":1440144261000},{"_id":"source/_posts/[JDK工具学习七]jcmd命令使用.md","shasum":"dad82b41fb35c81362ceaaa4a50d65efec9cba96","modified":1440144623000},{"_id":"source/_posts/[JDK工具学习三]jinfo命令使用.md","shasum":"7bc733c4ce7974177c5c579a0ac11712837077cd","modified":1440144322000},{"_id":"source/_posts/[JDK工具学习二]jstat命令使用.md","shasum":"3a2cf8d3579368b797273bf4877df64ba10d116f","modified":1440935768000},{"_id":"source/_posts/[JDK工具学习五]jhat命令使用.md","shasum":"9d9505c2f663431cd278893e2e3032ea20aeabc9","modified":1440144519000},{"_id":"source/_posts/[JDK工具学习六]jstack命令使用.md","shasum":"84ac0c6c07e70c5145ae6a6270250bdcb5990cff","modified":1440144575000},{"_id":"source/_posts/[JDK工具学习四]jmap命令使用.md","shasum":"bcc41c40bd310c6a2300d4670a77ead78019263b","modified":1440936008000},{"_id":"source/_posts/[Java]ToStringBuilder介绍.md","shasum":"69ef02bfb3bcda9731f19c6eaa01d2cae4f3f919","modified":1440145092000},{"_id":"source/_posts/[Java]finalize-方法对垃圾回收的影响.md","shasum":"cbb58d472247161c4a4d8c576f1e8557c512fb30","modified":1440145126000},{"_id":"source/_posts/[Java]初探Java虚拟机.md","shasum":"fddda9acc194611c82d5e99de54ee7bccf786b97","modified":1440145193000},{"_id":"source/_posts/[Java]四种引用类型.md","shasum":"16ad8887ab581774c696ed9ae066a1baa59b3ef8","modified":1440145049000},{"_id":"source/_posts/[Java]垃圾回收算法概述.md","shasum":"e975a479d5477dff28e2b3879130378a50705976","modified":1440145220000},{"_id":"source/_posts/[Java]常用虚拟机参数.md","shasum":"5291dd01d6bc030254287c197fb106927e904e3d","modified":1440145007000},{"_id":"source/_posts/[Java]直接内存和堆内存的性能比较.md","shasum":"28f4f3894fcb453c8be663796c995e4d799ff9d4","modified":1440145250000},{"_id":"source/_posts/[Java]虚拟机基本结构.md","shasum":"8daf056ef9328c797c64b9facfb9fb0a38a772b4","modified":1440145157000},{"_id":"source/_posts/[Java并发包学习一]Executor和ExecutorService.md","shasum":"3af3be009fb8f06bc9272147fda4c9e0c93b13cb","modified":1440933424000},{"_id":"source/_posts/[Java并发包学习七]解密ThreadLocal.md","shasum":"f066aad0b40cbe2f996023746efb992274dd0efb","modified":1444716222000},{"_id":"source/_posts/[Java并发包学习三]ThreadFactory介绍.md","shasum":"28fc4d488329a2edfb66d669c5f90c700bed485a","modified":1440933424000},{"_id":"source/_posts/[Java并发包学习二]Executors介绍.md","shasum":"c61ebdd687ee9df0bfc600fa6fd10bec6525e9e4","modified":1440143790000},{"_id":"source/_posts/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍.md","shasum":"0c9f2a83bc0ca6e01a9fe9aed1d138fc665ec667","modified":1441941223000},{"_id":"source/_posts/[Java并发包学习八]深度剖析ConcurrentHashMap.md","shasum":"b63f8576e948206d9e6af06205aa99881f9efcad","modified":1445264589000},{"_id":"source/_posts/[Java并发包学习六]Semaphore介绍.md","shasum":"3c684ad269c144f19d2b357cdf47f6a44140a07c","modified":1440520850000},{"_id":"source/_posts/[Java并发包学习四]Future和FutureTask.md","shasum":"7bbf5ebc9f5117b3f81f7ea77a4aefc498bd8fd9","modified":1440933424000},{"_id":"source/_posts/[Java锁学习一]偏向锁.md","shasum":"fbfeb4b0fd044d19db816a80c706b3f6c0f4dcac","modified":1440144687000},{"_id":"source/_posts/[Java锁学习三]锁在应用层的优化思路.md","shasum":"aa4716a29de128ced33983013b47a763d01e97dc","modified":1440144791000},{"_id":"source/_posts/[Java锁学习二]锁消除.md","shasum":"30e372ffc713a344570bddaa47397b34b9ee15c9","modified":1440144733000},{"_id":"source/_posts/[MarkDown]MarkDown简介.md","shasum":"4bd16daee24aebf38e4fcc7b2de6e3ec693dc0e8","modified":1440145473000},{"_id":"source/_posts/[git]git命令自动补全.md","shasum":"48f1e4ad8bd3ed5c5488a0976eb148f3f8a82368","modified":1444716272000},{"_id":"source/_posts/[数据库]NoSQL简介.md","shasum":"208582a070851b4bfd24ae1fe9a06d7e37dc0ad0","modified":1440145367000},{"_id":"source/_posts/[日志处理]log4j配置详解.md","shasum":"d1e563b421abcf931dd1fc51bee8ba1fd21ad4ce","modified":1440951691000},{"_id":"source/_posts/[日志处理]slf4j的优势与使用原理.md","shasum":"121a0b97e7311d6eba25786b51af9523c7829491","modified":1440600162000},{"_id":"source/_posts/sed命令详解.md","shasum":"d2338fd1f2a9aebd7663cfa8c2ca94f237d9d81c","modified":1442849223000},{"_id":"source/_posts/wait-notify-notifyAll详细介绍.md","shasum":"28693075bf88729b215ade943ce31ecc97a96e9f","modified":1445580659000},{"_id":"source/_posts/代码战争.md","shasum":"79b99d31cfa55fbc6bb1dfcafeae2b1066681ff1","modified":1445575957000},{"_id":"source/_posts/皆大欢喜的加薪.md","shasum":"835d6293c342fb9b9106b257f7360d55f965027b","modified":1445575920000},{"_id":"source/_posts/程序员八荣八耻.md","shasum":"26f4e59b2fc826230a7eb21baa17a3f511e57be5","modified":1445575939000},{"_id":"source/about/index.md","shasum":"39cf209f6fcf8871df226c91c9f0f477e8653791","modified":1444877719000},{"_id":"source/categories/index.md","shasum":"388aa0be8c7262753c42052f961814d46d477184","modified":1439361984000},{"_id":"source/robots.txt","shasum":"64be6aaa5b6855e518c0f750b7887d6a4f74581f","modified":1442385570000},{"_id":"source/sitemap.txt","shasum":"6c393a1d0b29bfc88dcf7cbf0f1c3537be2569ca","modified":1440847123000},{"_id":"source/tags/index.md","shasum":"9eb1491493ff21a38eb4a1d3b11810f08dd1db1e","modified":1439361984000},{"_id":"themes/next/source/css/_common/_page/home.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/source/css/_mixins/Mist.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/source/css/_mixins/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/source/css/_mixins/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/source/css/_variables/custom.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/source/css/_variables/default.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1439361984000},{"_id":"themes/next/README.en.md","shasum":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1439361984000},{"_id":"themes/next/README.md","shasum":"aa16555d1aa1d80666ab9085042e118cdb7f5ef2","modified":1439361984000},{"_id":"themes/next/_config.yml","shasum":"6439ccb05a1a418d1ea4b1158aa2df9a037ff749","modified":1443593167000},{"_id":"themes/next/languages/de.yml","shasum":"784bea46de28a3113d7c91621740f521dae09dce","modified":1439361984000},{"_id":"themes/next/languages/default.yml","shasum":"d0cad2843283dd2a62cb8d1a2ed182a368210aca","modified":1439361984000},{"_id":"themes/next/languages/en.yml","shasum":"d0cad2843283dd2a62cb8d1a2ed182a368210aca","modified":1439361984000},{"_id":"themes/next/languages/fr-FR.yml","shasum":"9ee1011db6307df957684c83f39ac7499391924c","modified":1439361984000},{"_id":"themes/next/languages/ru.yml","shasum":"60cc1fb273adfd84137a207dd9d0d00f08605ccd","modified":1439361984000},{"_id":"themes/next/languages/zh-Hans.yml","shasum":"7a9daa8bac2c82eca0ebe77a78f94733481ab7e7","modified":1439361984000},{"_id":"themes/next/languages/zh-hk.yml","shasum":"e58766e0af5abf0705ccca4a5fc86d1be03db198","modified":1439361984000},{"_id":"themes/next/languages/zh-tw.yml","shasum":"d34c5781a231978e66852784ad00c9895a7de022","modified":1439361984000},{"_id":"themes/next/layout/_layout.swig","shasum":"42a41e7fa6328e5c1a6cf7e0cfb91da97d4a6c31","modified":1445663049000},{"_id":"themes/next/layout/_macro/post-collapse.swig","shasum":"e0e16ca56917b51728a13453d0a2f932da7ecdcb","modified":1439361984000},{"_id":"themes/next/layout/_macro/post.swig","shasum":"3cfebe634145c9e59ef54b4ca466ead4535d2c18","modified":1442568962000},{"_id":"themes/next/layout/_macro/sidebar.swig","shasum":"58e8624f88bcebf5f36701d499a1f13165c9bbb5","modified":1442387250000},{"_id":"themes/next/layout/_partials/footer.swig","shasum":"6b4dbeec062dd38bfc2bdb9d133849622f9dcce4","modified":1445494034000},{"_id":"themes/next/layout/_partials/head.swig","shasum":"d92cf1010115612d4311ae829496395e3783c700","modified":1442411926000},{"_id":"themes/next/layout/_partials/header.swig","shasum":"4be17058ca3a895b3a21244e1eae3c075c7650d8","modified":1442730985000},{"_id":"themes/next/layout/_partials/old-browsers.swig","shasum":"dbbfea810bf3a2ed9c83b9a6683037175aacfc67","modified":1439361984000},{"_id":"themes/next/layout/_partials/pagination.swig","shasum":"d6c7f04eee4388d8f133eb5526b7c0875c321a30","modified":1439361984000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","shasum":"ee0c2540e8178f390051af7d365a42ae68375afa","modified":1439361984000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","shasum":"94beb0764ccbbba0c9f5c9886cc656bf879bcfd5","modified":1439361984000},{"_id":"themes/next/layout/_partials/search.swig","shasum":"8a18d32e2a257dafaaba75353692db901e1dddc5","modified":1439361984000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","shasum":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1439361984000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","shasum":"63315fcf210799f894208c9f512737096df84962","modified":1439361984000},{"_id":"themes/next/layout/_scripts/analytics/baidu-analytics.swig","shasum":"5ccaf2f2fa5e9a4a7dbdf146605c6f336abcf89f","modified":1440847746000},{"_id":"themes/next/layout/_scripts/analytics/google-analytics.swig","shasum":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1439361984000},{"_id":"themes/next/layout/_scripts/analytics.swig","shasum":"0ebbf76c2317faa8ba31365adba59331c2e0262c","modified":1439361984000},{"_id":"themes/next/layout/_scripts/baidushare.swig","shasum":"d726361945437cf6e48067b3dd041b7e36e98d85","modified":1439361984000},{"_id":"themes/next/layout/_scripts/bootstrap.scrollspy.swig","shasum":"85295f126836b95f0837d03e58228bb3cf8c4490","modified":1439361984000},{"_id":"themes/next/layout/_scripts/comments/disqus.swig","shasum":"3491d3cebabc8a28857200db28a1be65aad6adc2","modified":1439361984000},{"_id":"themes/next/layout/_scripts/comments/duoshuo.swig","shasum":"0da59f3ef04af3f9d342a44cef632f6496187822","modified":1442406832000},{"_id":"themes/next/layout/_scripts/fancy-box.swig","shasum":"41b4ff1446060c88c33bf666a32277dcf12129f0","modified":1439361984000},{"_id":"themes/next/layout/_scripts/helpers.swig","shasum":"4d2cbfca0aaf546a2b5813288073e824c1498fdf","modified":1439361984000},{"_id":"themes/next/layout/_scripts/mathjax.swig","shasum":"abc52fefb276c52cbb19de5c214521dfcf2a10fd","modified":1439361984000},{"_id":"themes/next/layout/_scripts/motion.swig","shasum":"817705bfd1a1282cb6bf59094afe507e11455aa0","modified":1439361984000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","shasum":"b63ef233886538f30ced60344ac15d25e5f3e0af","modified":1439361984000},{"_id":"themes/next/layout/archive.swig","shasum":"0c3ce594759f347ea90a4ce592a7a18e2ae4cc5c","modified":1440600810000},{"_id":"themes/next/layout/category.swig","shasum":"d6b3e1dc5e0b8deade9a084c463126e70188ee9b","modified":1440600851000},{"_id":"themes/next/layout/index.swig","shasum":"fe8a79fc65f08ffcf51a3c24b0e884145b677a0b","modified":1442387602000},{"_id":"themes/next/layout/page.swig","shasum":"c1e392549a85a13b1b697656b169af09c78f8c4d","modified":1440600864000},{"_id":"themes/next/layout/post.swig","shasum":"a84457e8ced46e63bc7a8a9e0541a6ba53122a92","modified":1440600876000},{"_id":"themes/next/layout/tag.swig","shasum":"aab44af54fcbc66fea4ad12b2767ffca3eadd451","modified":1440600891000},{"_id":"themes/next/source/404.html","shasum":"c529c9996250082ea7eb024078bef33e88e01353","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/back-to-top.styl","shasum":"88cd66910260006aa8e9e795df4948d4b67bfa11","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/buttons.styl","shasum":"81063e0979f04a0f9af37f321d7321dda9abf593","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/comments.styl","shasum":"54e73681ba6f57ef961138f94d2ee8ac845990c3","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/duoshuo.styl","shasum":"c307f1e4827d7cb82816a5f9de109ae14ed4199c","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/gallery.styl","shasum":"fa6e23ebddb6f235803b51974f36be2a43b2c9c4","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/jiathis.styl","shasum":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/pagination.styl","shasum":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/posts-collapse.styl","shasum":"8f9e8f5f65956ccf1d52ff8526392803dff579d3","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/posts-expand.styl","shasum":"4b82dbbb6e536e6e8ee3cec6e62c2fd4bea60a09","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/posts-type.styl","shasum":"40b593134bf96d1d6095b3439d47820659d7f10b","modified":1439361984000},{"_id":"themes/next/source/css/_common/_component/tag-cloud.styl","shasum":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1439361984000},{"_id":"themes/next/source/css/_common/_core/base.styl","shasum":"e79a08484b191dca14ccfc005053eb95786dafae","modified":1439361984000},{"_id":"themes/next/source/css/_common/_core/helpers.styl","shasum":"41a31d651b60b4f458fc56a1d191dfbbdcb6d794","modified":1439361984000},{"_id":"themes/next/source/css/_common/_core/normalize.styl","shasum":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1439361984000},{"_id":"themes/next/source/css/_common/_core/scaffolding.styl","shasum":"d776e241cf650b00ee1dd21b9ff377c250d9eeaa","modified":1439361984000},{"_id":"themes/next/source/css/_common/_core/tables.styl","shasum":"be6c1a04595cf38673511366a3d89fcdb046f533","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-default.styl","shasum":"86bd4135afa2589ad074e0cf8ebb054ff3d10f24","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-feather.styl","shasum":"f49f8966496166bd62f79f75a3277d4d5b1102e8","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-fifty-shades.styl","shasum":"90e68936ea0f26af93c2c517fe1b891538f9c1b1","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-font.styl","shasum":"6fd7caf8194656b90c3b7976295f157bce593b54","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-linecons.styl","shasum":"3874252c8392b5a18e849ac69b6d66999ec1de16","modified":1439361984000},{"_id":"themes/next/source/css/_common/_fonts/icon-winwill2012.styl","shasum":"c4f8c8ad54f09476582fff572f2712a931d82695","modified":1442417709000},{"_id":"themes/next/source/css/_common/_page/archive.styl","shasum":"dff879f55ca65fa79c07e9098719e53eeea7ac88","modified":1439361984000},{"_id":"themes/next/source/css/_common/_page/categories.styl","shasum":"4f696a2eaeee2f214adcf273eab25c62a398077a","modified":1439361984000},{"_id":"themes/next/source/css/_common/_page/post-detail.styl","shasum":"73796f6f13caa7151a2ee8e55755627e0d189f55","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/body.styl","shasum":"ca1a4766cbe25baac757c6b47a4858d221afdc40","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/footer.styl","shasum":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/header.styl","shasum":"ba501332fb111bd72dc0777f2e1c8a29ad538ff9","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/layout.styl","shasum":"4daaadd156ece64ae05908ad6bb0159c8a27c071","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/media.styl","shasum":"fa9809d2ecc753cf32f70803c1d0821c405211f4","modified":1439361984000},{"_id":"themes/next/source/css/_common/_section/sidebar.styl","shasum":"d57e1769ebd2c472d2b27d17a706d3f564f94033","modified":1439361984000},{"_id":"themes/next/source/css/_common/_vendor/highlight/highlight.styl","shasum":"6259f4780f2aae1e6f85b892d8822c1c7ebc28bc","modified":1439361984000},{"_id":"themes/next/source/css/_common/_vendor/highlight/theme.styl","shasum":"ae19721ceee5ba460e131cb2427dae3c1ff39d6f","modified":1439361984000},{"_id":"themes/next/source/css/_custom/custom.styl","shasum":"68b6859fb48fe8358e567fc324f218cecfc3a533","modified":1439361984000},{"_id":"themes/next/source/css/_mixins/base.styl","shasum":"66985fe77bd323f7f8f634908e17166f51e96e95","modified":1439361984000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","shasum":"b0037a87ee1a613f315c331e8ecf1673c6d82211","modified":1442732500000},{"_id":"themes/next/source/css/_schemes/default/_menu.styl","shasum":"4bba29cece65ffc5122f4e052063dea4439fe4ae","modified":1439361984000},{"_id":"themes/next/source/css/_schemes/default/_search.styl","shasum":"05045d24850a982dc8069012c86c878b130b60eb","modified":1439361984000},{"_id":"themes/next/source/css/_schemes/default/index.styl","shasum":"2588e55132e10d82c0608f03c2c72a2bace8fa4e","modified":1439361984000},{"_id":"themes/next/source/css/_variables/Mist.styl","shasum":"f5dda1ca48c1b73a0bd34e08413de57699f24083","modified":1439361984000},{"_id":"themes/next/source/css/_variables/base.styl","shasum":"59acc8bf6e6b55f576b001e520e048cd0ca801fb","modified":1439361984000},{"_id":"themes/next/source/css/main.styl","shasum":"b05c342e94ded24a5f2b203cedf77d3faa817fd5","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-default/icomoon.eot","shasum":"a58d5e893c6faefc90d5c2589cc314dff8ffca7a","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-default/icomoon.svg","shasum":"4f18f0bb815b1aeba57739069c3416106240b7c1","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-default/icomoon.ttf","shasum":"e6452f07b050ee0ff265b3b99a1e7ef82eb561b2","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-default/icomoon.woff","shasum":"4d0adc55240f331c6de225e23afd76ea5318da9c","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.eot","shasum":"6d0eb1a5bfef4f2bf77089bd090e88c5b2f7944d","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.svg","shasum":"690836f81c0feb1a49e2253d4f984ad543414986","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.ttf","shasum":"8c865cffa3845be32406737fcc0466cf9cd965b3","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-feather/icomoon.woff","shasum":"9159eea8641b840e0f7aa6e087dae414044ecdd3","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.eot","shasum":"f27c3643af6ed6f3d29a0be0c8dbea9b157857db","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.svg","shasum":"f0790da03008b6cb3ae4215cbb656cb4b4599633","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.ttf","shasum":"e0b5e4a23a949bac499908bcef2fae56430e230e","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-fifty-shades/icomoon.woff","shasum":"088a16303b0700e1c9e2c6962240b4c2f0fc3aa4","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.eot","shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.svg","shasum":"e316347805eb93425faa678611c5e42a7152da8f","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.ttf","shasum":"f399713d1c9400d4d3373e38991a7e362a754a94","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-icomoon/icomoon.woff","shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.eot","shasum":"176695cc0dc12daba049b2bb889397a7bf2e553c","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.ttf","shasum":"c8ec218adabc788b17f976f60dd1c5fa872d9fc4","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.woff","shasum":"d1ed08a17670fa259df02c1d52dc9ce754343775","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.eot","shasum":"8c64d1154cff0fcf11a9735104355fbd9b781814","modified":1442417729000},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.svg","shasum":"b055f109eb576bd3920884f82f3ac8833433915d","modified":1442417729000},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.ttf","shasum":"4b4f7e516c37738b730b6ee0eba2c8c0edb5e489","modified":1442417729000},{"_id":"themes/next/source/fonts/icon-winwill2012/icomoon.woff","shasum":"b4f2cce2e608b30249a3fd71c976aeab0a3be630","modified":1442417729000},{"_id":"themes/next/source/images/bkdefault_avatar.jpg","shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc","modified":1439361984000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1439361984000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1439361984000},{"_id":"themes/next/source/images/cc-by-nc.svg","shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1439361984000},{"_id":"themes/next/source/images/cc-by-nd.svg","shasum":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1439361984000},{"_id":"themes/next/source/images/cc-by-sa.svg","shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1439361984000},{"_id":"themes/next/source/images/cc-by.svg","shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1439361984000},{"_id":"themes/next/source/images/cc-zero.svg","shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1439361984000},{"_id":"themes/next/source/images/it.jpg","shasum":"4b8977f4357bfde1a60b408414fbde635bffc3dc","modified":1439361984000},{"_id":"themes/next/source/images/loading.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1439361984000},{"_id":"themes/next/source/images/placeholder.gif","shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1439361984000},{"_id":"themes/next/source/images/searchicon.png","shasum":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1439361984000},{"_id":"themes/next/source/js/fancy-box.js","shasum":"116cafc741e048497287121a508d7a54c050c70c","modified":1439361984000},{"_id":"themes/next/source/js/bootstrap.scrollspy.js","shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625","modified":1439361984000},{"_id":"themes/next/source/js/helpers.js","shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335","modified":1439361984000},{"_id":"themes/next/source/js/hook-duoshuo.js","shasum":"a7a618126d6853d52f4e32be116d3985325ad17d","modified":1439361984000},{"_id":"themes/next/source/js/lazyload.js","shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf","modified":1439361984000},{"_id":"themes/next/source/js/motion_fallback.js","shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e","modified":1439361984000},{"_id":"themes/next/source/js/motion_global.js","shasum":"e6df9e7e61109667df0e22c4f7cc25c85015440b","modified":1439361984000},{"_id":"themes/next/source/js/search-toggle.js","shasum":"0bf617514cd86307f0678a226761341100dd86d4","modified":1439361984000},{"_id":"themes/next/source/js/ua-parser.min.js","shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/fancybox_buttons.png","shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-media.js","shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","shasum":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.css","shasum":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.js","shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1439361984000},{"_id":"themes/next/source/vendors/fancybox/source/jquery.fancybox.pack.js","shasum":"53360764b429c212f424399384417ccc233bb3be","modified":1439361984000},{"_id":"themes/next/source/vendors/velocity/bower.json","shasum":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1439361984000},{"_id":"themes/next/source/vendors/velocity/velocity.min.js","shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1439361984000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.js","shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1439361984000},{"_id":"themes/next/source/vendors/velocity/velocity.ui.min.js","shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1439361984000},{"_id":"themes/next/tests/helpers.js","shasum":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1439361984000},{"_id":"themes/next/tests/intern.js","shasum":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1439361984000},{"_id":"themes/next/source/fonts/icon-linecons/icomoon.svg","shasum":"888a285a4a7329210b2210742c673611c27425eb","modified":1439361984000},{"_id":"themes/next/source/images/wechat.jpg","shasum":"2d17b680c1b7ac7d5ee4c3610f578fced7bbab78","modified":1439361984000},{"_id":"themes/next/source/vendors/jquery/index.js","shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1439361984000},{"_id":"themes/next/source/vendors/velocity/velocity.js","shasum":"e63dc7cea055ca60a95d286f32349d88b10c5a4d","modified":1439361984000},{"_id":"themes/next/source/images/qifuguang.jpg","shasum":"1ded095e58fea7fb9cef90b8ba2b88570e2d16bc","modified":1439361984000},{"_id":"source/_posts/Java并发包学习九-Java中的阻塞队列.md","shasum":"dad04bcb0e20790b2b0c2f763dad71d2ad94a099","modified":1445588173000},{"_id":"public/tags/index.html","modified":1445663074131,"shasum":"200cbaeb6471525c8c7dea4f53be6ac995fbb0f8"},{"_id":"public/categories/index.html","modified":1445663074185,"shasum":"ba0d2bf48fb57eb8bb91d400160327de556419c0"},{"_id":"public/about/index.html","modified":1445663074225,"shasum":"1ef850f0d0de5a1339f63f75c892a265c9e6408d"},{"_id":"public/2015/10/23/Java并发包学习九-Java中的阻塞队列/index.html","modified":1445663074325,"shasum":"e461ae381ff831a67a4276f11bd38403f90751cf"},{"_id":"public/2015/10/23/wait-notify-notifyAll详细介绍/index.html","modified":1445663074386,"shasum":"b4e5c5fb5a3e35395ce7d64531c6f6ed8ead3d84"},{"_id":"public/2015/10/23/皆大欢喜的加薪/index.html","modified":1445663074433,"shasum":"0941d97d50070e5c76e3644241439f602457810b"},{"_id":"public/2015/10/18/Redis主从复制/index.html","modified":1445663074500,"shasum":"4d6a2d6f03571a5cbf644cda89a53cc025767fbc"},{"_id":"public/2015/10/13/Redis持久化/index.html","modified":1445663074634,"shasum":"57425f8efa4990e1ce69e1f3fe3cdb4d8de7bb48"},{"_id":"public/2015/10/10/ZooKeeper使用场景/index.html","modified":1445663074771,"shasum":"262670f9d60284e16c3378258a66ad2b3e900cec"},{"_id":"public/2015/09/30/Redis过期机制介绍/index.html","modified":1445663074837,"shasum":"f7be4958a84eda0b597fed5e83440ae9d7bdb4db"},{"_id":"public/2015/09/30/Redis事务介绍/index.html","modified":1445663074901,"shasum":"3eb45a1d6e626baad8f498c5b95c275259ce0121"},{"_id":"public/2015/09/29/Redis五种数据类型介绍/index.html","modified":1445663074945,"shasum":"e8f8d1cdbf9a9cf8a76073b8461090bb3eae099c"},{"_id":"public/2015/09/28/Redis-3-0新特性/index.html","modified":1445663075000,"shasum":"c3e1a2a88387fd6c9a46ab7bfa6c5fb695a3d5af"},{"_id":"public/2015/09/23/Shell特殊字符简介/index.html","modified":1445663075039,"shasum":"0938367c27fa39e1f0ff68c43fb35484ab462221"},{"_id":"public/2015/09/21/sed命令详解/index.html","modified":1445663075098,"shasum":"a5067a7f75356c7425b75edf016d3b268b695d33"},{"_id":"public/2015/09/18/IntelliJ远程调试教程/index.html","modified":1445663075176,"shasum":"a7531f5a9e19bd089fa35d28fcf1a7dd95002a35"},{"_id":"public/2015/09/11/Thrift入门教程/index.html","modified":1445663075286,"shasum":"3285eb49f121ddb168875c08f22a021149f1a3a1"},{"_id":"public/2015/09/10/[Java并发包学习八]深度剖析ConcurrentHashMap/index.html","modified":1445663075358,"shasum":"621ea1ee8faecea175403ce91cc894f483150d45"},{"_id":"public/2015/09/08/UTF8编码/index.html","modified":1445663075439,"shasum":"4456ac52174bee58e05f94b48c0e88b96c6656fe"},{"_id":"public/2015/09/04/程序员八荣八耻/index.html","modified":1445663075488,"shasum":"ec8d0521dcd25527afb34fddaed1857207b61dad"},{"_id":"public/2015/09/02/[git]git命令自动补全/index.html","modified":1445663075550,"shasum":"d241d3d8d7d74cb860430267f15e4dc7f97824e7"},{"_id":"public/2015/09/02/[Java并发包学习七]解密ThreadLocal/index.html","modified":1445663075610,"shasum":"136c8b3400b709374a7b75d27bfc433a83ba928b"},{"_id":"public/2015/08/31/A记录与CNAME记录介绍/index.html","modified":1445663075669,"shasum":"6f595d36cc3c1ee8e49bfc4778e44458eaa445c3"},{"_id":"public/2015/08/31/[日志处理]log4j配置详解/index.html","modified":1445663075722,"shasum":"055c04b7e4594c7e953600e58d6f0b58c8b3ab17"},{"_id":"public/2015/08/26/[日志处理]slf4j的优势与使用原理/index.html","modified":1445663075797,"shasum":"e0c771d4c2c0886c86a2b4ceea485c6439ae483d"},{"_id":"public/2015/08/26/[Java并发包学习六]Semaphore介绍/index.html","modified":1445663075851,"shasum":"304065108e4618d9411f152fd559f412658b52ba"},{"_id":"public/2015/08/25/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍/index.html","modified":1445663075927,"shasum":"736b34ca9f0537c8011657db84e208e90f6bfa1e"},{"_id":"public/2015/08/21/[Java并发包学习四]Future和FutureTask/index.html","modified":1445663075979,"shasum":"a3cf1828d493da5e50c071fafd7a8f50b20ad1ca"},{"_id":"public/2015/08/13/[Java并发包学习三]ThreadFactory介绍/index.html","modified":1445663076028,"shasum":"69dd6ba8ddfb3af83d172c88d89be2ca8b2c83f1"},{"_id":"public/2015/08/13/代码战争/index.html","modified":1445663076081,"shasum":"fd6737c1d5757ba3a0e29e57be6552d8b648e87e"},{"_id":"public/2015/08/12/[Java并发包学习二]Executors介绍/index.html","modified":1445663076130,"shasum":"08dfa62cfda393e5daa392249907d9c6cbc4e4ec"},{"_id":"public/2015/08/11/[Java并发包学习一]Executor和ExecutorService/index.html","modified":1445663076188,"shasum":"a05532473a394192e0b2f37194e8b68a209992cc"},{"_id":"public/2015/08/04/[数据库]NoSQL简介/index.html","modified":1445663076234,"shasum":"9f378a7c07ee7df516d52ded6c7cff992d603f31"},{"_id":"public/2015/08/01/[Docker学习三]Docker入门/index.html","modified":1445663076298,"shasum":"c1549d00cab06c9d8e198ca209026568198a4204"},{"_id":"public/2015/08/01/[Docker学习二]Ubuntu系统安装Docker/index.html","modified":1445663076354,"shasum":"54f54484a2dc126ec167f3f5b4389ce730fbfd44"},{"_id":"public/2015/08/01/[Docker学习一]Docker简介/index.html","modified":1445663076412,"shasum":"7ccd01c390e200c86e528025808fb3bbf2d3ec87"},{"_id":"public/2015/08/01/[Java锁学习三]锁在应用层的优化思路/index.html","modified":1445663076461,"shasum":"6f63dcb8edcdb805be54558a469fc847412ed6ca"},{"_id":"public/2015/08/01/[Java锁学习二]锁消除/index.html","modified":1445663076518,"shasum":"24055c69c0e033d21c357cdb2623e9ef70666f23"},{"_id":"public/2015/08/01/[Java锁学习一]偏向锁/index.html","modified":1445663076568,"shasum":"5544508d33ce8eec29d8ac213ece0411b4324871"},{"_id":"public/2015/08/01/[JDK工具学习七]jcmd命令使用/index.html","modified":1445663076613,"shasum":"7ccae7cb5385b63e0189d2230857fee4f5d0c625"},{"_id":"public/2015/08/01/[JDK工具学习六]jstack命令使用/index.html","modified":1445663076683,"shasum":"6e4fccbc1a6f0234846226be578219e38fbff6d3"},{"_id":"public/2015/08/01/[JDK工具学习五]jhat命令使用/index.html","modified":1445663076729,"shasum":"62a9fc5e8044835eaf818ce026c696a9f4c3ddc9"},{"_id":"public/2015/08/01/[JDK工具学习四]jmap命令使用/index.html","modified":1445663076794,"shasum":"99113eea89f03e8a61c924b5e9deb759b2fda74c"},{"_id":"public/2015/08/01/[JDK工具学习三]jinfo命令使用/index.html","modified":1445663076829,"shasum":"efdca98abf80ef9db4d644ef71dfa567d790d445"},{"_id":"public/2015/08/01/[JDK工具学习二]jstat命令使用/index.html","modified":1445663076899,"shasum":"406d1ecf7c2c22400a01de1e2a59866e206f7489"},{"_id":"public/2015/08/01/[JDK工具学习一]jps命令使用/index.html","modified":1445663076942,"shasum":"e1c1b93ce5d4aea840dab7875e19a662203f2eb2"},{"_id":"public/2015/08/01/[Java]finalize-方法对垃圾回收的影响/index.html","modified":1445663077007,"shasum":"4c8be816b55d1a7e31090d4519638092f90d619a"},{"_id":"public/2015/08/01/[Java]四种引用类型/index.html","modified":1445663077075,"shasum":"f9c87b0d00e1106563cfa60082bd868d210fb295"},{"_id":"public/2015/08/01/[Java]垃圾回收算法概述/index.html","modified":1445663077151,"shasum":"393beff09561de3166056210ad2845d433ce1a12"},{"_id":"public/2015/08/01/[Java]直接内存和堆内存的性能比较/index.html","modified":1445663077211,"shasum":"7be09d63a44993288654e6ea956d6830669271cc"},{"_id":"public/2015/08/01/[Java]常用虚拟机参数/index.html","modified":1445663077289,"shasum":"a8040bef10ff0e4e97cb504682094ed09897f199"},{"_id":"public/2015/08/01/[Java]虚拟机基本结构/index.html","modified":1445663077347,"shasum":"9f4b67a1123c3f7dbf0dd828381cfb3c0517c495"},{"_id":"public/2015/08/01/[Java]初探Java虚拟机/index.html","modified":1445663077426,"shasum":"a804723e89da6e95588c10bc7ff175c95e68c3e6"},{"_id":"public/2015/08/01/[Java]ToStringBuilder介绍/index.html","modified":1445663077492,"shasum":"532dad0d6bec789de2bd6dfc783cef3c794f0981"},{"_id":"public/2015/08/01/[MarkDown]MarkDown简介/index.html","modified":1445663077561,"shasum":"d2a9d94869a8b582f7f49830e00bb55021c85256"},{"_id":"public/categories/杂谈/index.html","modified":1445663078893,"shasum":"836449b3ea7d700f3ba6e776f0a68baf19a83620"},{"_id":"public/categories/Java/index.html","modified":1445663078946,"shasum":"46e7529b0a78a673f3c76fc1f8c062d7f155fb25"},{"_id":"public/categories/linux-shell/index.html","modified":1445663078978,"shasum":"b9d45f45092341f2c6346c1813409620032e13c8"},{"_id":"public/categories/日志处理/index.html","modified":1445663079024,"shasum":"d72403d9b06cc0489f2652fe01a2ed52c3eda589"},{"_id":"public/categories/数据库/index.html","modified":1445663079052,"shasum":"372fba19a57880bb7d438ddae26ab0b75edac2b6"},{"_id":"public/categories/git/index.html","modified":1445663079084,"shasum":"68467b89d608c01fe7ee1068a32952f0580ad93e"},{"_id":"public/categories/MarkDown/index.html","modified":1445663079123,"shasum":"77914f84412b9ce43751d83bcdfde43be2b48ed8"},{"_id":"public/categories/MarkDown/工具/index.html","modified":1445663079157,"shasum":"63bc6f5d9f9749c2f08fbd9f88fc3dab9d431175"},{"_id":"public/categories/Java锁学习/index.html","modified":1445663079192,"shasum":"1f0939399a7ab61a3ad48e7dbbf65ac2311008de"},{"_id":"public/categories/Java并发包学习/index.html","modified":1445663079248,"shasum":"c9bb77f6b8b8c855de42293ebe6674350b6f8798"},{"_id":"public/categories/JDK工具学习/index.html","modified":1445663079293,"shasum":"d6f271cc7ccaffe4299acda4de51bd049380c797"},{"_id":"public/categories/Docker/index.html","modified":1445663079334,"shasum":"2e4c23e0a38912f7e7c491b10bee6494ce5e0038"},{"_id":"public/categories/ZooKeeper/index.html","modified":1445663079371,"shasum":"5172755ebae7d820c208cf4fd2c1bedd260bb8a2"},{"_id":"public/categories/编码/index.html","modified":1445663079406,"shasum":"5d971e15e0362700a24a9034a632c4bfd0bf7d5d"},{"_id":"public/categories/thrift/index.html","modified":1445663079456,"shasum":"c21d1c337f10337051b6f047aee31680b3767123"},{"_id":"public/categories/Redis/index.html","modified":1445663079499,"shasum":"deb674500334d7c3c7e0864c439e4eeae63d1973"},{"_id":"public/categories/Redis/NoSQL/index.html","modified":1445663079544,"shasum":"91b4021baa0177cdccf6d9c23ac7551d69a30a9d"},{"_id":"public/categories/Java/工具/index.html","modified":1445663079577,"shasum":"0e283b94f41bd690bdbd4e7d02b4873c675e64e2"},{"_id":"public/categories/域名解析/index.html","modified":1445663079610,"shasum":"38c98ffb35093ce96a9d6684140e761a34e85c28"},{"_id":"public/archives/index.html","modified":1445663077681,"shasum":"76dd42f744ebe0ed0d07f558c5ad2c314b5ec0d1"},{"_id":"public/archives/page/2/index.html","modified":1445663077750,"shasum":"8c5701e9f6048d67ae36f22f55e1db6089c43749"},{"_id":"public/archives/page/3/index.html","modified":1445663077837,"shasum":"69196240984235fad2efd37942e7afbc9e71990b"},{"_id":"public/archives/page/4/index.html","modified":1445663077915,"shasum":"1dab86046f288c29be893fbb79a9badcb253b0b1"},{"_id":"public/archives/page/5/index.html","modified":1445663077983,"shasum":"e15d617fade05154fddc5cf2e6bba207dafa5df1"},{"_id":"public/archives/page/6/index.html","modified":1445663078024,"shasum":"7e08b14d8aef28d824a49605e965099a39dd0954"},{"_id":"public/archives/2015/index.html","modified":1445663078103,"shasum":"0c7cc53c16d749e6d04d1db0eb616a7497316efe"},{"_id":"public/archives/2015/page/2/index.html","modified":1445663078161,"shasum":"45c3ce48f6230d211d1eb824867d697b746964b1"},{"_id":"public/archives/2015/page/3/index.html","modified":1445663078225,"shasum":"358a714664cb7ef40a05abc15dc4459e382b52a4"},{"_id":"public/archives/2015/page/4/index.html","modified":1445663078305,"shasum":"7dac354b05d4340d3d8b7666ddbf2d4d186c94fb"},{"_id":"public/archives/2015/page/5/index.html","modified":1445663078379,"shasum":"e7c12ba2fcceb7c59ba0fe917f0d07be0d18a804"},{"_id":"public/archives/2015/page/6/index.html","modified":1445663078419,"shasum":"fa27a8906c99065a64072aaf005f4ab227a69c80"},{"_id":"public/archives/2015/08/index.html","modified":1445663078491,"shasum":"aaae0ceb7b02d6e3ffc2be2f7575ec855e9afda8"},{"_id":"public/archives/2015/08/page/2/index.html","modified":1445663078558,"shasum":"f497b1d5a687f8f01e05a665914dbba5b94d31f6"},{"_id":"public/archives/2015/08/page/3/index.html","modified":1445663078635,"shasum":"a950d383b490d799624ad4d0d4b890f53b084c60"},{"_id":"public/archives/2015/08/page/4/index.html","modified":1445663078679,"shasum":"b71f64dbd03c25b5fd93a7c7a53fc053e27d6e53"},{"_id":"public/archives/2015/09/index.html","modified":1445663078745,"shasum":"25796c04d47eee66c234152fa25237db03fbe60e"},{"_id":"public/archives/2015/09/page/2/index.html","modified":1445663078797,"shasum":"bf81a1803e78baf0e16eb4ec7ef68cf17b399ee2"},{"_id":"public/archives/2015/10/index.html","modified":1445663078848,"shasum":"7fe22110e2604bfe596be218c861eac799cf68a3"},{"_id":"public/baidusitemap.xml","modified":1445588184158,"shasum":"149879e03eeefb8364da41d4d686e4cd5bcdb69d"},{"_id":"public/atom.xml","modified":1445588184743,"shasum":"7f1880911d022ff2684f396fe47f4386178487ae"},{"_id":"public/index.html","modified":1445663079695,"shasum":"c0a4fad8c9bfef0169b4795e6325e2cb73ced8fb"},{"_id":"public/page/2/index.html","modified":1445663079762,"shasum":"b49768f0e5b535fa58a370788b1f446dfd0cc4e8"},{"_id":"public/page/3/index.html","modified":1445663079828,"shasum":"319af1863eda8d2969b6ee7bbf811cad8d70da16"},{"_id":"public/page/4/index.html","modified":1445663079916,"shasum":"d725209eead8db4d8a677a4ff5eecf03650792b8"},{"_id":"public/page/5/index.html","modified":1445663079993,"shasum":"7970e33ea736ba5e63ad4ace7cc6b5906fbc435b"},{"_id":"public/page/6/index.html","modified":1445663080038,"shasum":"5eed06230a8bf08a2bd9949bf6ba964bdee4e551"},{"_id":"public/sitemap.xml","modified":1445755814263,"shasum":"0c32b0e71fffe75d4f99deeb34f3fd5011955065"},{"_id":"public/tags/杂谈/index.html","modified":1445663080078,"shasum":"7001445d2339c1153c136f19f94fd72a0c0f4e7b"},{"_id":"public/tags/Java/index.html","modified":1445663080134,"shasum":"beb601a8f1bf723747a19aaa4494aca496d37ac1"},{"_id":"public/tags/linux-shell/index.html","modified":1445663080166,"shasum":"6f4bc9757551713c714697a1c94ad2dffcf596df"},{"_id":"public/tags/日志处理/index.html","modified":1445663080213,"shasum":"ac3185e89679372963daeb774dde1012f83a9d85"},{"_id":"public/tags/数据库/index.html","modified":1445663080239,"shasum":"67f22395d0702b78457f0d9293a6194eb1e5b731"},{"_id":"public/tags/git/index.html","modified":1445663080274,"shasum":"5de79a9dcd823a46917ad8db44ed020829d211fc"},{"_id":"public/tags/MarkDown/index.html","modified":1445663080317,"shasum":"b1233040176c97055f2ad78a9e8f166dc6e4f826"},{"_id":"public/tags/工具/index.html","modified":1445663080353,"shasum":"96179d017a8dd2478c36d2e6e439e96aed8e9fed"},{"_id":"public/tags/Java锁学习/index.html","modified":1445663080396,"shasum":"d57439262ccbb9bbbeab9dc714054bf14784b636"},{"_id":"public/tags/Java并发包学习/index.html","modified":1445663080460,"shasum":"8ba1af640a2b7bd7104bf74264e159e2203f748a"},{"_id":"public/tags/JDK工具学习/index.html","modified":1445663080494,"shasum":"5016b680d1d156b849fd1dd2aa2cd4e2b068dadd"},{"_id":"public/tags/Docker/index.html","modified":1445663080552,"shasum":"6f94faa40afa29d5c0d0a811ce83cb8b39153a85"},{"_id":"public/tags/ZooKeeper/index.html","modified":1445663080582,"shasum":"85ec2da81c4fc0474beb8dc5f9de8bc6c62ed836"},{"_id":"public/tags/编码/index.html","modified":1445663080622,"shasum":"3038e8baa350e41daa51f84233e5bd2afcd9a560"},{"_id":"public/tags/thrift/index.html","modified":1445663080667,"shasum":"3139aebfb7c4b7ae1f4df1af212f3919e5fd1fd1"},{"_id":"public/tags/Redis/index.html","modified":1445663080717,"shasum":"a522e4cc7213f15fc0c34c894bfbe11083697752"},{"_id":"public/tags/NoSQL/index.html","modified":1445663080761,"shasum":"ae4c133fd8a50ff929dec967b93b25ae4550e2e0"},{"_id":"public/tags/域名解析/index.html","modified":1445663080811,"shasum":"b4d0fd74e29c3d01bccba962e5baaadc4f93ce7b"},{"_id":"source/CNAME","shasum":"5bb3ccfccdab82b1cbb2037423ead180569c96c0","modified":1445680735000},{"_id":"public/CNAME","modified":1445680751545,"shasum":"5bb3ccfccdab82b1cbb2037423ead180569c96c0"},{"_id":"public/sitemap.txt","modified":1445762608910,"shasum":"6c393a1d0b29bfc88dcf7cbf0f1c3537be2569ca"},{"_id":"public/robots.txt","modified":1445762608916,"shasum":"64be6aaa5b6855e518c0f750b7887d6a4f74581f"},{"_id":"public/vendors/velocity/velocity.ui.min.js","modified":1445762608918,"shasum":"ed5e534cd680a25d8d14429af824f38a2c7d9908"},{"_id":"public/vendors/velocity/velocity.ui.js","modified":1445762608921,"shasum":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df"},{"_id":"public/vendors/velocity/velocity.min.js","modified":1445762608924,"shasum":"2f1afadc12e4cf59ef3b405308d21baa97e739c6"},{"_id":"public/vendors/velocity/velocity.js","modified":1445762608926,"shasum":"9f08181baea0cc0e906703b7e5df9111b9ef3373"},{"_id":"public/vendors/velocity/bower.json","modified":1445762608929,"shasum":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409"},{"_id":"public/vendors/jquery/index.js","modified":1445762608930,"shasum":"41b4bfbaa96be6d1440db6e78004ade1c134e276"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.pack.js","modified":1445762608934,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.js","modified":1445762608936,"shasum":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4"},{"_id":"public/vendors/fancybox/source/jquery.fancybox.css","modified":1445762608943,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1445762608946,"shasum":"53e194f4a72e649c04fb586dd57762b8c022800b"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1445762608947,"shasum":"4ac329c16a5277592fc12a37cca3d72ca4ec292f"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-media.js","modified":1445762608949,"shasum":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1445762608951,"shasum":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876"},{"_id":"public/vendors/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1445762608953,"shasum":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8"},{"_id":"public/vendors/fancybox/source/helpers/fancybox_buttons.png","modified":1445762608957,"shasum":"e385b139516c6813dcd64b8fc431c364ceafe5f3"},{"_id":"public/vendors/fancybox/source/fancybox_sprite@2x.png","modified":1445762608959,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/vendors/fancybox/source/fancybox_sprite.png","modified":1445762608962,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/vendors/fancybox/source/fancybox_overlay.png","modified":1445762608964,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/vendors/fancybox/source/fancybox_loading@2x.gif","modified":1445762608965,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/vendors/fancybox/source/fancybox_loading.gif","modified":1445762608967,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/vendors/fancybox/source/blank.gif","modified":1445762608980,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/js/ua-parser.min.js","modified":1445762608987,"shasum":"acf0ee6a47ffb7231472b56e43996e3f947c258a"},{"_id":"public/js/search-toggle.js","modified":1445762608992,"shasum":"0bf617514cd86307f0678a226761341100dd86d4"},{"_id":"public/js/motion_global.js","modified":1445762608993,"shasum":"e6df9e7e61109667df0e22c4f7cc25c85015440b"},{"_id":"public/js/motion_fallback.js","modified":1445762608995,"shasum":"a767d522c65a8b2fbad49135c9332135c6785c3e"},{"_id":"public/js/lazyload.js","modified":1445762608996,"shasum":"b92e9acdc7afc15468314c03f4a643b0c93944cf"},{"_id":"public/js/hook-duoshuo.js","modified":1445762608998,"shasum":"e529f5d6dda3aee77fadfed879da9fe1fb570165"},{"_id":"public/js/helpers.js","modified":1445762608999,"shasum":"c2117b0ec653df4c45dd9d9575b190cbe1035335"},{"_id":"public/js/fancy-box.js","modified":1445762609004,"shasum":"116cafc741e048497287121a508d7a54c050c70c"},{"_id":"public/js/bootstrap.scrollspy.js","modified":1445762609006,"shasum":"ae7bdce88b515aade4eea8bf7407eec458bcd625"},{"_id":"public/images/wechat.jpg","modified":1445762609010,"shasum":"2d17b680c1b7ac7d5ee4c3610f578fced7bbab78"},{"_id":"public/images/searchicon.png","modified":1445762609016,"shasum":"67727a6a969be0b2659b908518fa6706eed307b8"},{"_id":"public/images/qifuguang.jpg","modified":1445762609023,"shasum":"1ded095e58fea7fb9cef90b8ba2b88570e2d16bc"},{"_id":"public/images/placeholder.gif","modified":1445762609034,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/loading.gif","modified":1445762609036,"shasum":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b"},{"_id":"public/images/it.jpg","modified":1445762609038,"shasum":"4b8977f4357bfde1a60b408414fbde635bffc3dc"},{"_id":"public/images/cc-zero.svg","modified":1445762609040,"shasum":"87669bf8ac268a91d027a0a4802c92a1473e9030"},{"_id":"public/images/cc-by.svg","modified":1445762609041,"shasum":"28a0a4fe355a974a5e42f68031652b76798d4f7e"},{"_id":"public/images/cc-by-sa.svg","modified":1445762609044,"shasum":"aa4742d733c8af8d38d4c183b8adbdcab045872e"},{"_id":"public/images/cc-by-nd.svg","modified":1445762609050,"shasum":"c563508ce9ced1e66948024ba1153400ac0e0621"},{"_id":"public/images/cc-by-nc.svg","modified":1445762609053,"shasum":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7"},{"_id":"public/images/cc-by-nc-sa.svg","modified":1445762609054,"shasum":"3031be41e8753c70508aa88e84ed8f4f653f157e"},{"_id":"public/images/cc-by-nc-nd.svg","modified":1445762609058,"shasum":"c6524ece3f8039a5f612feaf865d21ec8a794564"},{"_id":"public/images/bkdefault_avatar.jpg","modified":1445762609062,"shasum":"b687bb4bfbe35a32b592c24d652ba80cfdc770fc"},{"_id":"public/fonts/icon-winwill2012/icomoon.woff","modified":1445762609066,"shasum":"b4f2cce2e608b30249a3fd71c976aeab0a3be630"},{"_id":"public/fonts/icon-winwill2012/icomoon.ttf","modified":1445762609069,"shasum":"4b4f7e516c37738b730b6ee0eba2c8c0edb5e489"},{"_id":"public/fonts/icon-winwill2012/icomoon.svg","modified":1445762609074,"shasum":"b055f109eb576bd3920884f82f3ac8833433915d"},{"_id":"public/fonts/icon-winwill2012/icomoon.eot","modified":1445762609077,"shasum":"8c64d1154cff0fcf11a9735104355fbd9b781814"},{"_id":"public/fonts/icon-linecons/icomoon.woff","modified":1445762609079,"shasum":"d1ed08a17670fa259df02c1d52dc9ce754343775"},{"_id":"public/fonts/icon-linecons/icomoon.ttf","modified":1445762609082,"shasum":"c8ec218adabc788b17f976f60dd1c5fa872d9fc4"},{"_id":"public/fonts/icon-linecons/icomoon.svg","modified":1445762609085,"shasum":"888a285a4a7329210b2210742c673611c27425eb"},{"_id":"public/fonts/icon-linecons/icomoon.eot","modified":1445762609091,"shasum":"176695cc0dc12daba049b2bb889397a7bf2e553c"},{"_id":"public/fonts/icon-icomoon/icomoon.woff","modified":1445762609098,"shasum":"05f1ec0bd307da5e731a86eb4961589a6042aebb"},{"_id":"public/fonts/icon-icomoon/icomoon.ttf","modified":1445762609101,"shasum":"f399713d1c9400d4d3373e38991a7e362a754a94"},{"_id":"public/fonts/icon-icomoon/icomoon.svg","modified":1445762609103,"shasum":"e316347805eb93425faa678611c5e42a7152da8f"},{"_id":"public/fonts/icon-icomoon/icomoon.eot","modified":1445762609105,"shasum":"301fcf00c24750dddf1c529f944ca62c7f1a217d"},{"_id":"public/fonts/icon-fifty-shades/icomoon.woff","modified":1445762609108,"shasum":"088a16303b0700e1c9e2c6962240b4c2f0fc3aa4"},{"_id":"public/fonts/icon-fifty-shades/icomoon.ttf","modified":1445762609111,"shasum":"e0b5e4a23a949bac499908bcef2fae56430e230e"},{"_id":"public/fonts/icon-fifty-shades/icomoon.svg","modified":1445762609121,"shasum":"f0790da03008b6cb3ae4215cbb656cb4b4599633"},{"_id":"public/fonts/icon-fifty-shades/icomoon.eot","modified":1445762609124,"shasum":"f27c3643af6ed6f3d29a0be0c8dbea9b157857db"},{"_id":"public/fonts/icon-feather/icomoon.woff","modified":1445762609128,"shasum":"9159eea8641b840e0f7aa6e087dae414044ecdd3"},{"_id":"public/fonts/icon-feather/icomoon.ttf","modified":1445762609131,"shasum":"8c865cffa3845be32406737fcc0466cf9cd965b3"},{"_id":"public/fonts/icon-feather/icomoon.svg","modified":1445762609134,"shasum":"690836f81c0feb1a49e2253d4f984ad543414986"},{"_id":"public/fonts/icon-feather/icomoon.eot","modified":1445762609139,"shasum":"6d0eb1a5bfef4f2bf77089bd090e88c5b2f7944d"},{"_id":"public/fonts/icon-default/icomoon.woff","modified":1445762609150,"shasum":"4d0adc55240f331c6de225e23afd76ea5318da9c"},{"_id":"public/fonts/icon-default/icomoon.ttf","modified":1445762609153,"shasum":"e6452f07b050ee0ff265b3b99a1e7ef82eb561b2"},{"_id":"public/fonts/icon-default/icomoon.svg","modified":1445762609161,"shasum":"4f18f0bb815b1aeba57739069c3416106240b7c1"},{"_id":"public/fonts/icon-default/icomoon.eot","modified":1445762609169,"shasum":"a58d5e893c6faefc90d5c2589cc314dff8ffca7a"},{"_id":"public/css/main.css","modified":1445762609778,"shasum":"146b5ebdeb0e6abc83128cc43ae7df41aad38ec5"},{"_id":"public/404.html","modified":1445762609873,"shasum":"c529c9996250082ea7eb024078bef33e88e01353"}],"Category":[{"name":"杂谈","_id":"cig3dov9b0004lo6bx0lzwww7"},{"name":"Java","_id":"cig3dov9y000flo6b1chgfkui"},{"name":"linux shell","_id":"cig3dova1000klo6bxtf67u6s"},{"name":"日志处理","_id":"cig3dova3000plo6bwoo7df9q"},{"name":"数据库","_id":"cig3dova8000xlo6bs18in1it"},{"name":"git","_id":"cig3dovab0012lo6bc2ew4jn5"},{"name":"MarkDown","_id":"cig3dovad0017lo6buac4e63z"},{"name":"工具","parent":"cig3dovad0017lo6buac4e63z","_id":"cig3dovad001alo6b20gpqn3v"},{"name":"Java锁学习","_id":"cig3dovag001glo6b32y4d3hq"},{"name":"Java并发包学习","_id":"cig3dovam001rlo6b4bl5jd8g"},{"name":"JDK工具学习","_id":"cig3dovbk0035lo6bbx4ffoc4"},{"name":"Docker","_id":"cig3dovc9003slo6b96gb7kdo"},{"name":"ZooKeeper","_id":"cig3dovci0043lo6bupai1j7q"},{"name":"编码","_id":"cig3dovck0048lo6bfyhvc881"},{"name":"thrift","_id":"cig3dovcn004dlo6b4rzhpr6u"},{"name":"Redis","_id":"cig3dovct004llo6bpustqsox"},{"name":"NoSQL","parent":"cig3dovct004llo6bpustqsox","_id":"cig3dovcu004olo6burtkurop"},{"name":"工具","parent":"cig3dov9y000flo6b1chgfkui","_id":"cig3dove2005mlo6bgbnxpc5y"},{"name":"域名解析","_id":"cig3dove5005slo6bc685ykuf"}],"Data":[],"Page":[{"title":"tags","date":"2015-07-31T12:39:32.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"title: tags\ndate: 2015-07-31 20:39:32\ntype: \"tags\"\ncomments: false\n---\n","updated":"2015-08-12T06:46:24.000Z","path":"tags/index.html","layout":"page","_id":"cig3dov6y0000lo6b1luzn7li"},{"title":"categories","date":"2015-07-31T17:30:44.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"title: categories\ndate: 2015-08-01 01:30:44\ntype: \"categories\"\ncomments: false\n---\n","updated":"2015-08-12T06:46:24.000Z","path":"categories/index.html","layout":"page","_id":"cig3dov8h0001lo6bfoeu3adr"},{"title":"about","date":"2015-07-31T13:02:17.000Z","comments":1,"_content":"### 关于我\n* ID：winwill2012\n* 毕业于：四川大学\n* 现就职于：小米科技有限责任公司\n* 职位：软件开发工程师\n* 兴趣：桌上足球，羽毛球，DOTA，电影院看电影\n* 梦想：做一个有钱和有品味的人，实在不行，只做个有钱人也可以\n\n### 关于博客\n* 目的：分享工作中的一些经验以及学习到的一些技能\n* 方向：Java，Redis，HBase，Storm，Kafka，RabbitMQ，Thrift，高并发，分布式...\n\n### 联系方式\n* 邮箱：qifuguang@gmail.com\n* 微博：[http://weibo.com/3497016832/profile?topnav=1&wvr=6](http://weibo.com/3497016832/profile?topnav=1&wvr=6)\n* 知乎：[http://www.zhihu.com/people/winwill2012](http://www.zhihu.com/people/winwill2012)\n* 微信：![](http://7xlune.com1.z0.glb.clouddn.com/images/WeChat.png)\n\n### 最近访客: \n<div class=\"ds-recent-visitors\" data-num-items=\"28\" data-avatar-size=\"42\" id=\"ds-recent-visitors\"></div>\n\n","source":"about/index.md","raw":"title: about\ndate: 2015-07-31 21:02:17\ncomments: true\n---\n### 关于我\n* ID：winwill2012\n* 毕业于：四川大学\n* 现就职于：小米科技有限责任公司\n* 职位：软件开发工程师\n* 兴趣：桌上足球，羽毛球，DOTA，电影院看电影\n* 梦想：做一个有钱和有品味的人，实在不行，只做个有钱人也可以\n\n### 关于博客\n* 目的：分享工作中的一些经验以及学习到的一些技能\n* 方向：Java，Redis，HBase，Storm，Kafka，RabbitMQ，Thrift，高并发，分布式...\n\n### 联系方式\n* 邮箱：qifuguang@gmail.com\n* 微博：[http://weibo.com/3497016832/profile?topnav=1&wvr=6](http://weibo.com/3497016832/profile?topnav=1&wvr=6)\n* 知乎：[http://www.zhihu.com/people/winwill2012](http://www.zhihu.com/people/winwill2012)\n* 微信：![](http://7xlune.com1.z0.glb.clouddn.com/images/WeChat.png)\n\n### 最近访客: \n<div class=\"ds-recent-visitors\" data-num-items=\"28\" data-avatar-size=\"42\" id=\"ds-recent-visitors\"></div>\n\n","updated":"2015-10-15T02:55:19.000Z","path":"about/index.html","layout":"page","_id":"cig3dov940002lo6b5sod6ahl"}],"Post":[{"title":"程序员八荣八耻","date":"2015-09-04T02:33:36.000Z","_content":"以动手实践为荣，以只看不练为耻。\n以打印日志为荣，以出错不报为耻。\n以局部变量为荣，以全局变量为耻。\n以单元测试为荣，以手工测试为耻。\n以代码重用为荣，以复制粘贴为耻。\n以多态应用为荣，以分支判断为耻。\n以定义常量为荣，以魔法数字为耻。\n以总结思考为荣，以不求甚解为耻。\n","source":"_posts/程序员八荣八耻.md","raw":"title: '程序员八荣八耻'\ntags: [杂谈]\ncategories: [杂谈]\ndate: 2015-09-04 10:33:36\n---\n以动手实践为荣，以只看不练为耻。\n以打印日志为荣，以出错不报为耻。\n以局部变量为荣，以全局变量为耻。\n以单元测试为荣，以手工测试为耻。\n以代码重用为荣，以复制粘贴为耻。\n以多态应用为荣，以分支判断为耻。\n以定义常量为荣，以魔法数字为耻。\n以总结思考为荣，以不求甚解为耻。\n","slug":"程序员八荣八耻","published":1,"updated":"2015-10-23T04:52:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dov970003lo6bex6aqoe2"},{"title":"皆大欢喜的加薪","date":"2015-10-23T04:47:28.000Z","_content":" 我的朋友A君是个典型的.NET开发人员，技术不错，人品也不错，在一家小公司（姑且称为甲公司）做项目开发，是技术骨干。3个月前，他找到我说想跳槽，让我帮忙介绍工作。我说为什么想跳了？\n\n<!--more-->\n##  为什么想离职？\n他简单说了一下他在甲公司当时的状况：A君在甲公司做了两年多，这两年多完成了一个大项目，作为开发的核心主力，开发压力很大，特别是项目上线前的几个月是非常辛苦，几乎每晚都要加班到12点以后，周末最多只有一天休息。在最困难的时候，老板给大家大气，“大家再坚持坚持，项目上线赚钱了，就给大家涨工资，公司是绝对不会亏待大家的”，在老板豪情壮语的加薪鼓励下，大家要紧牙关拼上了。终于，半年前，项目上线了，运行也慢慢稳定了，公司赚钱也多了起来。\n\n是的，公司赚钱了，利润很可观，这是大家都知道的事情。但是，一两个月过去了，加薪的事情完全没影，老板就像从来没提过一样。于是，A君向人事经理说出了希望加薪的请求，最后，得到的回复（在小公司，这当然是老板的意思）:\n\n1. A君目前的工资与外面相比，基本是持平的。\n2. A君目前的工作很悠闲，工作量不饱和。\n\n关于1实际上是个难题，两个人的工资要怎么比较，几乎都是老板一个非常主观的想法。而关于2，却是事实：由于新的项目还在调研中，所以，A君的工作暂时就轻松了不少，主要就是维护线上的系统，加加小功能，修修小bug，比较清闲。\n\n## 老板很有骨气\nA君听到回复后，很是生气，在和同事们一起吃饭时，就忍不住埋怨起公司来，后来，这话传到了老板的耳朵里，老板很有骨气：越是抱怨，越不给你涨工资，看你怎么样。\n终于，A决定离职，老板一如既往的有骨气：离职就离职，离开你公司就得关门了？\n所以，就回到了开头的一幕，3个月前，A要我帮忙介绍工作。我刚好想到之前另外一个乙公司的技术经理联系我说，他下面有个B君想离职，希望我推荐个人，事成之后有推荐费拿的。理所当然的，我把A推荐了到了乙公司，A接手了B君的工作（在接手的过程中，A和B还成为了好朋友），乙公司对A的表现非常满意，最后，A的工资相比在甲公司涨幅达到50%。\n\n## 对调一下吧\n事情还没完，A君从甲公司离职后，甲公司的线上系统的维护就成为一个大问题了，老板命令人事经理赶快找人来顶上，苦逼的人事经理在QQ里群发了招聘的信息，这个信息也发给了A君，于是，A君把正在找工作的B君推荐过去了。B君在甲公司工作一个月后就转正，老板也很满意，相比之前在乙公司工资上涨了30%，和现在A的工资差不多。\n\n —— 后来，A告诉我，B之所以要离职，原因跟A是差不多的。\n\n## 皆大欢喜\n这真是一个皆大欢喜的局面！\n\n1. A到乙公司接手了原来B的工作，工资涨了50%。\n2. B到甲公司接手了原来A的工作，工资涨了30%。\n3. 更重要的是，甲、乙公司的老板都爽了，对新进来的员工的表现都非常满意。\n4. 而我，拿到了乙公司的推荐费。\n5. A和B成为了好朋友，除了经常探讨技术外，还经常一起讨论这搞笑的离职加薪过程，交流心得。\n\n## 声明\n尊重原创，本文转载自：[http://www.cnblogs.com/justnow/p/4903436.html?utm_source=tuicool&utm_medium=referral](http://www.cnblogs.com/justnow/p/4903436.html?utm_source=tuicool&utm_medium=referral)\n","source":"_posts/皆大欢喜的加薪.md","raw":"title: 皆大欢喜的加薪\ntags: [杂谈]\ncategories: [杂谈]\ndate: 2015-10-23 12:47:28\n---\n 我的朋友A君是个典型的.NET开发人员，技术不错，人品也不错，在一家小公司（姑且称为甲公司）做项目开发，是技术骨干。3个月前，他找到我说想跳槽，让我帮忙介绍工作。我说为什么想跳了？\n\n<!--more-->\n##  为什么想离职？\n他简单说了一下他在甲公司当时的状况：A君在甲公司做了两年多，这两年多完成了一个大项目，作为开发的核心主力，开发压力很大，特别是项目上线前的几个月是非常辛苦，几乎每晚都要加班到12点以后，周末最多只有一天休息。在最困难的时候，老板给大家大气，“大家再坚持坚持，项目上线赚钱了，就给大家涨工资，公司是绝对不会亏待大家的”，在老板豪情壮语的加薪鼓励下，大家要紧牙关拼上了。终于，半年前，项目上线了，运行也慢慢稳定了，公司赚钱也多了起来。\n\n是的，公司赚钱了，利润很可观，这是大家都知道的事情。但是，一两个月过去了，加薪的事情完全没影，老板就像从来没提过一样。于是，A君向人事经理说出了希望加薪的请求，最后，得到的回复（在小公司，这当然是老板的意思）:\n\n1. A君目前的工资与外面相比，基本是持平的。\n2. A君目前的工作很悠闲，工作量不饱和。\n\n关于1实际上是个难题，两个人的工资要怎么比较，几乎都是老板一个非常主观的想法。而关于2，却是事实：由于新的项目还在调研中，所以，A君的工作暂时就轻松了不少，主要就是维护线上的系统，加加小功能，修修小bug，比较清闲。\n\n## 老板很有骨气\nA君听到回复后，很是生气，在和同事们一起吃饭时，就忍不住埋怨起公司来，后来，这话传到了老板的耳朵里，老板很有骨气：越是抱怨，越不给你涨工资，看你怎么样。\n终于，A决定离职，老板一如既往的有骨气：离职就离职，离开你公司就得关门了？\n所以，就回到了开头的一幕，3个月前，A要我帮忙介绍工作。我刚好想到之前另外一个乙公司的技术经理联系我说，他下面有个B君想离职，希望我推荐个人，事成之后有推荐费拿的。理所当然的，我把A推荐了到了乙公司，A接手了B君的工作（在接手的过程中，A和B还成为了好朋友），乙公司对A的表现非常满意，最后，A的工资相比在甲公司涨幅达到50%。\n\n## 对调一下吧\n事情还没完，A君从甲公司离职后，甲公司的线上系统的维护就成为一个大问题了，老板命令人事经理赶快找人来顶上，苦逼的人事经理在QQ里群发了招聘的信息，这个信息也发给了A君，于是，A君把正在找工作的B君推荐过去了。B君在甲公司工作一个月后就转正，老板也很满意，相比之前在乙公司工资上涨了30%，和现在A的工资差不多。\n\n —— 后来，A告诉我，B之所以要离职，原因跟A是差不多的。\n\n## 皆大欢喜\n这真是一个皆大欢喜的局面！\n\n1. A到乙公司接手了原来B的工作，工资涨了50%。\n2. B到甲公司接手了原来A的工作，工资涨了30%。\n3. 更重要的是，甲、乙公司的老板都爽了，对新进来的员工的表现都非常满意。\n4. 而我，拿到了乙公司的推荐费。\n5. A和B成为了好朋友，除了经常探讨技术外，还经常一起讨论这搞笑的离职加薪过程，交流心得。\n\n## 声明\n尊重原创，本文转载自：[http://www.cnblogs.com/justnow/p/4903436.html?utm_source=tuicool&utm_medium=referral](http://www.cnblogs.com/justnow/p/4903436.html?utm_source=tuicool&utm_medium=referral)\n","slug":"皆大欢喜的加薪","published":1,"updated":"2015-10-23T04:52:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dov9e0008lo6bt0t16hhn"},{"title":"代码战争","date":"2015-08-13T09:23:02.000Z","_content":">一天我路过一座桥，碰巧看见一个人想跳河自杀。我跑过去对他大喊道：“别跳，别死啊。”\n> “为什么不让我跳？”他说。\n<!--more-->\n> “因为还有很多东西值得我们活下去啊。”\n> “有吗？比如说？”\n> “呃……你做什么工作？”\n> “程序员。”\n> “我也是！瞧，有共同点了吧。你是软件还是硬件？”\n> “软件。”\n> “我也是！PC 还是 Web？”\n> “PC。”\n> “我也是！Windows 还是 Linux 平台？”\n> “Linux。”\n> “我也是！那你使用 C 还是 C++？”\n> “C++。”\n> “我也是。1998 年的 C++ 98 还是 2011 年的 C++ 11？”\n> “2011 年的 C++ 11。”\n> “我也是。大括号写在后面还是写在下一行？”\n> “下一行。”\n> “去死吧！你这个异教徒人渣！”我一把将他推下桥去。\n\n以上段子来源于[知乎](http://www.zhihu.com/question/33490847#answer-18353949)\n","source":"_posts/代码战争.md","raw":"title: \"代码战争\"\ntags: [杂谈]\ncategories: [杂谈]\ndate: 2015-08-13 17:23:02\n---\n>一天我路过一座桥，碰巧看见一个人想跳河自杀。我跑过去对他大喊道：“别跳，别死啊。”\n> “为什么不让我跳？”他说。\n<!--more-->\n> “因为还有很多东西值得我们活下去啊。”\n> “有吗？比如说？”\n> “呃……你做什么工作？”\n> “程序员。”\n> “我也是！瞧，有共同点了吧。你是软件还是硬件？”\n> “软件。”\n> “我也是！PC 还是 Web？”\n> “PC。”\n> “我也是！Windows 还是 Linux 平台？”\n> “Linux。”\n> “我也是！那你使用 C 还是 C++？”\n> “C++。”\n> “我也是。1998 年的 C++ 98 还是 2011 年的 C++ 11？”\n> “2011 年的 C++ 11。”\n> “我也是。大括号写在后面还是写在下一行？”\n> “下一行。”\n> “去死吧！你这个异教徒人渣！”我一把将他推下桥去。\n\n以上段子来源于[知乎](http://www.zhihu.com/question/33490847#answer-18353949)\n","slug":"代码战争","published":1,"updated":"2015-10-23T04:52:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dov9w000blo6bv6r0c547"},{"title":"wait,notify,notifyAll详细介绍","date":"2015-10-23T06:05:18.000Z","_content":"\n# 概述\nwait，notify和notifyAll方法是Object类的成员函数，所以Java的任何一个对象都能够调用这三个方法。这三个方法主要是用于线程间通信，协调多个线程的运行。\n\n<!--more-->\n# wait函数\n调用线程的sleep，yield方法时，线程并不会让出对象锁，wait却不同。\n\n**wait函数必须在同步代码块中调用(也就是当前线程必须持有对象的锁)**，他的功能是这样的：\n\n>我累了，休息一会儿，对象的锁你们拿去用吧，CPU也给你们。\n\n\n调用了wait函数的线程会一直等待，直到有其他线程调用了同一个对象的notify或者notifyAll方法才能被唤醒，需要注意的是：被唤醒并不代表立即获得对象的锁。也就是说，一个线程调用了对象的wait方法后，他需要等待两件事情的发生：\n\n1. 有其他线程调用同一个对象的notify或者notifyAll方法（调用notify/notifyAll方法之前）\n2. 被唤醒之后重新获得对象的锁(调用notify/notifyAll方法之后)\n\n才能继续往下执行后续动作。\n\n如果一个线程调用了某个对象的wait方法，但是后续并没有其他线程调用该对象的notify或者notifyAll方法，则该线程将会永远等下去...\n\n# notify和notifyAll方法\n**notofy/notifyAll方法也必须在同步代码块中调用(也就是调用线程必须持有对象的锁)**，他们的功能是这样的：\n\n> 女士们，先生们请注意，锁的对象我即将用完，请大家醒醒，准备一下，马上你们就能使用锁了。\n\n\n不同的是，notify方法只会唤醒一个正在等待的线程(至于唤醒谁，不确定！)，而notifyAll方法会唤醒所有正在等待的线程。还有一点需要特别强调：**调用notify和notifyAll方法后，当前线程并不会立即放弃锁的持有权，而必须要等待当前同步代码块执行完才会让出锁。**\n\n如果一个对象之前没有调用wait方法，那么调用notify方法是没有任何影响的。\n\n# 小试牛刀\n下面我们举例子来巩固上面讲到的理论知识,下面的代码创建了两个线程，Thread1在同步代码块中调用wait，Thread2在同步代码块中调用notify：\n\n```\npackage com.winwill.test;\n\n/**\n * @author winwill2012\n * @date 15/8/14 16:37\n */\npublic class Test {\n    private static final Object lock = new Object();\n\n    public static void main(String[] args) {\n        new Thread(new Thread1()).start();\n        new Thread(new Thread2()).start();\n    }\n\n    static class Thread1 implements Runnable {\n\n        @Override\n        public void run() {\n            System.out.println(\"Thread1 start...\");\n            synchronized (lock) {\n                try {\n                    lock.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            System.out.println(\"Thread1 stop...\");\n        }\n    }\n\n    static class Thread2 implements Runnable {\n\n        @Override\n        public void run() {\n            System.out.println(\"Thread2 start...\");\n            synchronized (lock) {\n                lock.notify();\n                System.out.println(\"Thread2 stop...\");\n            }\n        }\n    }\n}\n\n```\n运行结果如下：\n>Thread1 start...  \nThread2 start...  \nThread2 stop...  \nThread1 stop...  \n\n从上面的例子可以证实上面说到的一个结论：**线程调用notify方法后并不会让出锁，而必须等待同步代码块执行完毕之后再让出**，可以看到执行结果中Thread2的开始和结束是成对挨着出现的。\n\n# 总结\n这三个函数的相互通信可以做很多事情，比如常见的生产者-消费者模式，生产者要往队列里面生产东西，就必须等待队列有空间，同样的，消费者要同队列里面消费东西，就必须等待队列里有东西。使用wait,notify,notifyAll方法可以协调生产者和消费者之间的行为。在JDK1.4之后出现了一个Condition类，这个类也能够实现相同的功能，并且一般建议使用Condition替代wait,notify,notifyAll家族，实现更安全的线程间通信功能，比如ArrayBlockingQueue就是使用Condition实现阻塞队列的。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/23/wait-notify-notifyAll%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/](http://qifuguang.me/2015/10/23/wait-notify-notifyAll%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/)\n\n","source":"_posts/wait-notify-notifyAll详细介绍.md","raw":"title: 'wait,notify,notifyAll详细介绍'\ntags: [Java]\ncategories: [Java]\ndate: 2015-10-23 14:05:18\n---\n\n# 概述\nwait，notify和notifyAll方法是Object类的成员函数，所以Java的任何一个对象都能够调用这三个方法。这三个方法主要是用于线程间通信，协调多个线程的运行。\n\n<!--more-->\n# wait函数\n调用线程的sleep，yield方法时，线程并不会让出对象锁，wait却不同。\n\n**wait函数必须在同步代码块中调用(也就是当前线程必须持有对象的锁)**，他的功能是这样的：\n\n>我累了，休息一会儿，对象的锁你们拿去用吧，CPU也给你们。\n\n\n调用了wait函数的线程会一直等待，直到有其他线程调用了同一个对象的notify或者notifyAll方法才能被唤醒，需要注意的是：被唤醒并不代表立即获得对象的锁。也就是说，一个线程调用了对象的wait方法后，他需要等待两件事情的发生：\n\n1. 有其他线程调用同一个对象的notify或者notifyAll方法（调用notify/notifyAll方法之前）\n2. 被唤醒之后重新获得对象的锁(调用notify/notifyAll方法之后)\n\n才能继续往下执行后续动作。\n\n如果一个线程调用了某个对象的wait方法，但是后续并没有其他线程调用该对象的notify或者notifyAll方法，则该线程将会永远等下去...\n\n# notify和notifyAll方法\n**notofy/notifyAll方法也必须在同步代码块中调用(也就是调用线程必须持有对象的锁)**，他们的功能是这样的：\n\n> 女士们，先生们请注意，锁的对象我即将用完，请大家醒醒，准备一下，马上你们就能使用锁了。\n\n\n不同的是，notify方法只会唤醒一个正在等待的线程(至于唤醒谁，不确定！)，而notifyAll方法会唤醒所有正在等待的线程。还有一点需要特别强调：**调用notify和notifyAll方法后，当前线程并不会立即放弃锁的持有权，而必须要等待当前同步代码块执行完才会让出锁。**\n\n如果一个对象之前没有调用wait方法，那么调用notify方法是没有任何影响的。\n\n# 小试牛刀\n下面我们举例子来巩固上面讲到的理论知识,下面的代码创建了两个线程，Thread1在同步代码块中调用wait，Thread2在同步代码块中调用notify：\n\n```\npackage com.winwill.test;\n\n/**\n * @author winwill2012\n * @date 15/8/14 16:37\n */\npublic class Test {\n    private static final Object lock = new Object();\n\n    public static void main(String[] args) {\n        new Thread(new Thread1()).start();\n        new Thread(new Thread2()).start();\n    }\n\n    static class Thread1 implements Runnable {\n\n        @Override\n        public void run() {\n            System.out.println(\"Thread1 start...\");\n            synchronized (lock) {\n                try {\n                    lock.wait();\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n            System.out.println(\"Thread1 stop...\");\n        }\n    }\n\n    static class Thread2 implements Runnable {\n\n        @Override\n        public void run() {\n            System.out.println(\"Thread2 start...\");\n            synchronized (lock) {\n                lock.notify();\n                System.out.println(\"Thread2 stop...\");\n            }\n        }\n    }\n}\n\n```\n运行结果如下：\n>Thread1 start...  \nThread2 start...  \nThread2 stop...  \nThread1 stop...  \n\n从上面的例子可以证实上面说到的一个结论：**线程调用notify方法后并不会让出锁，而必须等待同步代码块执行完毕之后再让出**，可以看到执行结果中Thread2的开始和结束是成对挨着出现的。\n\n# 总结\n这三个函数的相互通信可以做很多事情，比如常见的生产者-消费者模式，生产者要往队列里面生产东西，就必须等待队列有空间，同样的，消费者要同队列里面消费东西，就必须等待队列里有东西。使用wait,notify,notifyAll方法可以协调生产者和消费者之间的行为。在JDK1.4之后出现了一个Condition类，这个类也能够实现相同的功能，并且一般建议使用Condition替代wait,notify,notifyAll家族，实现更安全的线程间通信功能，比如ArrayBlockingQueue就是使用Condition实现阻塞队列的。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/23/wait-notify-notifyAll%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/](http://qifuguang.me/2015/10/23/wait-notify-notifyAll%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/)\n\n","slug":"wait-notify-notifyAll详细介绍","published":1,"updated":"2015-10-23T06:10:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dov9y000elo6bqcr74kwf"},{"title":"sed命令详解","date":"2015-09-21T15:16:16.000Z","_content":"\n# 概述\nsed是stream editor的简称，也就是流编辑器。它一次处理一行内容，处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。\n\n<!--more-->\n\n# 使用语法\nsed命令的使用规则是这样的：\n\n```\nsed [option] 'command' input_file\n```\n\n其中option是可选的，常用的option有如下几种：\n\n * **-n** 使用安静(silent)模式（想不通为什么不是-s）。在一般sed的用法中，所有来自stdin的内容一般都会被列出到屏幕上。但如果加上-n参数后，则只有经过sed特殊处理的那一行(或者动作)才会被列出来；\n * **-e** 直接在指令列模式上进行 sed 的动作编辑；\n * **-f** 直接将 sed 的动作写在一个文件内， `-f filename` 则可以执行filename内的sed命令；\n * **-r** 让sed命令支持扩展的正则表达式(默认是基础正则表达式)；\n * **-i** 直接修改读取的文件内容，而不是由屏幕输出。\n \n 常用的命令有以下几种：\n \n * **a \\\\：** append即追加字符串， a \\的后面跟上字符串s(多行字符串可以用\\n分隔)，则会在当前选择的行的后面都加上字符串s；\n * **c \\\\：** 取代/替换字符串，c \\后面跟上字符串s(多行字符串可以用\\n分隔)，则会将当前选中的行替换成字符串s；\n * **d：** delete即删除，该命令会将当前选中的行删除；\n * **i \\\\：** insert即插入字符串，i \\后面跟上字符串s(多行字符串可以用\\n分隔)，则会在当前选中的行的前面都插入字符串s；\n * **p：** print即打印，该命令会打印当前选择的行到屏幕上；\n * **s：** 替换，通常s命令的用法是这样的：`1，2s/old/new/g`，将old字符串替换成new字符串\n \n \n# 命令示例\n假设有一个本地文件test.txt，文件内容如下：\n>[qifuguang@winwill~]$ cat test.txt  \nthis is first line  \nthis is second line  \nthis is third line  \nthis is fourth line  \nthis fifth line  \nhappy everyday  \nend  \n\n本节将使用该文件详细演示每一个命令的用法。\n## a命令\n```\n[qifuguang@winwill~]$ sed '1a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例命令部分中的1表示第一行，同样的第二行写成2，第一行到第三行写成`1,3`，用`$`表示最后一行，比如`2,$`表示第二行到最后一行中间所有的行(包含第二行和最后一行)。\n本例的作用是在第一行之后增加字符串\"add one\"，从输出可以看到具体效果。\n\n```\n[qifuguang@winwill~]$ sed '1,$a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nadd one\nthis is third line\nadd one\nthis is fourth line\nadd one\nthis is fifth line\nadd one\nhappy everyday\nadd one\nend\nadd one\n```\n本例表示在第一行和最后一行所有的行后面都加上\"add one\"字符串，从输出可以看到效果。\n\n```\n[qifuguang@winwill~]$ sed '/first/a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例表示在包含\"first\"字符串的行的后面加上字符串\"add one\"，从输出可以看到第一行包含first，所以第一行之后增加了\"add one\"\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/a \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nadd one\nend\n```\n本例使用正则表达式匹配行，`^ha.*day$`表示以ha开头，以day结尾的行，则可以匹配到文件的\"happy everyday\"这样，所以在该行后面增加了\"add one\"字符串。\n\n## i命令\ni命令使用方法和a命令一样的，只不过是在匹配的行的前面插入字符串，所以直接将上面a命令的示例的a替换成i即可，在此就不啰嗦了。\n\n\n## c命令\n\n```\n[qifuguang@winwill~]$ sed '$c \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is     fifth line\nhappy everyday\nadd one\n```\n本例表示将最后一行替换成字符串\"add one\"，从输出可以看到效果。\n\n```\n[qifuguang@winwill~]$ sed '4,$c \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nadd one\n```\n本例将第四行到最后一行的内容替换成字符串\"add one\"。\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/c \\replace line' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nreplace line\nend\n```\n本例将以ha开头，以day结尾的行替换成\"replace line\"。\n\n## d命令\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/d' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nend\n```\n本例删除以ha开头，以day结尾的行。\n\n```\n[qifuguang@winwill~]$ sed '4,$d' test.txt\nthis is first line\nthis is second line\nthis is third line\n```\n本例删除第四行到最后一行中的内容。\n\n## p命令\n\n```\n[qifuguang@winwill~]$ sed -n '4,$p' test.txt\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例在屏幕上打印第四行到最后一行的内容，p命令一般和-n选项一起使用。\n\n```\n[qifuguang@winwill~]$ sed -n '/^ha.*day$/p' test.txt\nhappy everyday\n```\n本例打印以ha开始，以day结尾的行。\n\n## s命令\n实际运用中s命令式最常使用到的。\n\n```\n[qifuguang@winwill~]$ sed 's/line/text/g' test.txt\nthis is first text\nthis is second text\nthis is third text\nthis is fourth text\nthis is fifth text\nhappy everyday\nend\n```\n本例将文件中的所有line替换成text，最后的g是global的意思，也就是全局替换，如果不加g，则只会替换本行的第一个line。\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/s/happy/very happy/g' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nvery happy everyday\nend\n```\n本例首先匹配以ha开始，以day结尾的行，本例中匹配到的行是\"happy everyday\"这样，然后再将该行中的happy替换成very happy。\n\n```\n[qifuguang@winwill~]$ sed 's/\\(.*\\)line$/\\1/g' test.txt\nthis is first\nthis is second\nthis is third\nthis is fourth\nthis is fifth\nhappy everyday\nend\n```\n这个例子有点复杂，先分解一下。首先s命令的模式是`s/old/new/g`这样的，所以本例的old部分即`\\(.*\\)line$`,sed命令中使用`\\(\\)`包裹的内容表示正则表达式的第n部分，序号从1开始计算，本例中只有一个`\\(\\)`所以`\\(.*\\)`表示正则表达式的第一部分，这部分匹配任意字符串，所以`\\(.*\\)line$`匹配的就是以line结尾的任何行。然后将匹配到的行替换成正则表达式的第一部分（本例中相当于删除line部分），使用`\\1`表示匹配到的第一部分，同样`\\2`表示第二部分，`\\3`表示第三部分，可以依次这样引用。比如下面的例子：\n\n```\n[qifuguang@winwill~]$ sed 's/\\(.*\\)is\\(.*\\)line/\\1\\2/g' test.txt\nthis  first\nthis  second\nthis  third\nthis  fourth\nthis  fifth\nhappy everyday\nend\n```\n正则表达式中`is`两边的部分可以用`\\1`和`\\2`表示，该例子的作用其实就是删除中间部分的is。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/21/sed命令详解/](http://qifuguang.me/2015/09/21/sed命令详解/)\n\n","source":"_posts/sed命令详解.md","raw":"title: sed命令详解\ntags: [linux shell]\ncategories: [linux shell]\ndate: 2015-09-21 23:16:16\n---\n\n# 概述\nsed是stream editor的简称，也就是流编辑器。它一次处理一行内容，处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。\n\n<!--more-->\n\n# 使用语法\nsed命令的使用规则是这样的：\n\n```\nsed [option] 'command' input_file\n```\n\n其中option是可选的，常用的option有如下几种：\n\n * **-n** 使用安静(silent)模式（想不通为什么不是-s）。在一般sed的用法中，所有来自stdin的内容一般都会被列出到屏幕上。但如果加上-n参数后，则只有经过sed特殊处理的那一行(或者动作)才会被列出来；\n * **-e** 直接在指令列模式上进行 sed 的动作编辑；\n * **-f** 直接将 sed 的动作写在一个文件内， `-f filename` 则可以执行filename内的sed命令；\n * **-r** 让sed命令支持扩展的正则表达式(默认是基础正则表达式)；\n * **-i** 直接修改读取的文件内容，而不是由屏幕输出。\n \n 常用的命令有以下几种：\n \n * **a \\\\：** append即追加字符串， a \\的后面跟上字符串s(多行字符串可以用\\n分隔)，则会在当前选择的行的后面都加上字符串s；\n * **c \\\\：** 取代/替换字符串，c \\后面跟上字符串s(多行字符串可以用\\n分隔)，则会将当前选中的行替换成字符串s；\n * **d：** delete即删除，该命令会将当前选中的行删除；\n * **i \\\\：** insert即插入字符串，i \\后面跟上字符串s(多行字符串可以用\\n分隔)，则会在当前选中的行的前面都插入字符串s；\n * **p：** print即打印，该命令会打印当前选择的行到屏幕上；\n * **s：** 替换，通常s命令的用法是这样的：`1，2s/old/new/g`，将old字符串替换成new字符串\n \n \n# 命令示例\n假设有一个本地文件test.txt，文件内容如下：\n>[qifuguang@winwill~]$ cat test.txt  \nthis is first line  \nthis is second line  \nthis is third line  \nthis is fourth line  \nthis fifth line  \nhappy everyday  \nend  \n\n本节将使用该文件详细演示每一个命令的用法。\n## a命令\n```\n[qifuguang@winwill~]$ sed '1a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例命令部分中的1表示第一行，同样的第二行写成2，第一行到第三行写成`1,3`，用`$`表示最后一行，比如`2,$`表示第二行到最后一行中间所有的行(包含第二行和最后一行)。\n本例的作用是在第一行之后增加字符串\"add one\"，从输出可以看到具体效果。\n\n```\n[qifuguang@winwill~]$ sed '1,$a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nadd one\nthis is third line\nadd one\nthis is fourth line\nadd one\nthis is fifth line\nadd one\nhappy everyday\nadd one\nend\nadd one\n```\n本例表示在第一行和最后一行所有的行后面都加上\"add one\"字符串，从输出可以看到效果。\n\n```\n[qifuguang@winwill~]$ sed '/first/a \\add one' test.txt\nthis is first line\nadd one\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例表示在包含\"first\"字符串的行的后面加上字符串\"add one\"，从输出可以看到第一行包含first，所以第一行之后增加了\"add one\"\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/a \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nhappy everyday\nadd one\nend\n```\n本例使用正则表达式匹配行，`^ha.*day$`表示以ha开头，以day结尾的行，则可以匹配到文件的\"happy everyday\"这样，所以在该行后面增加了\"add one\"字符串。\n\n## i命令\ni命令使用方法和a命令一样的，只不过是在匹配的行的前面插入字符串，所以直接将上面a命令的示例的a替换成i即可，在此就不啰嗦了。\n\n\n## c命令\n\n```\n[qifuguang@winwill~]$ sed '$c \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is     fifth line\nhappy everyday\nadd one\n```\n本例表示将最后一行替换成字符串\"add one\"，从输出可以看到效果。\n\n```\n[qifuguang@winwill~]$ sed '4,$c \\add one' test.txt\nthis is first line\nthis is second line\nthis is third line\nadd one\n```\n本例将第四行到最后一行的内容替换成字符串\"add one\"。\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/c \\replace line' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nreplace line\nend\n```\n本例将以ha开头，以day结尾的行替换成\"replace line\"。\n\n## d命令\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/d' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nend\n```\n本例删除以ha开头，以day结尾的行。\n\n```\n[qifuguang@winwill~]$ sed '4,$d' test.txt\nthis is first line\nthis is second line\nthis is third line\n```\n本例删除第四行到最后一行中的内容。\n\n## p命令\n\n```\n[qifuguang@winwill~]$ sed -n '4,$p' test.txt\nthis is fourth line\nthis is fifth line\nhappy everyday\nend\n```\n本例在屏幕上打印第四行到最后一行的内容，p命令一般和-n选项一起使用。\n\n```\n[qifuguang@winwill~]$ sed -n '/^ha.*day$/p' test.txt\nhappy everyday\n```\n本例打印以ha开始，以day结尾的行。\n\n## s命令\n实际运用中s命令式最常使用到的。\n\n```\n[qifuguang@winwill~]$ sed 's/line/text/g' test.txt\nthis is first text\nthis is second text\nthis is third text\nthis is fourth text\nthis is fifth text\nhappy everyday\nend\n```\n本例将文件中的所有line替换成text，最后的g是global的意思，也就是全局替换，如果不加g，则只会替换本行的第一个line。\n\n```\n[qifuguang@winwill~]$ sed '/^ha.*day$/s/happy/very happy/g' test.txt\nthis is first line\nthis is second line\nthis is third line\nthis is fourth line\nthis is fifth line\nvery happy everyday\nend\n```\n本例首先匹配以ha开始，以day结尾的行，本例中匹配到的行是\"happy everyday\"这样，然后再将该行中的happy替换成very happy。\n\n```\n[qifuguang@winwill~]$ sed 's/\\(.*\\)line$/\\1/g' test.txt\nthis is first\nthis is second\nthis is third\nthis is fourth\nthis is fifth\nhappy everyday\nend\n```\n这个例子有点复杂，先分解一下。首先s命令的模式是`s/old/new/g`这样的，所以本例的old部分即`\\(.*\\)line$`,sed命令中使用`\\(\\)`包裹的内容表示正则表达式的第n部分，序号从1开始计算，本例中只有一个`\\(\\)`所以`\\(.*\\)`表示正则表达式的第一部分，这部分匹配任意字符串，所以`\\(.*\\)line$`匹配的就是以line结尾的任何行。然后将匹配到的行替换成正则表达式的第一部分（本例中相当于删除line部分），使用`\\1`表示匹配到的第一部分，同样`\\2`表示第二部分，`\\3`表示第三部分，可以依次这样引用。比如下面的例子：\n\n```\n[qifuguang@winwill~]$ sed 's/\\(.*\\)is\\(.*\\)line/\\1\\2/g' test.txt\nthis  first\nthis  second\nthis  third\nthis  fourth\nthis  fifth\nhappy everyday\nend\n```\n正则表达式中`is`两边的部分可以用`\\1`和`\\2`表示，该例子的作用其实就是删除中间部分的is。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/21/sed命令详解/](http://qifuguang.me/2015/09/21/sed命令详解/)\n\n","slug":"sed命令详解","published":1,"updated":"2015-09-21T15:27:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dova0000jlo6bqnduy1ug"},{"title":"[日志处理]slf4j的优势与使用原理","date":"2015-08-26T14:39:41.000Z","_content":"# 概述\nslf4j的全称是Simple Loging Facade For Java，即它仅仅是一个为Java程序提供日志输出的统一接口，并不是一个具体的日志实现方案，就比如JDBC一样，只是一种规则而已。所以单独的slf4j是不能工作的，必须搭配其他具体的日志实现方案，比如apache的**org.apache.log4j.Logger**，jdk自带的**java.util.logging.Logger**等等。\n<!--more-->\n\n# slf4j的优势\n知道什么是slf4j之后我们应该明白为什么要使用slf4j，为什么不适用具体的日志实现方案。笔者理解，slf4j主要有以下几点优势：\n## 与客户端解耦  \n想象一下下面的场景：\n\n> 有一个别人写的很棒的类库，里面使用的是jdk自带的java.util.logging.Logger这个日志系统，现在你有一个程序需要用到这个类库，并且你自己的程序现在是使用apache的org.apache.log4j.Logger这个日志系统。那么问题来了，如果你的程序导入了这个类库，那么是不是必须两种日志系统都要支持，那么你是不是需要多配置一些东西，多维护一些东西？耗费了太多维护成本，你想死的心都有了吧？\n\n有问题就要有解决方案，不错，解决方案就是：**使用slf4j**。\n\nslf4j只是一种接口，它本身并不关心你底层使用的是什么日志实现方案，所以它支持各种日志实现方案。简单的说，只要我们在类库中使用slf4j打日志，那么底层使用什么日志实现方案是使用者决定的，怎么决定？依靠配置文件和jar库。\n\n## 省内存\n如果大家之前使用过log4j，那么一定基本都是这样用的：\n\n```\npackage com.winwill.test;\n\nimport org.apache.log4j.Logger;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = Logger.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        LOGGER.info(\"This is a test message: \" + message);\n    }\n}\n```\n注意到log4j的info函数有两种使用方式：\n\n```\npublic void info(Object message)\npublic void info(Object message, Throwable t)\n```\n第一个参数是要输出的信息，假设要输出的是一个字符串，并且字符串中包含变量，则message参数就必须使用字符串相加操作，就比如上面测试代码的14行一样。姑且不说字符串相加是一个比较消耗性能的操作，字符串是一个不可变对象，一旦创建就不能被修改，创建的字符串会保存在String池中，占用内存。更糟糕的是如果配置文件中配置的日志级别是ERROR的话，这行info日志根本不会输出，则相加得到的字符串对象是一个非必须对象，白白浪费了内存空间。有人会说了，那我可以这样写啊：\n\n```\npackage com.winwill.test;\n\nimport org.apache.log4j.Logger;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = Logger.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        if (LOGGER.isInfoEnabled()) {\n            LOGGER.info(\"This is a test message: \" + message);\n        }\n    }\n}\n```\n这样不就解决了白白浪费内存的问题了吗？没错，这是一个变通方案，但是这样的代码太繁琐，不直观！\n\n再来看看slf4j的打日志的方式：\n\n```\npackage com.winwill.test;\n\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = LoggerFactory.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        LOGGER.info(\"This is a test message: {}\", message);\n    }\n}\n```\n看到没有，打日志的时候使用了{}占位符，这样就不会有字符串拼接操作，减少了无用String对象的数量，节省了内存。并且，记住，在生产最终日志信息的字符串之前，这个方法会检查一个特定的日志级别是不是打开了，这不仅降低了内存消耗而且预先降低了CPU去处理字符串连接命令的时间。这里是使用SLF4J日志方法的代码，来自于slf4j-log4j12-1.6.1.jar中的Log4j的适配器类Log4jLoggerAdapter。\n\n```\npublic void debug(String format, Object arg1, Object arg2) {\n    if (logger.isDebugEnabled()) {\n        FormattingTuple ft = MessageFormatter.format(format, arg1, arg2);\n        logger.log(FQCN, Level.DEBUG, ft.getMessage(), ft.getThrowable());\n    }\n}\n```\n\n# slf4j的使用与绑定原理\n前面介绍了slf4j的优势，本节介绍怎么使用slf4j以及其中的原理，前文说到了，单独的slf4j是不能工作的，必须带上其他具体的日志实现方案。就以apache的log4j作为具体日志实现方案为例，如果在工程中要使用slf4j作为接口，并且要用log4j作为具体实现方案，那么我们需要做的事情如下：（下面的xxx表示具体版本号）\n\n* 将slf4j-api-xxx.jar加入工程classpath中；\n* 将slf4j-log4jxx-xxx.jar加入工程classpath中；\n* 将log4j-xxx.jar加入工程classpath中；\n* 将log4j.properties（log4j.xml）文件加入工程classpath中。\n\n介绍一下工作原理：\n\n首先，slf4j-api作为slf4j的接口类，使用在程序代码中，这个包提供了一个Logger类和LoggerFactory类，Logger类用来打日志，LoggerFactory类用来获取Logger；slf4j-log4j是连接slf4j和log4j的桥梁，怎么连接的呢？我们看看slf4j的LoggerFactory类的getLogger函数的源码：\n\n```\n  /**\n   * Return a logger named corresponding to the class passed as parameter, using\n   * the statically bound {@link ILoggerFactory} instance.\n   *\n   * @param clazz the returned logger will be named after clazz\n   * @return logger\n   */\n  public static Logger getLogger(Class clazz) {\n    return getLogger(clazz.getName());\n  }\n  /**\n   * Return a logger named according to the name parameter using the statically\n   * bound {@link ILoggerFactory} instance.\n   *\n   * @param name The name of the logger.\n   * @return logger\n   */\n  public static Logger getLogger(String name) {\n    ILoggerFactory iLoggerFactory = getILoggerFactory();\n    return iLoggerFactory.getLogger(name);\n  }\n  \n    public static ILoggerFactory getILoggerFactory() {\n    if (INITIALIZATION_STATE == UNINITIALIZED) {\n      INITIALIZATION_STATE = ONGOING_INITIALIZATION;\n      performInitialization();\n    }\n    switch (INITIALIZATION_STATE) {\n      case SUCCESSFUL_INITIALIZATION:\n        return StaticLoggerBinder.getSingleton().getLoggerFactory();\n      case NOP_FALLBACK_INITIALIZATION:\n        return NOP_FALLBACK_FACTORY;\n      case FAILED_INITIALIZATION:\n        throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG);\n      case ONGOING_INITIALIZATION:\n        // support re-entrant behavior.\n        // See also http://bugzilla.slf4j.org/show_bug.cgi?id=106\n        return TEMP_FACTORY;\n    }\n    throw new IllegalStateException(\"Unreachable code\");\n  }\n```\n追踪到最后，发现LoggerFactory.getLogger()首先获取一个ILoggerFactory接口，然后使用该接口获取具体的Logger。获取ILoggerFactory的时候用到了一个StaticLoggerBinder类，仔细研究我们会发现StaticLoggerBinder这个类并不是slf4j-api这个包中的类，而是slf4j-log4j包中的类，这个类就是一个中间类，它用来将抽象的slf4j变成具体的log4j，也就是说具体要使用什么样的日志实现方案，就得靠这个StaticLoggerBinder类。再看看slf4j-log4j包种的这个StaticLoggerBinder类创建ILoggerFactory长什么样子：\n\n```\n  private final ILoggerFactory loggerFactory;\n\n  private StaticLoggerBinder() {\n    loggerFactory = new Log4jLoggerFactory();\n    try {\n      Level level = Level.TRACE;\n    } catch (NoSuchFieldError nsfe) {\n      Util\n          .report(\"This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version\");\n    }\n  }\n\n  public ILoggerFactory getLoggerFactory() {\n    return loggerFactory;\n  }\n```\n可以看到slf4j-log4j中的StaticLoggerBinder类创建的ILoggerFactory其实是一个**org.slf4j.impl.Log4jLoggerFactory**，这个类的getLogger函数是这样的：\n\n```\n  public Logger getLogger(String name) {\n    Logger slf4jLogger = loggerMap.get(name);\n    if (slf4jLogger != null) {\n      return slf4jLogger;\n    } else {\n      org.apache.log4j.Logger log4jLogger;\n      if(name.equalsIgnoreCase(Logger.ROOT_LOGGER_NAME))\n        log4jLogger = LogManager.getRootLogger();\n      else\n        log4jLogger = LogManager.getLogger(name);\n\n      Logger newInstance = new Log4jLoggerAdapter(log4jLogger);\n      Logger oldInstance = loggerMap.putIfAbsent(name, newInstance);\n      return oldInstance == null ? newInstance : oldInstance;\n    }\n  }\n```\n就在其中创建了真正的**org.apache.log4j.Logger**，也就是我们需要的具体的日志实现方案的Logger类。就这样，整个绑定过程就完成了，没晕吧？log4j.properties(log4j.xml)的具体配置下一篇文章会详细介绍。\n\n \n","source":"_posts/[日志处理]slf4j的优势与使用原理.md","raw":"title: '[日志处理]slf4j的优势与使用原理'\ntags: [日志处理]\ncategories: [日志处理]\ndate: 2015-08-26 22:39:41\n---\n# 概述\nslf4j的全称是Simple Loging Facade For Java，即它仅仅是一个为Java程序提供日志输出的统一接口，并不是一个具体的日志实现方案，就比如JDBC一样，只是一种规则而已。所以单独的slf4j是不能工作的，必须搭配其他具体的日志实现方案，比如apache的**org.apache.log4j.Logger**，jdk自带的**java.util.logging.Logger**等等。\n<!--more-->\n\n# slf4j的优势\n知道什么是slf4j之后我们应该明白为什么要使用slf4j，为什么不适用具体的日志实现方案。笔者理解，slf4j主要有以下几点优势：\n## 与客户端解耦  \n想象一下下面的场景：\n\n> 有一个别人写的很棒的类库，里面使用的是jdk自带的java.util.logging.Logger这个日志系统，现在你有一个程序需要用到这个类库，并且你自己的程序现在是使用apache的org.apache.log4j.Logger这个日志系统。那么问题来了，如果你的程序导入了这个类库，那么是不是必须两种日志系统都要支持，那么你是不是需要多配置一些东西，多维护一些东西？耗费了太多维护成本，你想死的心都有了吧？\n\n有问题就要有解决方案，不错，解决方案就是：**使用slf4j**。\n\nslf4j只是一种接口，它本身并不关心你底层使用的是什么日志实现方案，所以它支持各种日志实现方案。简单的说，只要我们在类库中使用slf4j打日志，那么底层使用什么日志实现方案是使用者决定的，怎么决定？依靠配置文件和jar库。\n\n## 省内存\n如果大家之前使用过log4j，那么一定基本都是这样用的：\n\n```\npackage com.winwill.test;\n\nimport org.apache.log4j.Logger;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = Logger.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        LOGGER.info(\"This is a test message: \" + message);\n    }\n}\n```\n注意到log4j的info函数有两种使用方式：\n\n```\npublic void info(Object message)\npublic void info(Object message, Throwable t)\n```\n第一个参数是要输出的信息，假设要输出的是一个字符串，并且字符串中包含变量，则message参数就必须使用字符串相加操作，就比如上面测试代码的14行一样。姑且不说字符串相加是一个比较消耗性能的操作，字符串是一个不可变对象，一旦创建就不能被修改，创建的字符串会保存在String池中，占用内存。更糟糕的是如果配置文件中配置的日志级别是ERROR的话，这行info日志根本不会输出，则相加得到的字符串对象是一个非必须对象，白白浪费了内存空间。有人会说了，那我可以这样写啊：\n\n```\npackage com.winwill.test;\n\nimport org.apache.log4j.Logger;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = Logger.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        if (LOGGER.isInfoEnabled()) {\n            LOGGER.info(\"This is a test message: \" + message);\n        }\n    }\n}\n```\n这样不就解决了白白浪费内存的问题了吗？没错，这是一个变通方案，但是这样的代码太繁琐，不直观！\n\n再来看看slf4j的打日志的方式：\n\n```\npackage com.winwill.test;\n\n\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\n\n/**\n * @author qifuguang\n * @date 15/8/26 21:54\n */\npublic class TestLog4j {\n    private static final Logger LOGGER = LoggerFactory.getLogger(TestLog4j.class);\n\n    public static void main(String[] args) {\n        String message = \"Hello World.\";\n        LOGGER.info(\"This is a test message: {}\", message);\n    }\n}\n```\n看到没有，打日志的时候使用了{}占位符，这样就不会有字符串拼接操作，减少了无用String对象的数量，节省了内存。并且，记住，在生产最终日志信息的字符串之前，这个方法会检查一个特定的日志级别是不是打开了，这不仅降低了内存消耗而且预先降低了CPU去处理字符串连接命令的时间。这里是使用SLF4J日志方法的代码，来自于slf4j-log4j12-1.6.1.jar中的Log4j的适配器类Log4jLoggerAdapter。\n\n```\npublic void debug(String format, Object arg1, Object arg2) {\n    if (logger.isDebugEnabled()) {\n        FormattingTuple ft = MessageFormatter.format(format, arg1, arg2);\n        logger.log(FQCN, Level.DEBUG, ft.getMessage(), ft.getThrowable());\n    }\n}\n```\n\n# slf4j的使用与绑定原理\n前面介绍了slf4j的优势，本节介绍怎么使用slf4j以及其中的原理，前文说到了，单独的slf4j是不能工作的，必须带上其他具体的日志实现方案。就以apache的log4j作为具体日志实现方案为例，如果在工程中要使用slf4j作为接口，并且要用log4j作为具体实现方案，那么我们需要做的事情如下：（下面的xxx表示具体版本号）\n\n* 将slf4j-api-xxx.jar加入工程classpath中；\n* 将slf4j-log4jxx-xxx.jar加入工程classpath中；\n* 将log4j-xxx.jar加入工程classpath中；\n* 将log4j.properties（log4j.xml）文件加入工程classpath中。\n\n介绍一下工作原理：\n\n首先，slf4j-api作为slf4j的接口类，使用在程序代码中，这个包提供了一个Logger类和LoggerFactory类，Logger类用来打日志，LoggerFactory类用来获取Logger；slf4j-log4j是连接slf4j和log4j的桥梁，怎么连接的呢？我们看看slf4j的LoggerFactory类的getLogger函数的源码：\n\n```\n  /**\n   * Return a logger named corresponding to the class passed as parameter, using\n   * the statically bound {@link ILoggerFactory} instance.\n   *\n   * @param clazz the returned logger will be named after clazz\n   * @return logger\n   */\n  public static Logger getLogger(Class clazz) {\n    return getLogger(clazz.getName());\n  }\n  /**\n   * Return a logger named according to the name parameter using the statically\n   * bound {@link ILoggerFactory} instance.\n   *\n   * @param name The name of the logger.\n   * @return logger\n   */\n  public static Logger getLogger(String name) {\n    ILoggerFactory iLoggerFactory = getILoggerFactory();\n    return iLoggerFactory.getLogger(name);\n  }\n  \n    public static ILoggerFactory getILoggerFactory() {\n    if (INITIALIZATION_STATE == UNINITIALIZED) {\n      INITIALIZATION_STATE = ONGOING_INITIALIZATION;\n      performInitialization();\n    }\n    switch (INITIALIZATION_STATE) {\n      case SUCCESSFUL_INITIALIZATION:\n        return StaticLoggerBinder.getSingleton().getLoggerFactory();\n      case NOP_FALLBACK_INITIALIZATION:\n        return NOP_FALLBACK_FACTORY;\n      case FAILED_INITIALIZATION:\n        throw new IllegalStateException(UNSUCCESSFUL_INIT_MSG);\n      case ONGOING_INITIALIZATION:\n        // support re-entrant behavior.\n        // See also http://bugzilla.slf4j.org/show_bug.cgi?id=106\n        return TEMP_FACTORY;\n    }\n    throw new IllegalStateException(\"Unreachable code\");\n  }\n```\n追踪到最后，发现LoggerFactory.getLogger()首先获取一个ILoggerFactory接口，然后使用该接口获取具体的Logger。获取ILoggerFactory的时候用到了一个StaticLoggerBinder类，仔细研究我们会发现StaticLoggerBinder这个类并不是slf4j-api这个包中的类，而是slf4j-log4j包中的类，这个类就是一个中间类，它用来将抽象的slf4j变成具体的log4j，也就是说具体要使用什么样的日志实现方案，就得靠这个StaticLoggerBinder类。再看看slf4j-log4j包种的这个StaticLoggerBinder类创建ILoggerFactory长什么样子：\n\n```\n  private final ILoggerFactory loggerFactory;\n\n  private StaticLoggerBinder() {\n    loggerFactory = new Log4jLoggerFactory();\n    try {\n      Level level = Level.TRACE;\n    } catch (NoSuchFieldError nsfe) {\n      Util\n          .report(\"This version of SLF4J requires log4j version 1.2.12 or later. See also http://www.slf4j.org/codes.html#log4j_version\");\n    }\n  }\n\n  public ILoggerFactory getLoggerFactory() {\n    return loggerFactory;\n  }\n```\n可以看到slf4j-log4j中的StaticLoggerBinder类创建的ILoggerFactory其实是一个**org.slf4j.impl.Log4jLoggerFactory**，这个类的getLogger函数是这样的：\n\n```\n  public Logger getLogger(String name) {\n    Logger slf4jLogger = loggerMap.get(name);\n    if (slf4jLogger != null) {\n      return slf4jLogger;\n    } else {\n      org.apache.log4j.Logger log4jLogger;\n      if(name.equalsIgnoreCase(Logger.ROOT_LOGGER_NAME))\n        log4jLogger = LogManager.getRootLogger();\n      else\n        log4jLogger = LogManager.getLogger(name);\n\n      Logger newInstance = new Log4jLoggerAdapter(log4jLogger);\n      Logger oldInstance = loggerMap.putIfAbsent(name, newInstance);\n      return oldInstance == null ? newInstance : oldInstance;\n    }\n  }\n```\n就在其中创建了真正的**org.apache.log4j.Logger**，也就是我们需要的具体的日志实现方案的Logger类。就这样，整个绑定过程就完成了，没晕吧？log4j.properties(log4j.xml)的具体配置下一篇文章会详细介绍。\n\n \n","slug":"[日志处理]slf4j的优势与使用原理","published":1,"updated":"2015-08-26T14:42:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dova2000olo6bf6ab9nvl"},{"title":"[日志处理]log4j配置详解","date":"2015-08-30T16:14:26.000Z","_content":"# 概述\nLog4j有三个主要的组件：Loggers(记录器)，Appenders (输出源)和Layouts(布局)。这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。\n\n<!--more-->\n## Logger\nLoggers组件被分为五个级别：\n\n* DEBUG\n* INFO\n* WARN\n* ERROR\n* FATAL  \n\n各个级别的顺序是这样那个的：\n> **DEBUG < INFO < WARN < ERROR < FATAL**\n\n可以简单地理解为级别越大越重要。  \nLog4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。\n\n## Appender\nAppender用来规定日志输出的目的地是哪里，可以是控制台，文件，数据库等等。  \n常见的Appender有以下几种：\n\n* org.apache.log4j.ConsoleAppender（控制台）\n* org.apache.log4j.FileAppender（文件）\n* org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）\n* org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）\n* org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）\n\n在配置文件中是这样配置的：\n\n>log4j.appender.appenderName = className  \nlog4j.appender.appenderName.Option1 = value1  \n…  \nlog4j.appender.appenderName.OptionN = valueN  \n\n其中appenderName是Appender的名字，可以随意起，只要满足命名规范就行，Option1，Option2，...，OptionN是这个appender的各种属性。\n\n## Layout\nLayout用来规定日志是以什么样的格式输出，需要输出哪些信息。Layout提供四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式。  \n常见的Layout如下：\n\n* org.apache.log4j.HTMLLayout（以HTML表格形式布局）\n* org.apache.log4j.PatternLayout（可以灵活地指定布局模式）\n* org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）\n* org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息）\n\n在配置文件中这样配置的：\n\n> log4j.appender.appenderName.layout =className  \nlog4j.appender.appenderName.layout.Option1 = value1  \n…  \nlog4j.appender.appenderName.layout.OptionN = valueN  \n\n含义和Appender的配置是一样的，就不另作解释了。\n\n## 配置详解\n在实际应用中，要使Log4j在系统中运行须事先设定配置文件。配置文件事实上也就是对Logger、Appender及Layout进行相应设定。 Log4j支持两种配置文件格式，一种是XML格式的文件，一种是properties属性文件。下面以properties属性文件为例介绍。\n\n\n### 配置Logger\n> log4j.rootLogger = [ level ] , appenderName1, appenderName2, …  \nlog4j.additivity.org.apache=false # 表示Logger不会在父Logger的appender里输出，默认为true。  \n\n**level** ：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。  \n**appenderName**：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。\n例如：log4j.rootLogger＝INFO,A1,B2,C3\n\n### 配置Appender\n> log4j.appender.appenderName = className\n\n**appenderName**: Appender的名字，自定义，在log4j.rootLogger设置中使用；  \n**className**：Appender的类的全名（包含包名），常用的Appender的className如下：\n\n* org.apache.log4j.ConsoleAppender（控制台）\n* org.apache.log4j.FileAppender（文件）\n* org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）\n* org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）\n* org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）\n\n#### ConsoleAppender的选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Target**=System.err：默认值是System.out。\n\n#### FileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中\n\n#### DailyRollingFileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。\n* **DatePattern**='.'yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。\n另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下：\n  * '.'yyyy-MM：每月\n  * '.'yyyy-ww：每周\n  * '.'yyyy-MM-dd：每天\n  * '.'yyyy-MM-dd-a：每天两次\n  * '.'yyyy-MM-dd-HH：每小时\n  * '.'yyyy-MM-dd-HH-mm：每分钟\n  \n#### RollingFileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。\n* **MaxFileSize=100KB：后缀可以是**KB, MB 或者GB**。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。\n* **MaxBackupIndex**=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。\n\n\n### 配置Layout\n> log4j.appender.appenderName.layout=className\n\n常见的className如下：\n\n* org.apache.log4j.HTMLLayout（以HTML表格形式布局）\n* org.apache.log4j.PatternLayout（可以灵活地指定布局模式）\n* org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）\n* org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）\n\n#### HTMLLayout选项\n\n* **LocationInfo**=true：输出java文件名称和行号，默认值是false。\n* **Title**=My Logging： 默认值是Log4J Log Messages。\n\n#### PatternLayout选项\n\n* **ConversionPattern**=%m%n：设定以怎样的格式显示消息。\n\n各种格式化说明如下：\n\n1. %p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。\n2. %d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d{yyyy/MM/dd HH:mm:ss,SSS}。\n3. %r：输出自应用程序启动到输出该log信息耗费的毫秒数。\n4. %t：输出产生该日志事件的线程名。\n5. %l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。\n6. %c：输出日志信息所属的类目，通常就是所在类的全名。\n7. %M：输出产生日志信息的方法名。\n8. %F：输出日志消息产生时所在的文件名称。\n9. %L:：输出代码中的行号。\n10. %m:：输出代码中指定的具体日志信息。\n11. %n：输出一个回车换行符，Windows平台为\"\\r\\n\"，Unix平台为\"\\n\"。\n12. %x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。\n13. %%：输出一个\"%\"字符。\n\n另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如：\n\n* c：指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。\n* %-20c：\"-\"号表示左对齐。\n* %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。\n\n\n## log4j的默认配置\nlog4j配置支持xml和properties两种格式的文件，默认先在程序的classpath目录下检查是否有log4j.xml文件，如果没有再出招log4j.properties文件。  \nlog4j的包中的LogManager类在加载的时候有个静态代码块是这样写的：\n\n\n```\nstatic {\n    // By default we use a DefaultRepositorySelector which always returns 'h'.\n    Hierarchy h = new Hierarchy(new RootLogger((Level) Level.DEBUG));\n    repositorySelector = new DefaultRepositorySelector(h);\n\n    /** Search for the properties file log4j.properties in the CLASSPATH.  */\n    String override =OptionConverter.getSystemProperty(DEFAULT_INIT_OVERRIDE_KEY,\n                               null);\n\n    // if there is no default init override, then get the resource\n    // specified by the user or the default config file.\n    if(override == null || \"false\".equalsIgnoreCase(override)) {\n\n      String configurationOptionStr = OptionConverter.getSystemProperty(\n                              DEFAULT_CONFIGURATION_KEY, \n                              null);\n\n      String configuratorClassName = OptionConverter.getSystemProperty(\n                                                   CONFIGURATOR_CLASS_KEY, \n                           null);\n\n      URL url = null;\n\n      // if the user has not specified the log4j.configuration\n      // property, we search first for the file \"log4j.xml\" and then\n      // \"log4j.properties\"\n      if(configurationOptionStr == null) {  \n    url = Loader.getResource(DEFAULT_XML_CONFIGURATION_FILE);\n    if(url == null) {\n      url = Loader.getResource(DEFAULT_CONFIGURATION_FILE);\n    }\n      } else {\n    try {\n      url = new URL(configurationOptionStr);\n    } catch (MalformedURLException ex) {\n      // so, resource is not a URL:\n      // attempt to get the resource from the class path\n      url = Loader.getResource(configurationOptionStr); \n    }   \n      }\n      \n      // If we have a non-null url, then delegate the rest of the\n      // configuration to the OptionConverter.selectAndConfigure\n      // method.\n      if(url != null) {\n    LogLog.debug(\"Using URL [\"+url+\"] for automatic log4j configuration.\");      \n    OptionConverter.selectAndConfigure(url, configuratorClassName, \n                       LogManager.getLoggerRepository());\n      } else {\n    LogLog.debug(\"Could not find resource: [\"+configurationOptionStr+\"].\");\n      }\n    }  \n  }\n```\n","source":"_posts/[日志处理]log4j配置详解.md","raw":"title: '[日志处理]log4j配置详解'\ntags: [日志处理]\ncategories: [日志处理]\ndate: 2015-08-31 00:14:26\n---\n# 概述\nLog4j有三个主要的组件：Loggers(记录器)，Appenders (输出源)和Layouts(布局)。这里可简单理解为日志类别，日志要输出的地方和日志以何种形式输出。综合使用这三个组件可以轻松地记录信息的类型和级别，并可以在运行时控制日志输出的样式和位置。\n\n<!--more-->\n## Logger\nLoggers组件被分为五个级别：\n\n* DEBUG\n* INFO\n* WARN\n* ERROR\n* FATAL  \n\n各个级别的顺序是这样那个的：\n> **DEBUG < INFO < WARN < ERROR < FATAL**\n\n可以简单地理解为级别越大越重要。  \nLog4j有一个规则：只输出级别不低于设定级别的日志信息，假设Loggers级别设定为INFO，则INFO、WARN、ERROR和FATAL级别的日志信息都会输出，而级别比INFO低的DEBUG则不会输出。\n\n## Appender\nAppender用来规定日志输出的目的地是哪里，可以是控制台，文件，数据库等等。  \n常见的Appender有以下几种：\n\n* org.apache.log4j.ConsoleAppender（控制台）\n* org.apache.log4j.FileAppender（文件）\n* org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）\n* org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）\n* org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）\n\n在配置文件中是这样配置的：\n\n>log4j.appender.appenderName = className  \nlog4j.appender.appenderName.Option1 = value1  \n…  \nlog4j.appender.appenderName.OptionN = valueN  \n\n其中appenderName是Appender的名字，可以随意起，只要满足命名规范就行，Option1，Option2，...，OptionN是这个appender的各种属性。\n\n## Layout\nLayout用来规定日志是以什么样的格式输出，需要输出哪些信息。Layout提供四种日志输出样式，如根据HTML样式、自由指定样式、包含日志级别与信息的样式和包含日志时间、线程、类别等信息的样式。  \n常见的Layout如下：\n\n* org.apache.log4j.HTMLLayout（以HTML表格形式布局）\n* org.apache.log4j.PatternLayout（可以灵活地指定布局模式）\n* org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）\n* org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等信息）\n\n在配置文件中这样配置的：\n\n> log4j.appender.appenderName.layout =className  \nlog4j.appender.appenderName.layout.Option1 = value1  \n…  \nlog4j.appender.appenderName.layout.OptionN = valueN  \n\n含义和Appender的配置是一样的，就不另作解释了。\n\n## 配置详解\n在实际应用中，要使Log4j在系统中运行须事先设定配置文件。配置文件事实上也就是对Logger、Appender及Layout进行相应设定。 Log4j支持两种配置文件格式，一种是XML格式的文件，一种是properties属性文件。下面以properties属性文件为例介绍。\n\n\n### 配置Logger\n> log4j.rootLogger = [ level ] , appenderName1, appenderName2, …  \nlog4j.additivity.org.apache=false # 表示Logger不会在父Logger的appender里输出，默认为true。  \n\n**level** ：设定日志记录的最低级别，可设的值有OFF、FATAL、ERROR、WARN、INFO、DEBUG、ALL或者自定义的级别，Log4j建议只使用中间四个级别。通过在这里设定级别，您可以控制应用程序中相应级别的日志信息的开关，比如在这里设定了INFO级别，则应用程序中所有DEBUG级别的日志信息将不会被打印出来。  \n**appenderName**：就是指定日志信息要输出到哪里。可以同时指定多个输出目的地，用逗号隔开。\n例如：log4j.rootLogger＝INFO,A1,B2,C3\n\n### 配置Appender\n> log4j.appender.appenderName = className\n\n**appenderName**: Appender的名字，自定义，在log4j.rootLogger设置中使用；  \n**className**：Appender的类的全名（包含包名），常用的Appender的className如下：\n\n* org.apache.log4j.ConsoleAppender（控制台）\n* org.apache.log4j.FileAppender（文件）\n* org.apache.log4j.DailyRollingFileAppender（每天产生一个日志文件）\n* org.apache.log4j.RollingFileAppender（文件大小到达指定尺寸的时候产生一个新的文件）\n* org.apache.log4j.WriterAppender（将日志信息以流格式发送到任意指定的地方）\n\n#### ConsoleAppender的选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Target**=System.err：默认值是System.out。\n\n#### FileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中\n\n#### DailyRollingFileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定当前消息输出到logging.log4j文件中。\n* **DatePattern**='.'yyyy-MM：每月滚动一次日志文件，即每月产生一个新的日志文件。当前月的日志文件名为logging.log4j，前一个月的日志文件名为logging.log4j.yyyy-MM。\n另外，也可以指定按周、天、时、分等来滚动日志文件，对应的格式如下：\n  * '.'yyyy-MM：每月\n  * '.'yyyy-ww：每周\n  * '.'yyyy-MM-dd：每天\n  * '.'yyyy-MM-dd-a：每天两次\n  * '.'yyyy-MM-dd-HH：每小时\n  * '.'yyyy-MM-dd-HH-mm：每分钟\n  \n#### RollingFileAppender选项\n\n* **Threshold**=WARN：指定日志信息的最低输出级别，默认为DEBUG。\n* **ImmediateFlush**=true：表示所有消息都会被立即输出，设为false则不输出，默认值是true。\n* **Append**=false：true表示消息增加到指定文件中，false则将消息覆盖指定的文件内容，默认值是true。\n* **File**=D:/logs/logging.log4j：指定消息输出到logging.log4j文件中。\n* **MaxFileSize=100KB：后缀可以是**KB, MB 或者GB**。在日志文件到达该大小时，将会自动滚动，即将原来的内容移到logging.log4j.1文件中。\n* **MaxBackupIndex**=2：指定可以产生的滚动文件的最大数，例如，设为2则可以产生logging.log4j.1，logging.log4j.2两个滚动文件和一个logging.log4j文件。\n\n\n### 配置Layout\n> log4j.appender.appenderName.layout=className\n\n常见的className如下：\n\n* org.apache.log4j.HTMLLayout（以HTML表格形式布局）\n* org.apache.log4j.PatternLayout（可以灵活地指定布局模式）\n* org.apache.log4j.SimpleLayout（包含日志信息的级别和信息字符串）\n* org.apache.log4j.TTCCLayout（包含日志产生的时间、线程、类别等等信息）\n\n#### HTMLLayout选项\n\n* **LocationInfo**=true：输出java文件名称和行号，默认值是false。\n* **Title**=My Logging： 默认值是Log4J Log Messages。\n\n#### PatternLayout选项\n\n* **ConversionPattern**=%m%n：设定以怎样的格式显示消息。\n\n各种格式化说明如下：\n\n1. %p：输出日志信息的优先级，即DEBUG，INFO，WARN，ERROR，FATAL。\n2. %d：输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，如：%d{yyyy/MM/dd HH:mm:ss,SSS}。\n3. %r：输出自应用程序启动到输出该log信息耗费的毫秒数。\n4. %t：输出产生该日志事件的线程名。\n5. %l：输出日志事件的发生位置，相当于%c.%M(%F:%L)的组合，包括类全名、方法、文件名以及在代码中的行数。例如：test.TestLog4j.main(TestLog4j.java:10)。\n6. %c：输出日志信息所属的类目，通常就是所在类的全名。\n7. %M：输出产生日志信息的方法名。\n8. %F：输出日志消息产生时所在的文件名称。\n9. %L:：输出代码中的行号。\n10. %m:：输出代码中指定的具体日志信息。\n11. %n：输出一个回车换行符，Windows平台为\"\\r\\n\"，Unix平台为\"\\n\"。\n12. %x：输出和当前线程相关联的NDC(嵌套诊断环境)，尤其用到像java servlets这样的多客户多线程的应用中。\n13. %%：输出一个\"%\"字符。\n\n另外，还可以在%与格式字符之间加上修饰符来控制其最小长度、最大长度、和文本的对齐方式。如：\n\n* c：指定输出category的名称，最小的长度是20，如果category的名称长度小于20的话，默认的情况下右对齐。\n* %-20c：\"-\"号表示左对齐。\n* %.30c：指定输出category的名称，最大的长度是30，如果category的名称长度大于30的话，就会将左边多出的字符截掉，但小于30的话也不会补空格。\n\n\n## log4j的默认配置\nlog4j配置支持xml和properties两种格式的文件，默认先在程序的classpath目录下检查是否有log4j.xml文件，如果没有再出招log4j.properties文件。  \nlog4j的包中的LogManager类在加载的时候有个静态代码块是这样写的：\n\n\n```\nstatic {\n    // By default we use a DefaultRepositorySelector which always returns 'h'.\n    Hierarchy h = new Hierarchy(new RootLogger((Level) Level.DEBUG));\n    repositorySelector = new DefaultRepositorySelector(h);\n\n    /** Search for the properties file log4j.properties in the CLASSPATH.  */\n    String override =OptionConverter.getSystemProperty(DEFAULT_INIT_OVERRIDE_KEY,\n                               null);\n\n    // if there is no default init override, then get the resource\n    // specified by the user or the default config file.\n    if(override == null || \"false\".equalsIgnoreCase(override)) {\n\n      String configurationOptionStr = OptionConverter.getSystemProperty(\n                              DEFAULT_CONFIGURATION_KEY, \n                              null);\n\n      String configuratorClassName = OptionConverter.getSystemProperty(\n                                                   CONFIGURATOR_CLASS_KEY, \n                           null);\n\n      URL url = null;\n\n      // if the user has not specified the log4j.configuration\n      // property, we search first for the file \"log4j.xml\" and then\n      // \"log4j.properties\"\n      if(configurationOptionStr == null) {  \n    url = Loader.getResource(DEFAULT_XML_CONFIGURATION_FILE);\n    if(url == null) {\n      url = Loader.getResource(DEFAULT_CONFIGURATION_FILE);\n    }\n      } else {\n    try {\n      url = new URL(configurationOptionStr);\n    } catch (MalformedURLException ex) {\n      // so, resource is not a URL:\n      // attempt to get the resource from the class path\n      url = Loader.getResource(configurationOptionStr); \n    }   \n      }\n      \n      // If we have a non-null url, then delegate the rest of the\n      // configuration to the OptionConverter.selectAndConfigure\n      // method.\n      if(url != null) {\n    LogLog.debug(\"Using URL [\"+url+\"] for automatic log4j configuration.\");      \n    OptionConverter.selectAndConfigure(url, configuratorClassName, \n                       LogManager.getLoggerRepository());\n      } else {\n    LogLog.debug(\"Could not find resource: [\"+configurationOptionStr+\"].\");\n      }\n    }  \n  }\n```\n","slug":"[日志处理]log4j配置详解","published":1,"updated":"2015-08-30T16:21:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dova5000tlo6b4ou7hlcm"},{"title":"[数据库]NoSQL简介","date":"2015-08-03T16:27:20.000Z","_content":"# 什么是NoSQL\nNoSQL是“Not only sql”的简称，泛指非关系型的数据库。\n> 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的\nweb2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题。\n\n<!--more-->\n# NoSQL数据库的分类\n## 键值(Key-Value)存储数据库  \n  这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。常见的key-value数据库比如Redis。\n## 列存储数据库  \n  这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。因为列的数据结构天生是相似的，即便逻辑上每一行之间有细微的差异，仍旧比按行存储的结构聚合在一起的数据更利于压缩，因为大多数的压缩算法只关注有限的压缩接口，像增量压缩法和前缀压缩法这类专业算法，是基于列存储的数据定制的，能够大大提高压缩比，更高的压缩比更有利于在返回查询接口的时候降低带宽的消耗。比如Hbase就是这类数据库。\n## 文档型数据库  \n  文档型数据库的灵感是来自于Lotus Notes办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDb. 国内也有文档型数据库SequoiaDB，已经开源。\n## 图形(Graph)数据库  \n  图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API，比如 Infinite Graph。\n \n# NoSQL的共同特征\n对于NoSQL并没有一个明确的范围和定义，但是他们都普遍存在下面一些共同特征：\n\n* **不需要预定义模式：**不需要事先定义数据模式，预定义表结构。数据中的每条记录都可能有不同的属性和格式。当插入数据时，并不需要预先定义它们的模式。  \n* **无共享架构：**相对于将所有数据存储的存储区域网络中的全共享架构。NoSQL往往将数据划分后存储在各个本地服务器上。因为从本地磁盘读取数据的性能往往好于通过网络传输读取数据的性能，从而提高了系统的性能。  \n* **弹性可扩展：**可以在系统运行的时候，动态增加或者删除结点。不需要停机维护，数据可以自动迁移。  \n* **分区：**相对于将数据存放于同一个节点，NoSQL数据库需要将数据进行分区，将记录分散在多个节点上面。并且通常分区的同时还要做复制。这样既提高了并行性能，又能保证没有单点失效的问题。  \n* **异步复制：**和RAID存储系统不同的是，NoSQL中的复制，往往是基于日志的异步复制。这样，数据就可以尽快地写入一个节点，而不会被网络传输引起迟延。缺点是并不总是能保证一致性，这样的方式在出现故障的时候，可能会丢失少量的数据。  \n* **BASE：**相对于事务严格的ACID特性，NoSQL数据库保证的是BASE特性。BASE是最终一致性和软事务。\nNoSQL数据库并没有一个统一的架构，两种NoSQL数据库之间的不同，甚至远远超过两种关系型数据库的不同。可以说，NoSQL各有所长，成功的NoSQL必然特别适用于某些场合或者某些应用，在这些场合中会远远胜过关系型数据库和其他的NoSQL。\n\n# 参考文献\n* [百度百科](http://baike.baidu.com/link?url=Lqb3ql7kuUlVrv8YbEX_0D9Wu9C8EJrwHcz4XQn1x2U_XIkiNqIFqhkei8QrNOErr2-I2AKNGbn2ZPxnOIBplK)\n* Lars george，代志远，刘佳，蒋杰，``<<Hbase权威指南>>``，人民邮电出版社，2013\n  \n\n","source":"_posts/[数据库]NoSQL简介.md","raw":"title: \"[数据库]NoSQL简介\"\ntags: [数据库]\ncategories: [数据库]\ndate: 2015-08-04 00:27:20\n---\n# 什么是NoSQL\nNoSQL是“Not only sql”的简称，泛指非关系型的数据库。\n> 随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的\nweb2.0纯动态网站已经显得力不从心，暴露了很多难以克服的问题，而非关系型的数据库则由于其本身的特点得到了非常迅速的发展。NoSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题。\n\n<!--more-->\n# NoSQL数据库的分类\n## 键值(Key-Value)存储数据库  \n  这一类数据库主要会使用到一个哈希表，这个表中有一个特定的键和一个指针指向特定的数据。Key/value模型对于IT系统来说的优势在于简单、易部署。但是如果DBA只对部分值进行查询或更新的时候，Key/value就显得效率低下了。常见的key-value数据库比如Redis。\n## 列存储数据库  \n  这部分数据库通常是用来应对分布式存储的海量数据。键仍然存在，但是它们的特点是指向了多个列。这些列是由列家族来安排的。因为列的数据结构天生是相似的，即便逻辑上每一行之间有细微的差异，仍旧比按行存储的结构聚合在一起的数据更利于压缩，因为大多数的压缩算法只关注有限的压缩接口，像增量压缩法和前缀压缩法这类专业算法，是基于列存储的数据定制的，能够大大提高压缩比，更高的压缩比更有利于在返回查询接口的时候降低带宽的消耗。比如Hbase就是这类数据库。\n## 文档型数据库  \n  文档型数据库的灵感是来自于Lotus Notes办公软件的，而且它同第一种键值存储相类似。该类型的数据模型是版本化的文档，半结构化的文档以特定的格式存储，比如JSON。文档型数据库可 以看作是键值数据库的升级版，允许之间嵌套键值。而且文档型数据库比键值数据库的查询效率更高。如：CouchDB, MongoDb. 国内也有文档型数据库SequoiaDB，已经开源。\n## 图形(Graph)数据库  \n  图形结构的数据库同其他行列以及刚性结构的SQL数据库不同，它是使用灵活的图形模型，并且能够扩展到多个服务器上。NoSQL数据库没有标准的查询语言(SQL)，因此进行数据库查询需要制定数据模型。许多NoSQL数据库都有REST式的数据接口或者查询API，比如 Infinite Graph。\n \n# NoSQL的共同特征\n对于NoSQL并没有一个明确的范围和定义，但是他们都普遍存在下面一些共同特征：\n\n* **不需要预定义模式：**不需要事先定义数据模式，预定义表结构。数据中的每条记录都可能有不同的属性和格式。当插入数据时，并不需要预先定义它们的模式。  \n* **无共享架构：**相对于将所有数据存储的存储区域网络中的全共享架构。NoSQL往往将数据划分后存储在各个本地服务器上。因为从本地磁盘读取数据的性能往往好于通过网络传输读取数据的性能，从而提高了系统的性能。  \n* **弹性可扩展：**可以在系统运行的时候，动态增加或者删除结点。不需要停机维护，数据可以自动迁移。  \n* **分区：**相对于将数据存放于同一个节点，NoSQL数据库需要将数据进行分区，将记录分散在多个节点上面。并且通常分区的同时还要做复制。这样既提高了并行性能，又能保证没有单点失效的问题。  \n* **异步复制：**和RAID存储系统不同的是，NoSQL中的复制，往往是基于日志的异步复制。这样，数据就可以尽快地写入一个节点，而不会被网络传输引起迟延。缺点是并不总是能保证一致性，这样的方式在出现故障的时候，可能会丢失少量的数据。  \n* **BASE：**相对于事务严格的ACID特性，NoSQL数据库保证的是BASE特性。BASE是最终一致性和软事务。\nNoSQL数据库并没有一个统一的架构，两种NoSQL数据库之间的不同，甚至远远超过两种关系型数据库的不同。可以说，NoSQL各有所长，成功的NoSQL必然特别适用于某些场合或者某些应用，在这些场合中会远远胜过关系型数据库和其他的NoSQL。\n\n# 参考文献\n* [百度百科](http://baike.baidu.com/link?url=Lqb3ql7kuUlVrv8YbEX_0D9Wu9C8EJrwHcz4XQn1x2U_XIkiNqIFqhkei8QrNOErr2-I2AKNGbn2ZPxnOIBplK)\n* Lars george，代志远，刘佳，蒋杰，``<<Hbase权威指南>>``，人民邮电出版社，2013\n  \n\n","slug":"[数据库]NoSQL简介","published":1,"updated":"2015-08-21T08:22:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dova7000wlo6b41pfijeb"},{"title":"[git]git命令自动补全","date":"2015-09-02T08:58:32.000Z","_content":"# 背景\n在Mac上安装了git之后，发现命令不能自动补全，使用起来非常不方便，本文介绍怎么让git命令能够自动补全。\n<!--more-->\n# 确保bash能够自动补全\n在终端（本文使用的是OS X的终端）执行如下命令：\n\n```\nbrew list \n```\n\n看看是否已经安装有bash-completion，比如我的机器(已经安装了)运行上面的命令会显示：\n\n>bash-completion\tnode\t\topenssl\t\tpkg-config\twget\n\n如果没有安装，运行如下命令安装bash-completion：\n\n```\nbrew install bash-completion\n```\n等待安装完成之后，运行如下命令：\n\n```\nbrew info bash-completion\n```\n\n运行上面的命令后会在终端显示下图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/git命令自动补全/bash-completion.png)\n\n仔细阅读箭头所指的地方，依照提示将矩形框内的内容添加到~/.bash_profile文件(如果没有该文件，新建)，然后重启终端，bash-completion功能安装完成。\n\n# 让git支持自动补全\n从github上clone git的源码到本地：\n\n```\ngit clone https://github.com/git/git.git\n```\n找到\"contrib/completion/\"目录下的git-completion.bash，将该文件拷贝到`~/`目录下下并重命名为.git-completion.bash:\n\n```\ncp git-completion.bash ~/.git-completion.bash\n```\n\n在~/.bashrc文件中追加如下内容：\n\n```\nsource ~/.git-completion.bash\n```\n\n重启终端，大功告成，现在git能够使用tab键自动补全命令了，enjoy it！\n\n","source":"_posts/[git]git命令自动补全.md","raw":"title: '[git]git命令自动补全'\ntags: [git]\ncategories: [git]\ndate: 2015-09-02 16:58:32\n---\n# 背景\n在Mac上安装了git之后，发现命令不能自动补全，使用起来非常不方便，本文介绍怎么让git命令能够自动补全。\n<!--more-->\n# 确保bash能够自动补全\n在终端（本文使用的是OS X的终端）执行如下命令：\n\n```\nbrew list \n```\n\n看看是否已经安装有bash-completion，比如我的机器(已经安装了)运行上面的命令会显示：\n\n>bash-completion\tnode\t\topenssl\t\tpkg-config\twget\n\n如果没有安装，运行如下命令安装bash-completion：\n\n```\nbrew install bash-completion\n```\n等待安装完成之后，运行如下命令：\n\n```\nbrew info bash-completion\n```\n\n运行上面的命令后会在终端显示下图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/git命令自动补全/bash-completion.png)\n\n仔细阅读箭头所指的地方，依照提示将矩形框内的内容添加到~/.bash_profile文件(如果没有该文件，新建)，然后重启终端，bash-completion功能安装完成。\n\n# 让git支持自动补全\n从github上clone git的源码到本地：\n\n```\ngit clone https://github.com/git/git.git\n```\n找到\"contrib/completion/\"目录下的git-completion.bash，将该文件拷贝到`~/`目录下下并重命名为.git-completion.bash:\n\n```\ncp git-completion.bash ~/.git-completion.bash\n```\n\n在~/.bashrc文件中追加如下内容：\n\n```\nsource ~/.git-completion.bash\n```\n\n重启终端，大功告成，现在git能够使用tab键自动补全命令了，enjoy it！\n\n","slug":"[git]git命令自动补全","published":1,"updated":"2015-10-13T06:04:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovaa0011lo6b6npqq66o"},{"title":"[MarkDown]MarkDown简介","date":"2015-07-31T19:31:48.000Z","_content":"# Markdown简介\n**说明：**文章首发于[简书](http://www.jianshu.com/p/3695e1a1d9a2)，转载请注明出处！\n>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过类似HTML的标记语法，它可以使普通文本内容具有一定的格式。\nMarkdown具有一系列衍生版本，用于扩展Markdown的功能（如表格、脚注、内嵌HTML等等），这些功能原初的Markdown尚不具备，它们能让Markdown转换成更多的格式，例如[LaTeX](http://baike.baidu.com/view/769333.htm)，[Docbook](http://baike.baidu.com/view/408796.htm)。Markdown增强版中比较有名的有Markdown Extra、MultiMarkdown、 Maruku等。这些衍生版本要么基于工具，如Pandoc；要么基于网站，如[GitHub](http://baike.baidu.com/view/3366456.htm)和[Wikipedia](http://baike.baidu.com/view/1637.htm)，在语法上基本兼容，但在换行等细节上也有改动。\n<!--more-->\n#Markdown语法\n下面介绍一些最基本最常用的markdown语法。\n## 标题\nMarkdown一共有六级标题，就相当于html中的H1，H2， H3 ... H6，在Markdown中在文字前面加上1-6个井号（#）然后再加上一个空格依次表示是几级标题。\n![六级标题演示](http://img.blog.csdn.net/20150508141703270)\n\n## 字体加粗\n字体加粗只需要在文字首尾分别加上两个星号（**）即可。\n![字体加粗演示](http://img.blog.csdn.net/20150508141732049)\n\n## 斜体字\n如果需要让文字变成斜体字，只需要在文字首尾分别加上一个星号（*）即可。\n![斜体字演示](http://img.blog.csdn.net/20150508142140483)\n\n## 文字加上删除线\n需要让文字从中间划上一横删除线，只需要在文字首尾分别加上两个波浪线符号（~~）即可。\n![文字删除线演示](http://img.blog.csdn.net/20150508142220653)\n\n## 换行\n一行文字需要换行，只需要在行末尾加上两个空格即可。\n![换行演示](http://img.blog.csdn.net/20150508142331976)\n\n## 列表\n列表分为有序列表和无序列表，有序列表只需要在文字前面加上“n.空格（n为任意整数）”即可，这里并不关心多个列表之间整数n的顺序性，只要是整数就行。无序列表只需要在文字前面加上“*空格”即可。\n![列表](http://img.blog.csdn.net/20150508142238949)\n\n## 水平分割线\n需要水平分隔线，只需要加上两个以上星号（***），或者两个以上减号（---），或者两个以上等号（===）即可。\n![水平分割线演示](http://img.blog.csdn.net/20150508142442017)\n\n## 代码块\n对程序员来说，常常需要在文中加入一段代码，这时可以在代码段的首行前加上一行这三个字符: \\```, 在代码段的尾行后再加上一行这三个字符：\\``` 即可。\n![代码块演示](http://img.blog.csdn.net/20150508142531956)\n\n## 表格\n这是Markdown语法中最蛋疼的一点，就是用字符描绘表格，没法用语言描述，直接看例子吧。\n![表格演示](http://img.blog.csdn.net/20150508142642933)\n最基本的也是最常用的语法大概就这么多了。\n\n# Markdown编辑器\n笔者这篇文章就是使用Markdown编写的，文中的演示图片使用的是OS X系统上比较好用的Mou这款Markdown编辑器，在此笔者也给大家推荐这一款软件。\n[Mou下载链接](http://mouapp.com/download/Mou.zip)\nMou刚安装之后的软件界面如下：\n![这里写图片描述](http://img.blog.csdn.net/20150508144515995)\n有很详细的使用说明，笔者就不多说了， enjoy it！\n\n其他一些编辑器如下：\n>OSX\n>[Byword](http://baike.baidu.com/view/10356750.htm)\n>[Mou](http://baike.baidu.com/view/940640.htm)\n>\n>Linux\n>ReText\n>UberWriter\n>\n>Windows\n>[MarkdownPad](http://baike.baidu.com/view/11801554.htm)\n>Miu\n>\n>iOS\n>[Byword](http://baike.baidu.com/view/10356750.htm)\n>\n>浏览器插件\n>MaDe (Chrome)\n\n","source":"_posts/[MarkDown]MarkDown简介.md","raw":"title: \"[MarkDown]MarkDown简介\"\ndate: 2015-08-01 03:31:48\ntags: [MarkDown,工具]\ncategories: [MarkDown,工具]\n---\n# Markdown简介\n**说明：**文章首发于[简书](http://www.jianshu.com/p/3695e1a1d9a2)，转载请注明出处！\n>Markdown是一种可以使用普通文本编辑器编写的标记语言，通过类似HTML的标记语法，它可以使普通文本内容具有一定的格式。\nMarkdown具有一系列衍生版本，用于扩展Markdown的功能（如表格、脚注、内嵌HTML等等），这些功能原初的Markdown尚不具备，它们能让Markdown转换成更多的格式，例如[LaTeX](http://baike.baidu.com/view/769333.htm)，[Docbook](http://baike.baidu.com/view/408796.htm)。Markdown增强版中比较有名的有Markdown Extra、MultiMarkdown、 Maruku等。这些衍生版本要么基于工具，如Pandoc；要么基于网站，如[GitHub](http://baike.baidu.com/view/3366456.htm)和[Wikipedia](http://baike.baidu.com/view/1637.htm)，在语法上基本兼容，但在换行等细节上也有改动。\n<!--more-->\n#Markdown语法\n下面介绍一些最基本最常用的markdown语法。\n## 标题\nMarkdown一共有六级标题，就相当于html中的H1，H2， H3 ... H6，在Markdown中在文字前面加上1-6个井号（#）然后再加上一个空格依次表示是几级标题。\n![六级标题演示](http://img.blog.csdn.net/20150508141703270)\n\n## 字体加粗\n字体加粗只需要在文字首尾分别加上两个星号（**）即可。\n![字体加粗演示](http://img.blog.csdn.net/20150508141732049)\n\n## 斜体字\n如果需要让文字变成斜体字，只需要在文字首尾分别加上一个星号（*）即可。\n![斜体字演示](http://img.blog.csdn.net/20150508142140483)\n\n## 文字加上删除线\n需要让文字从中间划上一横删除线，只需要在文字首尾分别加上两个波浪线符号（~~）即可。\n![文字删除线演示](http://img.blog.csdn.net/20150508142220653)\n\n## 换行\n一行文字需要换行，只需要在行末尾加上两个空格即可。\n![换行演示](http://img.blog.csdn.net/20150508142331976)\n\n## 列表\n列表分为有序列表和无序列表，有序列表只需要在文字前面加上“n.空格（n为任意整数）”即可，这里并不关心多个列表之间整数n的顺序性，只要是整数就行。无序列表只需要在文字前面加上“*空格”即可。\n![列表](http://img.blog.csdn.net/20150508142238949)\n\n## 水平分割线\n需要水平分隔线，只需要加上两个以上星号（***），或者两个以上减号（---），或者两个以上等号（===）即可。\n![水平分割线演示](http://img.blog.csdn.net/20150508142442017)\n\n## 代码块\n对程序员来说，常常需要在文中加入一段代码，这时可以在代码段的首行前加上一行这三个字符: \\```, 在代码段的尾行后再加上一行这三个字符：\\``` 即可。\n![代码块演示](http://img.blog.csdn.net/20150508142531956)\n\n## 表格\n这是Markdown语法中最蛋疼的一点，就是用字符描绘表格，没法用语言描述，直接看例子吧。\n![表格演示](http://img.blog.csdn.net/20150508142642933)\n最基本的也是最常用的语法大概就这么多了。\n\n# Markdown编辑器\n笔者这篇文章就是使用Markdown编写的，文中的演示图片使用的是OS X系统上比较好用的Mou这款Markdown编辑器，在此笔者也给大家推荐这一款软件。\n[Mou下载链接](http://mouapp.com/download/Mou.zip)\nMou刚安装之后的软件界面如下：\n![这里写图片描述](http://img.blog.csdn.net/20150508144515995)\n有很详细的使用说明，笔者就不多说了， enjoy it！\n\n其他一些编辑器如下：\n>OSX\n>[Byword](http://baike.baidu.com/view/10356750.htm)\n>[Mou](http://baike.baidu.com/view/940640.htm)\n>\n>Linux\n>ReText\n>UberWriter\n>\n>Windows\n>[MarkdownPad](http://baike.baidu.com/view/11801554.htm)\n>Miu\n>\n>iOS\n>[Byword](http://baike.baidu.com/view/10356750.htm)\n>\n>浏览器插件\n>MaDe (Chrome)\n\n","slug":"[MarkDown]MarkDown简介","published":1,"updated":"2015-08-21T08:24:33.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovac0016lo6bx2d8kvi3"},{"title":"[Java锁学习二]锁消除","date":"2015-08-01T01:39:10.000Z","_content":"## 概述\n锁消除是Java虚拟机在JIT编译是，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。\n<!--more-->\n## 实验\n看如下代码：\n```\npackage com.winwill.lock;\n\n/**\n * @author qifuguang\n * @date 15/6/5 14:11\n */\npublic class TestLockEliminate {\n    public static String getString(String s1, String s2) {\n        StringBuffer sb = new StringBuffer();\n        sb.append(s1);\n        sb.append(s2);\n        return sb.toString();\n    }\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 1000000; i++) {\n            getString(\"TestLockEliminate \", \"Suffix\");\n        }\n        System.out.println(\"一共耗费：\" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n```\ngetString()方法中的StringBuffer数以函数内部的局部变量，进作用于方法内部，不可能逃逸出该方法，因此他就不可能被多个线程同时访问，也就没有资源的竞争，但是StringBuffer的append操作却需要执行同步操作:\n```\n    @Override\n    public synchronized StringBuffer append(String str) {\n        toStringCache = null;\n        super.append(str);\n        return this;\n    }\n```\n逃逸分析和锁消除分别可以使用参数-XX:+DoEscapeAnalysis和-XX:+EliminateLocks(锁消除必须在-server模式下)开启。使用如下参数运行上面的程序：\n> -XX:+DoEscapeAnalysis -XX:-EliminateLocks\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605143406270)\n\n使用如下命令运行程序：\n> -XX:+DoEscapeAnalysis -XX:+EliminateLocks\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605143628409)\n\n## 结论\n由上面的例子可以看出，关闭了锁消除之后，StringBuffer每次append都会进行锁的申请，浪费了不必要的时间，开启锁消除之后性能得到了提高。\n\n\n","source":"_posts/[Java锁学习二]锁消除.md","raw":"title: \"[Java锁学习二]锁消除\"\ntags: [Java锁学习]\ncategories: [Java锁学习]\ndate: 2015-08-01 09:39:10\n---\n## 概述\n锁消除是Java虚拟机在JIT编译是，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过锁消除，可以节省毫无意义的请求锁时间。\n<!--more-->\n## 实验\n看如下代码：\n```\npackage com.winwill.lock;\n\n/**\n * @author qifuguang\n * @date 15/6/5 14:11\n */\npublic class TestLockEliminate {\n    public static String getString(String s1, String s2) {\n        StringBuffer sb = new StringBuffer();\n        sb.append(s1);\n        sb.append(s2);\n        return sb.toString();\n    }\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 1000000; i++) {\n            getString(\"TestLockEliminate \", \"Suffix\");\n        }\n        System.out.println(\"一共耗费：\" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n```\ngetString()方法中的StringBuffer数以函数内部的局部变量，进作用于方法内部，不可能逃逸出该方法，因此他就不可能被多个线程同时访问，也就没有资源的竞争，但是StringBuffer的append操作却需要执行同步操作:\n```\n    @Override\n    public synchronized StringBuffer append(String str) {\n        toStringCache = null;\n        super.append(str);\n        return this;\n    }\n```\n逃逸分析和锁消除分别可以使用参数-XX:+DoEscapeAnalysis和-XX:+EliminateLocks(锁消除必须在-server模式下)开启。使用如下参数运行上面的程序：\n> -XX:+DoEscapeAnalysis -XX:-EliminateLocks\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605143406270)\n\n使用如下命令运行程序：\n> -XX:+DoEscapeAnalysis -XX:+EliminateLocks\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605143628409)\n\n## 结论\n由上面的例子可以看出，关闭了锁消除之后，StringBuffer每次append都会进行锁的申请，浪费了不必要的时间，开启锁消除之后性能得到了提高。\n\n\n","slug":"[Java锁学习二]锁消除","published":1,"updated":"2015-08-21T08:12:13.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovaf001flo6bivs6kwxz"},{"title":"[Java锁学习三]锁在应用层的优化思路","date":"2015-08-01T01:39:57.000Z","_content":"## 减少锁持有时间\n如下面的代码：\n```\npublic synchronized void test() {\n        executeMethod1();\n        multiThreadExecute();\n        executeMethod2();\n    }\n```\n<!--more-->\n如果真正存在资源的竞争，需要加锁的函数是multiThreadExecute(),其他两个函数executeMethod1和executeMethod2都没有资源的竞争时，这样写只会增加线程持有锁的时间，就会导致其他线程等待这个锁的时间增长，影响性能。这种情况下，应该修改为：\n```\n    public void test() {\n        executeMethod1();\n        synchronized (this) {\n            MultiThreadExecute();\n        }\n        executeMethod2();\n    }\n```\n\n## 减小锁粒度\n这个思路最典型的例子就是JDK中的重要成员ConcurrentHashMap，ConcurrentHashMap将整个区间分成若干个Segment（默认是16个），每一个Segment都是一个子map，每个Segment都拥有自己的一把锁。当需要向map中插入数据时，并不是先申请所有的锁，而是根据需要插入的数据的key的hashcode计算出应该从插入到哪一个Segment，然后再申请这个Segment的锁。所以理想情况下，ConcurrentHashMap最多可能有16个线程真正同时插入数据。\n\n但是较小锁粒度会有一个问题：如果需要访问全局数据（这时需要取得全局锁），消耗的资源会比较多。以ConcurrentHashMap为例，put操作使用分段锁提高了并发，但是size()函数却没那么幸运，size函数返回map中所有有效的元素个数，所以需要访问所有数据，也就需要取得所有的锁，损耗的性能是比较多的。\n\n## 锁分离\n同样以JDK中的重要成员LinkedBlockingQueue为例，take()和put()函数分别从队列中取得数据和向队列中添加元素。因为LinkedBlockingQueue是链表实现的，take和put操作分别在队头和队尾操作，互不影响，所以这两个操作就不应该公用一把锁。下面是jdk中LinkedBlockingQueue的代码的一部分：\n```\n    /**\n     * Tail of linked list.\n     * Invariant: last.next == null\n     */\n    private transient Node<E> last;\n\n    /** Lock held by take, poll, etc */\n    private final ReentrantLock takeLock = new ReentrantLock();\n\n    /** Wait queue for waiting takes */\n    private final Condition notEmpty = takeLock.newCondition();\n\n    /** Lock held by put, offer, etc */\n    private final ReentrantLock putLock = new ReentrantLock();\n\n    /** Wait queue for waiting puts */\n    private final Condition notFull = putLock.newCondition();\n```\n可以看到分别定义了takeLock和putLock，这两个操作不适用同一把锁，削弱了锁竞争的可能性，提高了性能。\n\n## 锁粗化\n所谓的锁粗化就是如果代码中有连续的对同一把锁的申请操作，则需要考虑将这些锁操作合并为一个。比如：\n```\n    public void test() {\n        synchronized (this) {\n            // do sth\n        }\n        synchronized (this) {\n            // do sth\n        }\n    }\n```\n这样的代码应该合并为：\n```\n    public void test() {\n        synchronized (this) {\n            // do sth\n        }\n    }\n```\n锁粗化的思想和减少锁持有时间是相反的，但是在不同的场合下，他们的效果并不相同，需要我们权衡利弊再做决策。\n\n","source":"_posts/[Java锁学习三]锁在应用层的优化思路.md","raw":"title: \"[Java锁学习三]锁在应用层的优化思路\"\ntags: [Java锁学习]\ncategories: [Java锁学习]\ndate: 2015-08-01 09:39:57\n---\n## 减少锁持有时间\n如下面的代码：\n```\npublic synchronized void test() {\n        executeMethod1();\n        multiThreadExecute();\n        executeMethod2();\n    }\n```\n<!--more-->\n如果真正存在资源的竞争，需要加锁的函数是multiThreadExecute(),其他两个函数executeMethod1和executeMethod2都没有资源的竞争时，这样写只会增加线程持有锁的时间，就会导致其他线程等待这个锁的时间增长，影响性能。这种情况下，应该修改为：\n```\n    public void test() {\n        executeMethod1();\n        synchronized (this) {\n            MultiThreadExecute();\n        }\n        executeMethod2();\n    }\n```\n\n## 减小锁粒度\n这个思路最典型的例子就是JDK中的重要成员ConcurrentHashMap，ConcurrentHashMap将整个区间分成若干个Segment（默认是16个），每一个Segment都是一个子map，每个Segment都拥有自己的一把锁。当需要向map中插入数据时，并不是先申请所有的锁，而是根据需要插入的数据的key的hashcode计算出应该从插入到哪一个Segment，然后再申请这个Segment的锁。所以理想情况下，ConcurrentHashMap最多可能有16个线程真正同时插入数据。\n\n但是较小锁粒度会有一个问题：如果需要访问全局数据（这时需要取得全局锁），消耗的资源会比较多。以ConcurrentHashMap为例，put操作使用分段锁提高了并发，但是size()函数却没那么幸运，size函数返回map中所有有效的元素个数，所以需要访问所有数据，也就需要取得所有的锁，损耗的性能是比较多的。\n\n## 锁分离\n同样以JDK中的重要成员LinkedBlockingQueue为例，take()和put()函数分别从队列中取得数据和向队列中添加元素。因为LinkedBlockingQueue是链表实现的，take和put操作分别在队头和队尾操作，互不影响，所以这两个操作就不应该公用一把锁。下面是jdk中LinkedBlockingQueue的代码的一部分：\n```\n    /**\n     * Tail of linked list.\n     * Invariant: last.next == null\n     */\n    private transient Node<E> last;\n\n    /** Lock held by take, poll, etc */\n    private final ReentrantLock takeLock = new ReentrantLock();\n\n    /** Wait queue for waiting takes */\n    private final Condition notEmpty = takeLock.newCondition();\n\n    /** Lock held by put, offer, etc */\n    private final ReentrantLock putLock = new ReentrantLock();\n\n    /** Wait queue for waiting puts */\n    private final Condition notFull = putLock.newCondition();\n```\n可以看到分别定义了takeLock和putLock，这两个操作不适用同一把锁，削弱了锁竞争的可能性，提高了性能。\n\n## 锁粗化\n所谓的锁粗化就是如果代码中有连续的对同一把锁的申请操作，则需要考虑将这些锁操作合并为一个。比如：\n```\n    public void test() {\n        synchronized (this) {\n            // do sth\n        }\n        synchronized (this) {\n            // do sth\n        }\n    }\n```\n这样的代码应该合并为：\n```\n    public void test() {\n        synchronized (this) {\n            // do sth\n        }\n    }\n```\n锁粗化的思想和减少锁持有时间是相反的，但是在不同的场合下，他们的效果并不相同，需要我们权衡利弊再做决策。\n\n","slug":"[Java锁学习三]锁在应用层的优化思路","published":1,"updated":"2015-08-21T08:13:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovah001klo6bggacybgj"},{"title":"[Java锁学习一]偏向锁","date":"2015-08-01T01:38:16.000Z","_content":"## 概述\n偏向锁是JDK 1.6提出的一种锁优化方式，起核心思想是如果程序没有竞争，则取消之前已经取得锁的线程的同步操作。也就是说，某一个锁被一个线程获取之后，便进入了偏向锁模式，当该线程再次请求这个锁时，就无需再进行相关的同步操作，从而节省了操作时间。但是如果在此期间，有其他线程申请了这个锁，则退出偏向锁模式。在JVM中可以使用-XX:+UseBiasedLocking设置启用偏向锁。\n<!--more-->\n## 实验\n看如下的代码:\n```\npackage com.winwill.lock;\n\nimport java.util.List;\nimport java.util.Vector;\n\n/**\n * @author qifuguang\n * @date 15/6/5 13:44\n */\npublic class TestBiasedLock {\n    private static List<Integer> list = new Vector<Integer>();\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 10000000; i++) {\n            list.add(i);\n        }\n        System.out.println(\"一共耗费：\" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n\n```\n代码中使用一个循环一直往Vector中新增元素，Vector的add操作会请求锁：\n```\n    /**\n     * Appends the specified element to the end of this Vector.\n     *\n     * @param e element to be appended to this Vector\n     * @return {@code true} (as specified by {@link Collection#add})\n     * @since 1.2\n     */\n    public synchronized boolean add(E e) {\n        modCount++;\n        ensureCapacityHelper(elementCount + 1);\n        elementData[elementCount++] = e;\n        return true;\n    }\n```\n我们使用如下的参数运行代码：\n> -XX:+UseBiasedLocking\n-XX:BiasedLockingStartupDelay=0\n-Xmx512m\n-Xms512m\n\n-XX:BiasedLockingStartupDelay=0这个参数表示虚拟机一启动就启动偏向锁模式，因为默认情况下，虚拟机启动4s之后才会启动偏向锁模式，该例运行时间较短，故做此设置。\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605140140392)\n\n但是，如果我们使用如下的参数运行程序：\n> -XX:-UseBiasedLocking\n-Xmx512m\n-Xms512m\n\n得到的结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150605140228893)\n\n## 结论\n偏向锁在少竞争的情况下，对系统性能有一定的帮助。\n\n## 注意事项\n偏向锁在竞争激烈的情况下没有太强的优化效果，因为大量的竞争会导致持有锁的线程不停地切换，锁也很难一直保持偏向模式，此时，使用偏向锁不仅不能优化程序，反而有可能降低程序性能。因为，在竞争激烈的场景下可以使用-XX:-UseBiasedLocking参数禁用偏向锁。\n\n","source":"_posts/[Java锁学习一]偏向锁.md","raw":"title: \"[Java锁学习一]偏向锁\"\ntags: [Java锁学习]\ncategories: [Java锁学习]\ndate: 2015-08-01 09:38:16\n---\n## 概述\n偏向锁是JDK 1.6提出的一种锁优化方式，起核心思想是如果程序没有竞争，则取消之前已经取得锁的线程的同步操作。也就是说，某一个锁被一个线程获取之后，便进入了偏向锁模式，当该线程再次请求这个锁时，就无需再进行相关的同步操作，从而节省了操作时间。但是如果在此期间，有其他线程申请了这个锁，则退出偏向锁模式。在JVM中可以使用-XX:+UseBiasedLocking设置启用偏向锁。\n<!--more-->\n## 实验\n看如下的代码:\n```\npackage com.winwill.lock;\n\nimport java.util.List;\nimport java.util.Vector;\n\n/**\n * @author qifuguang\n * @date 15/6/5 13:44\n */\npublic class TestBiasedLock {\n    private static List<Integer> list = new Vector<Integer>();\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 10000000; i++) {\n            list.add(i);\n        }\n        System.out.println(\"一共耗费：\" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n\n```\n代码中使用一个循环一直往Vector中新增元素，Vector的add操作会请求锁：\n```\n    /**\n     * Appends the specified element to the end of this Vector.\n     *\n     * @param e element to be appended to this Vector\n     * @return {@code true} (as specified by {@link Collection#add})\n     * @since 1.2\n     */\n    public synchronized boolean add(E e) {\n        modCount++;\n        ensureCapacityHelper(elementCount + 1);\n        elementData[elementCount++] = e;\n        return true;\n    }\n```\n我们使用如下的参数运行代码：\n> -XX:+UseBiasedLocking\n-XX:BiasedLockingStartupDelay=0\n-Xmx512m\n-Xms512m\n\n-XX:BiasedLockingStartupDelay=0这个参数表示虚拟机一启动就启动偏向锁模式，因为默认情况下，虚拟机启动4s之后才会启动偏向锁模式，该例运行时间较短，故做此设置。\n\n得到如下结果：\n![这里写图片描述](http://img.blog.csdn.net/20150605140140392)\n\n但是，如果我们使用如下的参数运行程序：\n> -XX:-UseBiasedLocking\n-Xmx512m\n-Xms512m\n\n得到的结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150605140228893)\n\n## 结论\n偏向锁在少竞争的情况下，对系统性能有一定的帮助。\n\n## 注意事项\n偏向锁在竞争激烈的情况下没有太强的优化效果，因为大量的竞争会导致持有锁的线程不停地切换，锁也很难一直保持偏向模式，此时，使用偏向锁不仅不能优化程序，反而有可能降低程序性能。因为，在竞争激烈的场景下可以使用-XX:-UseBiasedLocking参数禁用偏向锁。\n\n","slug":"[Java锁学习一]偏向锁","published":1,"updated":"2015-08-21T08:11:27.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovaj001nlo6brprbyg3u"},{"title":"[Java并发包学习四]Future和FutureTask","date":"2015-08-21T06:02:02.000Z","_content":"# 概述\nFuture主要用来表示线程异步执行的结果，他提供了检查异步执行的程序是否已经执行完毕、是否已经被取消，并且获取执行结果的方法。它是一个接口，接口的定义如下：\n<!--more-->\n```\npublic interface Future<V> {\n    boolean cancel(boolean mayInterruptIfRunning);\n    boolean isCancelled();\n    boolean isDone();\n    V get() throws InterruptedException, ExecutionException;\n    V get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n}\n```\nJDK中的FutureTask类是这个接口的最基本的实现。\n\n# 成员函数介绍\n## cancel函数\ncancel函数用来取消一个正在异步执行的任务，如果任务还没有开始，则该任务将不会再被执行，如果任务已经在执行，则可以通过mayInterruptIfRunning参数来决定是否需要尝试取消正在执行的任务，如果mayInterruptIfRunning参数为**true**则将取消正在运行的任务，为**false**则不会打断，该任务能正常结束。    \n\n## isCanceled函数\nisCanceled函数用来判断一个任务是否已经被取消，如果一个任务在正常执行结束之前被取消，则该函数返回**true**，否则返回**false**。\n\n## isDone函数\nisDone函数用来检测一个任务是否已经结束，结束的原因可以分为以下几种情况：  \n\n* 正常完成； \n* 抛出异常而退出；\n* 被cancel函数取消；\n\n以上这三种情况，该函数都会返回**true**，否则返回**false**。\n\n## get函数\nget函数用来获取异步执行的结果，需要说明的是，对于没有参数的get函数，如果任务没有执行完毕，该函数会一直阻塞，直到任务结束，然后再返回执行的结果；而有timeout和unit两个参数的get函数能提供一个最长等待时间，如果过了给定的时间，任务仍然没有完毕，则抛出TimeoutException，否则返回任务执行结果。\n\n# 基本用法\n下面的例子演示怎么使用Future来获取异步执行的结果，假设这样一个场景：\n> 我们现在正在家里打dota(笔者是个dota爱好者^_^)，突然口渴了，想喝点白开水，于是我们需要烧开水，烧开水是一个比较耗时的事情，所以热水器(烧水线程)在烧开水的时候我们（主线程）不应该在一旁干等着，而是可以继续玩dota。等到被干死了之后或者上了别人高地之后再去检查开水是否已经烧好了。\n\n在这个场景中，我就好比是程序的主线程，而热水器就是我创建的副线程，它的主要任务就是烧水。副线程在进行比较耗时的时候主线程可以去干它自己喜欢的事情，等到空闲的时候再去检查副线程任务是否完成，然后获取任务执行结果。\n## 代码演示\n下面的代码演示上述场景：\n\n```\npackage com.winwill.test;\n\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.FutureTask;\n\n/**\n * @author qifuguang\n * @date 15/8/21 11:29\n */\npublic class TestFuture {\n    static class BoilWater implements Callable<String> {\n        public String call() throws Exception {\n            Thread.sleep(5000);            // 模拟一个耗时操作\n            return System.currentTimeMillis() + \" | 热水器：主人，水烧开了\";   //烧水完成\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        //创建一个线程池，相当于找到一个热水器\n        FutureTask futureTask = new FutureTask(new BoilWater());\n        // 开始烧水\n        // Executors.newCachedThreadPool().submit(futureTask); 这样使用线程池的形式，\n        // 结果是一样的\n        new Thread(futureTask).start();\n        System.out.println(System.currentTimeMillis() + \" | 我：小热，你可以开始烧水了...\");\n\n        // 继续打Dota\n        System.out.println(System.currentTimeMillis() + \" | 我：继续开心地玩Dota...\");\n        Thread.sleep(4000);\n        System.out.println(System.currentTimeMillis() + \" | 我：Oh，我死了...\");\n\n        // 被干了或者上对面高地了，有时间来检查水是否烧好了。\n        System.out.println(System.currentTimeMillis() + \" | 我：看看水烧好没...\");\n        while (!futureTask.isDone()) {\n            System.out.println(System.currentTimeMillis() + \" | 我：水还没烧开，小热，你快点烧，我再给你一秒钟...\");\n            Thread.sleep(1000);\n        }\n        // 使用get函数来获取烧水结果\n        System.out.println((String) futureTask.get());\n    }\n\n}\n```\n执行结果为：\n>1440129236549 | 我：小热，你可以开始烧水了...  \n>1440129236549 | 我：继续开心地玩Dota...  \n>1440129240554 | 我：Oh，我死了...  \n>1440129240554 | 我：看看水烧好没...  \n>1440129240554 | 我：水还没烧开，小热，你快点烧，我再给你一秒钟...  \n>1440129241553 | 热水器：主人，水烧开了   \n\n可以看到，我和小热分工明确，我玩dota，他烧水，**他烧水的时候我并没有傻傻地等着!**\n\n# 其他\nFutureTask类实现了Runnable接口和Callable接口，Runnable接口只能执行任务，不能获取结果，能用于new Thread()创建新线程，Callable接口能执行任务也能获取结果，但是却不能用于创建Thread。FutureTask兼具两者的优势！！！\n\n","source":"_posts/[Java并发包学习四]Future和FutureTask.md","raw":"title: \"[Java并发包学习四]Future和FutureTask\"\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-08-21 14:02:02\n---\n# 概述\nFuture主要用来表示线程异步执行的结果，他提供了检查异步执行的程序是否已经执行完毕、是否已经被取消，并且获取执行结果的方法。它是一个接口，接口的定义如下：\n<!--more-->\n```\npublic interface Future<V> {\n    boolean cancel(boolean mayInterruptIfRunning);\n    boolean isCancelled();\n    boolean isDone();\n    V get() throws InterruptedException, ExecutionException;\n    V get(long timeout, TimeUnit unit)\n        throws InterruptedException, ExecutionException, TimeoutException;\n}\n```\nJDK中的FutureTask类是这个接口的最基本的实现。\n\n# 成员函数介绍\n## cancel函数\ncancel函数用来取消一个正在异步执行的任务，如果任务还没有开始，则该任务将不会再被执行，如果任务已经在执行，则可以通过mayInterruptIfRunning参数来决定是否需要尝试取消正在执行的任务，如果mayInterruptIfRunning参数为**true**则将取消正在运行的任务，为**false**则不会打断，该任务能正常结束。    \n\n## isCanceled函数\nisCanceled函数用来判断一个任务是否已经被取消，如果一个任务在正常执行结束之前被取消，则该函数返回**true**，否则返回**false**。\n\n## isDone函数\nisDone函数用来检测一个任务是否已经结束，结束的原因可以分为以下几种情况：  \n\n* 正常完成； \n* 抛出异常而退出；\n* 被cancel函数取消；\n\n以上这三种情况，该函数都会返回**true**，否则返回**false**。\n\n## get函数\nget函数用来获取异步执行的结果，需要说明的是，对于没有参数的get函数，如果任务没有执行完毕，该函数会一直阻塞，直到任务结束，然后再返回执行的结果；而有timeout和unit两个参数的get函数能提供一个最长等待时间，如果过了给定的时间，任务仍然没有完毕，则抛出TimeoutException，否则返回任务执行结果。\n\n# 基本用法\n下面的例子演示怎么使用Future来获取异步执行的结果，假设这样一个场景：\n> 我们现在正在家里打dota(笔者是个dota爱好者^_^)，突然口渴了，想喝点白开水，于是我们需要烧开水，烧开水是一个比较耗时的事情，所以热水器(烧水线程)在烧开水的时候我们（主线程）不应该在一旁干等着，而是可以继续玩dota。等到被干死了之后或者上了别人高地之后再去检查开水是否已经烧好了。\n\n在这个场景中，我就好比是程序的主线程，而热水器就是我创建的副线程，它的主要任务就是烧水。副线程在进行比较耗时的时候主线程可以去干它自己喜欢的事情，等到空闲的时候再去检查副线程任务是否完成，然后获取任务执行结果。\n## 代码演示\n下面的代码演示上述场景：\n\n```\npackage com.winwill.test;\n\nimport java.util.concurrent.Callable;\nimport java.util.concurrent.FutureTask;\n\n/**\n * @author qifuguang\n * @date 15/8/21 11:29\n */\npublic class TestFuture {\n    static class BoilWater implements Callable<String> {\n        public String call() throws Exception {\n            Thread.sleep(5000);            // 模拟一个耗时操作\n            return System.currentTimeMillis() + \" | 热水器：主人，水烧开了\";   //烧水完成\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        //创建一个线程池，相当于找到一个热水器\n        FutureTask futureTask = new FutureTask(new BoilWater());\n        // 开始烧水\n        // Executors.newCachedThreadPool().submit(futureTask); 这样使用线程池的形式，\n        // 结果是一样的\n        new Thread(futureTask).start();\n        System.out.println(System.currentTimeMillis() + \" | 我：小热，你可以开始烧水了...\");\n\n        // 继续打Dota\n        System.out.println(System.currentTimeMillis() + \" | 我：继续开心地玩Dota...\");\n        Thread.sleep(4000);\n        System.out.println(System.currentTimeMillis() + \" | 我：Oh，我死了...\");\n\n        // 被干了或者上对面高地了，有时间来检查水是否烧好了。\n        System.out.println(System.currentTimeMillis() + \" | 我：看看水烧好没...\");\n        while (!futureTask.isDone()) {\n            System.out.println(System.currentTimeMillis() + \" | 我：水还没烧开，小热，你快点烧，我再给你一秒钟...\");\n            Thread.sleep(1000);\n        }\n        // 使用get函数来获取烧水结果\n        System.out.println((String) futureTask.get());\n    }\n\n}\n```\n执行结果为：\n>1440129236549 | 我：小热，你可以开始烧水了...  \n>1440129236549 | 我：继续开心地玩Dota...  \n>1440129240554 | 我：Oh，我死了...  \n>1440129240554 | 我：看看水烧好没...  \n>1440129240554 | 我：水还没烧开，小热，你快点烧，我再给你一秒钟...  \n>1440129241553 | 热水器：主人，水烧开了   \n\n可以看到，我和小热分工明确，我玩dota，他烧水，**他烧水的时候我并没有傻傻地等着!**\n\n# 其他\nFutureTask类实现了Runnable接口和Callable接口，Runnable接口只能执行任务，不能获取结果，能用于new Thread()创建新线程，Callable接口能执行任务也能获取结果，但是却不能用于创建Thread。FutureTask兼具两者的优势！！！\n\n","slug":"[Java并发包学习四]Future和FutureTask","published":1,"updated":"2015-08-30T11:17:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3doval001qlo6bmn2o3yu7"},{"title":"[Java并发包学习六]Semaphore介绍","date":"2015-08-25T16:36:36.000Z","_content":"# 概述\nemaphore字面意思是信号量。他主要用于控制有限的资源的访问数量。我们看一个生活中常常出现的场景：\n<!--more-->\n> 一个厕所只有3个坑位，但是有10个人来上厕所，那怎么办？假设10的人的编号分别为1-10，并且1号先到厕所，10号最后到厕所。那么1-3号来的时候必然有可用坑位，顺利如厕，4号来的时候需要看看前面3人是否有人出来了，如果有人出来，进去，否则等待。同样的道理，4-10号也需要等待正在上厕所的人出来后才能进去，并且谁先进去这得看等待的人是否有素质，是否能遵守先来先上的规则。\n\n\n在这种场景下，Semaphore便派上了用场。\n# 基本函数介绍\n## 构造函数\n构造函数使用一个初始非零整数初始化Semaphore，表示最开始的时候的可用资源（上例中的厕所坑位）数量。有两种类型的构造函数，函数签名分别如下：\n\n```\npublic Semaphore(int permits)\npublic Semaphore(int permits, boolean fair)\n```\n其中permits参数表示初始的可用资源数量，fair参数表示是否使用公平策略（是否按照先来线上的顺序）选择正在等候的使用者（上例中的上厕所的人），fair为**true**表示公平策略，采用先来先用的算法，为**false**表示非公平策略，完全随机，默认使用非公平策略。\n\n## acquire函数\nacquire函数用来申请资源，有两种不同的函数，签名分别如下：\n\n```\npublic void acquire() throws InterruptedException \npublic void acquire(int permits) throws InterruptedException\n```\n第一个函数用来申请一个资源，第二个函数用来申请permits个资源，当没有需要申请的数量这么多个资源时，申请线程会被阻塞，直到有可用资源或者申请线程被打断，如果申请线程被打断，则抛出InterruptedException异常。\n\n## acquireUninterruptibly函数\n翻译过来就是不可能被打断的申请，对，该函数用来申请可用资源，并且不会被打断，也有两种类型，函数签名分别如下：\n\n```\npublic void acquireUninterruptibly()\npublic void acquireUninterruptibly(int permits)\n```\n第一个函数用来申请一个资源，第二个函数用来申请permits个资源。就算线程在申请资源过程中被打断，依然会继续申请，只不过获取资源的时间可能会有所变化。\n\n## tryAcquire函数\ntryAcquire函数用来获取可用资源，但是这类函数能够有时间的限制，如果超时，立即返回，有几种类型的函数，签名分别如下：\n\n```\npublic boolean tryAcquire()\npublic boolean tryAcquire(long timeout, TimeUnit unit)\n        throws InterruptedException\npublic boolean tryAcquire(int permits)\npublic boolean tryAcquire(int permits, long timeout, TimeUnit unit)\n        throws InterruptedException\n```\n1. 第一个函数用来申请一个资源，如果当前有可用资源，立即返回true，否则立即返回false；\n2. 第二个函数用来申请一个资源，指定一个超时时间，如果当前可以资源数量足够，立即返回true，否则最多等待给定的时间，如果时间到还是未能获取资源，则返回false；如果等待过程中线程被打断，抛出InterruptedException异常；\n3. 和1一样，只是申请permits个资源；\n4. 和2一样，只是申请permits个资源。\n\n## release函数\nrelease函数用来释放资源，就好比说蹲厕所的人出来了，让出了坑位。有两种类型，函数签名分别如下：\n\n```\npublic void release()\npublic void release(int permits)\n```\n第一个函数释放一个资源，第二个函数释放permits个资源。\n\n## availablePermits函数\navailablePermits函数用来获取当前可用的资源数量，函数签名如下：\n\n```\npublic int availablePermits()\n```\n\n## drainPermits函数\ndrainPermits函数用来申请当前所有可用的资源，函数签名如下：\n\n```\npublic int drainPermits()\n```\n函数返回申请到的资源的个数。\n\n## reducePermits函数\nreducePermits函数用来禁止某些资源不可用，函数签名如下：\n\n```\nprotected void reducePermits(int reduction)\n```\nreduction表示禁止的数量，比如由于厕所马桶坏了，有一个坑位不能用，此时就可以调用该函数禁止一个资源不可用。如果reduction小于零，则抛出IllegalArgumentException异常。\n\n## isFair函数\nisFair函数用来判断当前的信号量是采用什么类型的策略，函数签名如下：\n\n```\npublic boolean isFair()\n```\n函数返回**true**表示采用的是公平策略，返回**false**表示采用非公平策略。\n\n## hasQueuedThreads函数\nhasQueuedThreads函数用来判断是否有现成正在等待申请资源，函数签名如下：\n\n```\npublic final boolean hasQueuedThreads()\n```\n返回**true**表示有现成正在等待申请资源，**false**表示没有，需要注意的是：**因为申请过程是可以取消的，函数返回true并不表示肯定会申请资源，该函数设计的初衷是用来做系统监控的。**\n\n## getQueueLength函数\ngetQueueLength函数用来返回正在等待申请资源的线程的数量，函数签名如下：\n\n```\npublic final int getQueueLength()\n```\n返回当前正在等待申请资源的线程数。\n\n## getQueuedThreads函数\ngetQueuedThreads函数返回当前正在等待申请资源的线程集合，函数签名如下：\n\n```\nprotected Collection<Thread> getQueuedThreads()\n```\n\n# 模拟实验\n下面用代码来模拟如下场景：\n\n> 一个厕所只有3个坑位，有6个人（编号1-6）先后来上厕所，采用先来先上的策略。\n\n代码如下:\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.Semaphore;\n\n/**\n * @author qifuguang\n * @date 15/8/25 23:23\n */\npublic class TestSemaphore {\n    public static void main(String[] args) throws Exception {\n        Semaphore wc = new Semaphore(3, true); // 3个坑位\n        for (int i = 1; i <= 6; i++) {\n            Thread t = new Thread(new Person(\"第\" + i + \"个人\", wc));\n            t.start();\n            Thread.sleep(new Random().nextInt(300));\n        }\n    }\n\n    static class Person implements Runnable {\n        private String name;\n        private Semaphore wc;\n\n        public Person(String name, Semaphore wc) {\n            this.name = name;\n            this.wc = wc;\n        }\n\n        public void run() {\n            System.out.print(name + \"：憋死老子了!\");\n            if (wc.availablePermits() > 0) {\n                System.out.println(\"天助我也，有坑位！\");\n            } else {\n                System.out.println(\"卧槽，没坑位了，等会儿吧...\");\n            }\n            try {\n                wc.acquire(); //申请坑位\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：终于轮到我了，拉屎就是爽！\");\n            try {\n                Thread.sleep(new Random().nextInt(1000)); // 模拟上厕所时间。\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：拉完了，好臭!\");\n            wc.release();\n        }\n    }\n}\n```\n运行结果：\n>第1个人：憋死老子了!天助我也，有坑位！  \n第1个人：终于轮到我了，拉屎就是爽！  \n第2个人：憋死老子了!天助我也，有坑位！  \n第2个人：终于轮到我了，拉屎就是爽！  \n第3个人：憋死老子了!天助我也，有坑位！  \n第3个人：终于轮到我了，拉屎就是爽！  \n第3个人：拉完了，好臭!  \n第4个人：憋死老子了!天助我也，有坑位！  \n第4个人：终于轮到我了，拉屎就是爽！  \n第5个人：憋死老子了!卧槽，没坑位了，等会儿吧...  \n第6个人：憋死老子了!卧槽，没坑位了，等会儿吧...  \n第2个人：拉完了，好臭!  \n第5个人：终于轮到我了，拉屎就是爽！  \n第4个人：拉完了，好臭!  \n第6个人：终于轮到我了，拉屎就是爽！  \n第1个人：拉完了，好臭!  \n第6个人：拉完了，好臭!  \n第5个人：拉完了，好臭!  \n\n可以看到，任何时候在用坑位的人数都控制在3人之内，并且开始蹲坑的顺序一定是按编号从小到大来的（公平策略）。\n\n# 注意事项\n* release函数和acquire并没有要求一定是同一个线程都调用，可以A线程申请资源，B线程释放资源；\n* 调用release函数之前并没有要求一定要先调用acquire函数。\n","source":"_posts/[Java并发包学习六]Semaphore介绍.md","raw":"title: '[Java并发包学习六]Semaphore介绍'\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-08-26 00:36:36\n---\n# 概述\nemaphore字面意思是信号量。他主要用于控制有限的资源的访问数量。我们看一个生活中常常出现的场景：\n<!--more-->\n> 一个厕所只有3个坑位，但是有10个人来上厕所，那怎么办？假设10的人的编号分别为1-10，并且1号先到厕所，10号最后到厕所。那么1-3号来的时候必然有可用坑位，顺利如厕，4号来的时候需要看看前面3人是否有人出来了，如果有人出来，进去，否则等待。同样的道理，4-10号也需要等待正在上厕所的人出来后才能进去，并且谁先进去这得看等待的人是否有素质，是否能遵守先来先上的规则。\n\n\n在这种场景下，Semaphore便派上了用场。\n# 基本函数介绍\n## 构造函数\n构造函数使用一个初始非零整数初始化Semaphore，表示最开始的时候的可用资源（上例中的厕所坑位）数量。有两种类型的构造函数，函数签名分别如下：\n\n```\npublic Semaphore(int permits)\npublic Semaphore(int permits, boolean fair)\n```\n其中permits参数表示初始的可用资源数量，fair参数表示是否使用公平策略（是否按照先来线上的顺序）选择正在等候的使用者（上例中的上厕所的人），fair为**true**表示公平策略，采用先来先用的算法，为**false**表示非公平策略，完全随机，默认使用非公平策略。\n\n## acquire函数\nacquire函数用来申请资源，有两种不同的函数，签名分别如下：\n\n```\npublic void acquire() throws InterruptedException \npublic void acquire(int permits) throws InterruptedException\n```\n第一个函数用来申请一个资源，第二个函数用来申请permits个资源，当没有需要申请的数量这么多个资源时，申请线程会被阻塞，直到有可用资源或者申请线程被打断，如果申请线程被打断，则抛出InterruptedException异常。\n\n## acquireUninterruptibly函数\n翻译过来就是不可能被打断的申请，对，该函数用来申请可用资源，并且不会被打断，也有两种类型，函数签名分别如下：\n\n```\npublic void acquireUninterruptibly()\npublic void acquireUninterruptibly(int permits)\n```\n第一个函数用来申请一个资源，第二个函数用来申请permits个资源。就算线程在申请资源过程中被打断，依然会继续申请，只不过获取资源的时间可能会有所变化。\n\n## tryAcquire函数\ntryAcquire函数用来获取可用资源，但是这类函数能够有时间的限制，如果超时，立即返回，有几种类型的函数，签名分别如下：\n\n```\npublic boolean tryAcquire()\npublic boolean tryAcquire(long timeout, TimeUnit unit)\n        throws InterruptedException\npublic boolean tryAcquire(int permits)\npublic boolean tryAcquire(int permits, long timeout, TimeUnit unit)\n        throws InterruptedException\n```\n1. 第一个函数用来申请一个资源，如果当前有可用资源，立即返回true，否则立即返回false；\n2. 第二个函数用来申请一个资源，指定一个超时时间，如果当前可以资源数量足够，立即返回true，否则最多等待给定的时间，如果时间到还是未能获取资源，则返回false；如果等待过程中线程被打断，抛出InterruptedException异常；\n3. 和1一样，只是申请permits个资源；\n4. 和2一样，只是申请permits个资源。\n\n## release函数\nrelease函数用来释放资源，就好比说蹲厕所的人出来了，让出了坑位。有两种类型，函数签名分别如下：\n\n```\npublic void release()\npublic void release(int permits)\n```\n第一个函数释放一个资源，第二个函数释放permits个资源。\n\n## availablePermits函数\navailablePermits函数用来获取当前可用的资源数量，函数签名如下：\n\n```\npublic int availablePermits()\n```\n\n## drainPermits函数\ndrainPermits函数用来申请当前所有可用的资源，函数签名如下：\n\n```\npublic int drainPermits()\n```\n函数返回申请到的资源的个数。\n\n## reducePermits函数\nreducePermits函数用来禁止某些资源不可用，函数签名如下：\n\n```\nprotected void reducePermits(int reduction)\n```\nreduction表示禁止的数量，比如由于厕所马桶坏了，有一个坑位不能用，此时就可以调用该函数禁止一个资源不可用。如果reduction小于零，则抛出IllegalArgumentException异常。\n\n## isFair函数\nisFair函数用来判断当前的信号量是采用什么类型的策略，函数签名如下：\n\n```\npublic boolean isFair()\n```\n函数返回**true**表示采用的是公平策略，返回**false**表示采用非公平策略。\n\n## hasQueuedThreads函数\nhasQueuedThreads函数用来判断是否有现成正在等待申请资源，函数签名如下：\n\n```\npublic final boolean hasQueuedThreads()\n```\n返回**true**表示有现成正在等待申请资源，**false**表示没有，需要注意的是：**因为申请过程是可以取消的，函数返回true并不表示肯定会申请资源，该函数设计的初衷是用来做系统监控的。**\n\n## getQueueLength函数\ngetQueueLength函数用来返回正在等待申请资源的线程的数量，函数签名如下：\n\n```\npublic final int getQueueLength()\n```\n返回当前正在等待申请资源的线程数。\n\n## getQueuedThreads函数\ngetQueuedThreads函数返回当前正在等待申请资源的线程集合，函数签名如下：\n\n```\nprotected Collection<Thread> getQueuedThreads()\n```\n\n# 模拟实验\n下面用代码来模拟如下场景：\n\n> 一个厕所只有3个坑位，有6个人（编号1-6）先后来上厕所，采用先来先上的策略。\n\n代码如下:\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.Semaphore;\n\n/**\n * @author qifuguang\n * @date 15/8/25 23:23\n */\npublic class TestSemaphore {\n    public static void main(String[] args) throws Exception {\n        Semaphore wc = new Semaphore(3, true); // 3个坑位\n        for (int i = 1; i <= 6; i++) {\n            Thread t = new Thread(new Person(\"第\" + i + \"个人\", wc));\n            t.start();\n            Thread.sleep(new Random().nextInt(300));\n        }\n    }\n\n    static class Person implements Runnable {\n        private String name;\n        private Semaphore wc;\n\n        public Person(String name, Semaphore wc) {\n            this.name = name;\n            this.wc = wc;\n        }\n\n        public void run() {\n            System.out.print(name + \"：憋死老子了!\");\n            if (wc.availablePermits() > 0) {\n                System.out.println(\"天助我也，有坑位！\");\n            } else {\n                System.out.println(\"卧槽，没坑位了，等会儿吧...\");\n            }\n            try {\n                wc.acquire(); //申请坑位\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：终于轮到我了，拉屎就是爽！\");\n            try {\n                Thread.sleep(new Random().nextInt(1000)); // 模拟上厕所时间。\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：拉完了，好臭!\");\n            wc.release();\n        }\n    }\n}\n```\n运行结果：\n>第1个人：憋死老子了!天助我也，有坑位！  \n第1个人：终于轮到我了，拉屎就是爽！  \n第2个人：憋死老子了!天助我也，有坑位！  \n第2个人：终于轮到我了，拉屎就是爽！  \n第3个人：憋死老子了!天助我也，有坑位！  \n第3个人：终于轮到我了，拉屎就是爽！  \n第3个人：拉完了，好臭!  \n第4个人：憋死老子了!天助我也，有坑位！  \n第4个人：终于轮到我了，拉屎就是爽！  \n第5个人：憋死老子了!卧槽，没坑位了，等会儿吧...  \n第6个人：憋死老子了!卧槽，没坑位了，等会儿吧...  \n第2个人：拉完了，好臭!  \n第5个人：终于轮到我了，拉屎就是爽！  \n第4个人：拉完了，好臭!  \n第6个人：终于轮到我了，拉屎就是爽！  \n第1个人：拉完了，好臭!  \n第6个人：拉完了，好臭!  \n第5个人：拉完了，好臭!  \n\n可以看到，任何时候在用坑位的人数都控制在3人之内，并且开始蹲坑的顺序一定是按编号从小到大来的（公平策略）。\n\n# 注意事项\n* release函数和acquire并没有要求一定是同一个线程都调用，可以A线程申请资源，B线程释放资源；\n* 调用release函数之前并没有要求一定要先调用acquire函数。\n","slug":"[Java并发包学习六]Semaphore介绍","published":1,"updated":"2015-08-25T16:40:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovao001vlo6b91g5tgte"},{"title":"[Java并发包学习八]深度剖析ConcurrentHashMap","date":"2015-09-10T15:07:52.000Z","_content":"# 概述\n还记得大学快毕业的时候要准备找工作了，然后就看各种面试相关的书籍，还记得很多面试书中都说到：\n> HashMap是非线程安全的，HashTable是线程安全的。\n\n那个时候没怎么写Java代码，所以根本就没有听说过ConcurrentHashMap，只知道面试的时候就记住这句话就行了...至于为什么是线程安全的，内部怎么实现的，通通不了解。\n<!--more-->\n今天我们将深入剖析一个比HashTable性能更优的线程安全的Map类，它就是ConcurrentHashMap，**本文基于Java 7的源码做剖析**。\n\n# ConcurrentHashMap的目的\n多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。虽然已经有一个线程安全的HashTable，但是HashTable容器使用synchronized（他的get和put方法的实现代码如下）来保证线程安全，在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，访问其他同步方法的线程就可能会进入阻塞或者轮训状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。\n\n```\n    public synchronized V get(Object key) {\n        Entry<?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash & 0x7FFFFFFF) % tab.length;\n        for (Entry<?,?> e = tab[index] ; e != null ; e = e.next) {\n            if ((e.hash == hash) && e.key.equals(key)) {\n                return (V)e.value;\n            }\n        }\n        return null;\n    }\n    public synchronized V put(K key, V value) {\n        // Make sure the value is not null\n        if (value == null) {\n            throw new NullPointerException();\n        }\n\n        // Makes sure the key is not already in the hashtable.\n        Entry<?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash & 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry<K,V> entry = (Entry<K,V>)tab[index];\n        for(; entry != null ; entry = entry.next) {\n            if ((entry.hash == hash) && entry.key.equals(key)) {\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            }\n        }\n\n        addEntry(hash, key, value, index);\n        return null;\n    }\n```\n\n在这么恶劣的环境下，ConcurrentHashMap应运而生。\n\n# 实现原理\nConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/深入剖析ConcurrentHashMap/ConcurrentHashMap.png)\n从图中可以看到，ConcurrentHashMap内部分为很多个Segment，每一个Segment拥有一把锁，然后每个Segment（继承ReentrantLock）下面包含很多个HashEntry列表数组。对于一个key，需要经过三次（为什么要hash三次下文会详细讲解）hash操作，才能最终定位这个元素的位置，这三次hash分别为：\n\n1. 对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)；\n2. 将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment；\n3. 将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。\n\n## 初始化\n先看看ConcurrentHashMap的初始化做了哪些事情，构造函数的源码如下：\n\n```\npublic ConcurrentHashMap(int initialCapacity,\n                             float loadFactor, int concurrencyLevel) {\n        if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)\n            throw new IllegalArgumentException();\n        if (concurrencyLevel > MAX_SEGMENTS)\n            concurrencyLevel = MAX_SEGMENTS;\n        // Find power-of-two sizes best matching arguments\n        int sshift = 0;\n        int ssize = 1;\n        while (ssize < concurrencyLevel) {\n            ++sshift;\n            ssize <<= 1;\n        }\n        this.segmentShift = 32 - sshift;\n        this.segmentMask = ssize - 1;\n        if (initialCapacity > MAXIMUM_CAPACITY)\n            initialCapacity = MAXIMUM_CAPACITY;\n        int c = initialCapacity / ssize;\n        if (c * ssize < initialCapacity)\n            ++c;\n        int cap = MIN_SEGMENT_TABLE_CAPACITY;\n        while (cap < c)\n            cap <<= 1;\n        // create segments and segments[0]\n        Segment<K,V> s0 =\n            new Segment<K,V>(loadFactor, (int)(cap * loadFactor),\n                             (HashEntry<K,V>[])new HashEntry[cap]);\n        Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];\n        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]\n        this.segments = ss;\n    }\n```\n传入的参数有initialCapacity，loadFactor，concurrencyLevel这三个。\n\n* initialCapacity表示新创建的这个ConcurrentHashMap的初始容量，也就是上面的结构图中的Entry数量。默认值为`static final int DEFAULT_INITIAL_CAPACITY = 16;`\n* loadFactor表示负载因子，就是当ConcurrentHashMap中的元素个数大于**loadFactor * 最大容量**时就需要rehash，扩容。默认值为`static final float DEFAULT_LOAD_FACTOR = 0.75f;`\n* concurrencyLevel表示并发级别，这个值用来确定Segment的个数，Segment的个数是大于等于concurrencyLevel的第一个2的n次方的数。比如，如果concurrencyLevel为12，13，14，15，16这些数，则Segment的数目为16(2的4次方)。默认值为`static final int DEFAULT_CONCURRENCY_LEVEL = 16;`。理想情况下ConcurrentHashMap的真正的并发访问量能够达到concurrencyLevel，因为有concurrencyLevel个Segment，假如有concurrencyLevel个线程需要访问Map，并且需要访问的数据都恰好分别落在不同的Segment中，则这些线程能够无竞争地自由访问（因为他们不需要竞争同一把锁），达到同时访问的效果。这也是为什么这个参数起名为“并发级别”的原因。\n\n初始化的一些动作：\n\n1. 验证参数的合法性，如果不合法，直接抛出异常。\n2. concurrencyLevel也就是Segment的个数不能超过规定的最大Segment的个数，默认值为`static final int MAX_SEGMENTS = 1 << 16;`，如果超过这个值，设置为这个值。\n3. 然后使用循环找到大于等于concurrencyLevel的第一个2的n次方的数ssize，这个数就是Segment数组的大小，并记录一共向左按位移动的次数sshift，并令`segmentShift = 32 - sshift`，并且segmentMask的值等于ssize - 1，segmentMask的各个二进制位都为1，目的是之后可以通过key的hash值与这个值做**&运算**确定Segment的索引。\n4. 检查给的容量值是否大于允许的最大容量值，如果大于该值，设置为该值。最大容量值为`static final int MAXIMUM_CAPACITY = 1 << 30;`。\n5. 然后计算每个Segment平均应该放置多少个元素，这个值c是向上取整的值。比如初始容量为15，Segment个数为4，则每个Segment平均需要放置4个元素。\n6. 最后创建一个Segment实例，将其当做Segment数组的第一个元素。\n\n## put操作\nput操作的源码如下：\n\n```\n  public V put(K key, V value) {\n        Segment<K,V> s;\n        if (value == null)\n            throw new NullPointerException();\n        int hash = hash(key);\n        int j = (hash >>> segmentShift) & segmentMask;\n        if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck\n             (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment\n            s = ensureSegment(j);\n        return s.put(key, hash, value, false);\n    }\n```\n操作步骤如下：\n\n1. 判断value是否为null，如果为null，直接抛出异常。\n2. key通过一次hash运算得到一个hash值。(这个hash运算下文详说)\n3. 将得到hash值向右按位移动segmentShift位，然后再与segmentMask做&运算得到segment的索引j。\n   在初始化的时候我们说过segmentShift的值等于32-sshift，例如concurrencyLevel等于16，则sshift等于4，则segmentShift为28。hash值是一个32位的整数，将其向右移动28位就变成这个样子：\n   0000 0000 0000 0000 0000 0000 0000 xxxx，然后再用这个值与segmentMask做&运算，也就是取最后四位的值。这个值确定Segment的索引。\n4. 使用Unsafe的方式从Segment数组中获取该索引对应的Segment对象。\n5. 向这个Segment对象中put值，这个put操作也基本是一样的步骤（通过&运算获取HashEntry的索引，然后set）。\n\n\n\n## get操作\nget操作的源码如下：\n\n```\npublic V get(Object key) {\n        Segment<K,V> s; // manually integrate access methods to reduce overhead\n        HashEntry<K,V>[] tab;\n        int h = hash(key);\n        long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;\n        if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&\n            (tab = s.table) != null) {\n            for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile\n                     (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);\n                 e != null; e = e.next) {\n                K k;\n                if ((k = e.key) == key || (e.hash == h && key.equals(k)))\n                    return e.value;\n            }\n        }\n        return null;\n    }\n```\n操作步骤为：\n\n1. 和put操作一样，先通过key进行两次hash确定应该去哪个Segment中取数据。\n2. 使用Unsafe获取对应的Segment，然后再进行一次&运算得到HashEntry链表的位置，然后从链表头开始遍历整个链表（因为Hash可能会有碰撞，所以用一个链表保存），如果找到对应的key，则返回对应的value值，如果链表遍历完都没有找到对应的key，则说明Map中不包含该key，返回null。\n\n\n## size操作\nsize操作与put和get操作最大的区别在于，size操作需要遍历所有的Segment才能算出整个Map的大小，而put和get都只关心一个Segment。假设我们当前遍历的Segment为SA，那么在遍历SA过程中其他的Segment比如SB可能会被修改，于是这一次运算出来的size值可能并不是Map当前的真正大小。所以一个比较简单的办法就是计算Map大小的时候所有的Segment都Lock住，不能更新(包含put，remove等等)数据，计算完之后再Unlock。这是普通人能够想到的方案，但是牛逼的作者还有一个更好的Idea：**先给3次机会，不lock所有的Segment，遍历所有Segment，累加各个Segment的大小得到整个Map的大小，如果某相邻的两次计算获取的所有Segment的更新的次数（每个Segment都有一个modCount变量，这个变量在Segment中的Entry被修改时会加一，通过这个值可以得到每个Segment的更新操作的次数）是一样的，说明计算过程中没有更新操作，则直接返回这个值。如果这三次不加锁的计算过程中Map的更新次数有变化，则之后的计算先对所有的Segment加锁，再遍历所有Segment计算Map大小，最后再解锁所有Segment。**源代码如下：\n\n```\npublic int size() {\n        // Try a few times to get accurate count. On failure due to\n        // continuous async changes in table, resort to locking.\n        final Segment<K,V>[] segments = this.segments;\n        int size;\n        boolean overflow; // true if size overflows 32 bits\n        long sum;         // sum of modCounts\n        long last = 0L;   // previous sum\n        int retries = -1; // first iteration isn't retry\n        try {\n            for (;;) {\n                if (retries++ == RETRIES_BEFORE_LOCK) {\n                    for (int j = 0; j < segments.length; ++j)\n                        ensureSegment(j).lock(); // force creation\n                }\n                sum = 0L;\n                size = 0;\n                overflow = false;\n                for (int j = 0; j < segments.length; ++j) {\n                    Segment<K,V> seg = segmentAt(segments, j);\n                    if (seg != null) {\n                        sum += seg.modCount;\n                        int c = seg.count;\n                        if (c < 0 || (size += c) < 0)\n                            overflow = true;\n                    }\n                }\n                if (sum == last)\n                    break;\n                last = sum;\n            }\n        } finally {\n            if (retries > RETRIES_BEFORE_LOCK) {\n                for (int j = 0; j < segments.length; ++j)\n                    segmentAt(segments, j).unlock();\n            }\n        }\n        return overflow ? Integer.MAX_VALUE : size;\n    }\n```\n举个例子：\n> 一个Map有4个Segment，标记为S1，S2，S3，S4，现在我们要获取Map的size。计算过程是这样的：第一次计算，不对S1，S2，S3，S4加锁，遍历所有的Segment，假设每个Segment的大小分别为1，2，3，4，更新操作次数分别为：2，2，3，1，则这次计算可以得到Map的总大小为1+2+3+4=10，总共更新操作次数为2+2+3+1=8；第二次计算，不对S1,S2,S3,S4加锁，遍历所有Segment，假设这次每个Segment的大小变成了2，2，3，4，更新次数分别为3，2，3，1，因为两次计算得到的Map更新次数不一致(第一次是8，第二次是9)则可以断定这段时间Map数据被更新，则此时应该再试一次；第三次计算，不对S1，S2，S3，S4加锁，遍历所有Segment，假设每个Segment的更新操作次数还是为3，2，3，1，则因为第二次计算和第三次计算得到的Map的更新操作的次数是一致的，就能说明第二次计算和第三次计算这段时间内Map数据没有被更新，此时可以直接返回第三次计算得到的Map的大小。最坏的情况：第三次计算得到的数据更新次数和第二次也不一样，则只能先对所有Segment加锁再计算最后解锁。\n\n\n## containsValue操作\ncontainsValue操作采用了和size操作一样的想法:\n\n```\npublic boolean containsValue(Object value) {\n        // Same idea as size()\n        if (value == null)\n            throw new NullPointerException();\n        final Segment<K,V>[] segments = this.segments;\n        boolean found = false;\n        long last = 0;\n        int retries = -1;\n        try {\n            outer: for (;;) {\n                if (retries++ == RETRIES_BEFORE_LOCK) {\n                    for (int j = 0; j < segments.length; ++j)\n                        ensureSegment(j).lock(); // force creation\n                }\n                long hashSum = 0L;\n                int sum = 0;\n                for (int j = 0; j < segments.length; ++j) {\n                    HashEntry<K,V>[] tab;\n                    Segment<K,V> seg = segmentAt(segments, j);\n                    if (seg != null && (tab = seg.table) != null) {\n                        for (int i = 0 ; i < tab.length; i++) {\n                            HashEntry<K,V> e;\n                            for (e = entryAt(tab, i); e != null; e = e.next) {\n                                V v = e.value;\n                                if (v != null && value.equals(v)) {\n                                    found = true;\n                                    break outer;\n                                }\n                            }\n                        }\n                        sum += seg.modCount;\n                    }\n                }\n                if (retries > 0 && sum == last)\n                    break;\n                last = sum;\n            }\n        } finally {\n            if (retries > RETRIES_BEFORE_LOCK) {\n                for (int j = 0; j < segments.length; ++j)\n                    segmentAt(segments, j).unlock();\n            }\n        }\n        return found;\n    }\n```\n\n# 关于hash\n大家一定还记得使用一个key定位Segment之前进行过一次hash操作吧？这次hash的作用是什么呢？看看hash的源代码：\n\n```\nprivate int hash(Object k) {\n        int h = hashSeed;\n\n        if ((0 != h) && (k instanceof String)) {\n            return sun.misc.Hashing.stringHash32((String) k);\n        }\n\n        h ^= k.hashCode();\n\n        // Spread bits to regularize both segment and index locations,\n        // using variant of single-word Wang/Jenkins hash.\n        h += (h <<  15) ^ 0xffffcd7d;\n        h ^= (h >>> 10);\n        h += (h <<   3);\n        h ^= (h >>>  6);\n        h += (h <<   2) + (h << 14);\n        return h ^ (h >>> 16);\n    }\n```\n源码中的注释是这样的：\n>Applies a supplemental hash function to a given hashCode, which defends against poor quality hash functions.  This is critical because ConcurrentHashMap uses power-of-two length hash tables, that otherwise encounter collisions for hashCodes that do not differ in lower or upper bits.\n \n这里用到了Wang/Jenkins hash算法的变种，主要的目的是为了减少哈希冲突，使元素能够均匀的分布在不同的Segment上，从而提高容器的存取效率。假如哈希的质量差到极点，那么所有的元素都在一个Segment中，不仅存取元素缓慢，分段锁也会失去意义。\n\n举个简单的例子：\n\n```\nSystem.out.println(Integer.parseInt(\"0001111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"0011111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"0111111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"1111111\", 2) & 15);\n\n```\n这些数字得到的hash值都是一样的，全是15，所以如果不进行第一次预hash，发生冲突的几率还是很大的，但是如果我们先把上例中的二进制数字使用hash()函数先进行一次预hash，得到的结果是这样的：\n>0100｜0111｜0110｜0111｜1101｜1010｜0100｜1110  \n1111｜0111｜0100｜0011｜0000｜0001｜1011｜1000  \n0111｜0111｜0110｜1001｜0100｜0110｜0011｜1110  \n1000｜0011｜0000｜0000｜1100｜1000｜0001｜1010  \n\n上面这个例子引用自: [InfoQ](http://www.infoq.com/cn/articles/ConcurrentHashMap/)\n可以看到每一位的数据都散开了，并且ConcurrentHashMap中是使用预hash值的高位参与运算的。比如之前说的先将hash值向右按位移动28位，再与15做&运算，得到的结果都别为：4，15，7，8，没有冲突！\n\n# 注意事项\n\n* ConcurrentHashMap中的key和value值都不能为null。\n* ConcurrentHashMap的整个操作过程中大量使用了Unsafe类来获取Segment/HashEntry，这里Unsafe的主要作用是提供原子操作。Unsafe这个类比较恐怖，破坏力极强，一般场景不建议使用，如果有兴趣可以到这里做详细的了解[Java中鲜为人知的特性](http://blog.csdn.net/fenglibing/article/details/17138079)\n* ConcurrentHashMap是线程安全的类并不能保证使用了ConcurrentHashMap的操作都是线程安全的！\n* 本文为作者个人理解，如果有误，请留言相告，感激不尽。\n* 转载请注明出处：[http://qifuguang.me/2015/09/10/[Java并发包学习八]深度剖析ConcurrentHashMap/](http://qifuguang.me/2015/09/10/[Java并发包学习八]深度剖析ConcurrentHashMap/)\n\n\n","source":"_posts/[Java并发包学习八]深度剖析ConcurrentHashMap.md","raw":"title: '[Java并发包学习八]深度剖析ConcurrentHashMap'\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-09-10 23:07:52\n---\n# 概述\n还记得大学快毕业的时候要准备找工作了，然后就看各种面试相关的书籍，还记得很多面试书中都说到：\n> HashMap是非线程安全的，HashTable是线程安全的。\n\n那个时候没怎么写Java代码，所以根本就没有听说过ConcurrentHashMap，只知道面试的时候就记住这句话就行了...至于为什么是线程安全的，内部怎么实现的，通通不了解。\n<!--more-->\n今天我们将深入剖析一个比HashTable性能更优的线程安全的Map类，它就是ConcurrentHashMap，**本文基于Java 7的源码做剖析**。\n\n# ConcurrentHashMap的目的\n多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap。虽然已经有一个线程安全的HashTable，但是HashTable容器使用synchronized（他的get和put方法的实现代码如下）来保证线程安全，在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，访问其他同步方法的线程就可能会进入阻塞或者轮训状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。\n\n```\n    public synchronized V get(Object key) {\n        Entry<?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash & 0x7FFFFFFF) % tab.length;\n        for (Entry<?,?> e = tab[index] ; e != null ; e = e.next) {\n            if ((e.hash == hash) && e.key.equals(key)) {\n                return (V)e.value;\n            }\n        }\n        return null;\n    }\n    public synchronized V put(K key, V value) {\n        // Make sure the value is not null\n        if (value == null) {\n            throw new NullPointerException();\n        }\n\n        // Makes sure the key is not already in the hashtable.\n        Entry<?,?> tab[] = table;\n        int hash = key.hashCode();\n        int index = (hash & 0x7FFFFFFF) % tab.length;\n        @SuppressWarnings(\"unchecked\")\n        Entry<K,V> entry = (Entry<K,V>)tab[index];\n        for(; entry != null ; entry = entry.next) {\n            if ((entry.hash == hash) && entry.key.equals(key)) {\n                V old = entry.value;\n                entry.value = value;\n                return old;\n            }\n        }\n\n        addEntry(hash, key, value, index);\n        return null;\n    }\n```\n\n在这么恶劣的环境下，ConcurrentHashMap应运而生。\n\n# 实现原理\nConcurrentHashMap使用分段锁技术，将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。如下图是ConcurrentHashMap的内部结构图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/深入剖析ConcurrentHashMap/ConcurrentHashMap.png)\n从图中可以看到，ConcurrentHashMap内部分为很多个Segment，每一个Segment拥有一把锁，然后每个Segment（继承ReentrantLock）下面包含很多个HashEntry列表数组。对于一个key，需要经过三次（为什么要hash三次下文会详细讲解）hash操作，才能最终定位这个元素的位置，这三次hash分别为：\n\n1. 对于一个key，先进行一次hash操作，得到hash值h1，也即h1 = hash1(key)；\n2. 将得到的h1的高几位进行第二次hash，得到hash值h2，也即h2 = hash2(h1高几位)，通过h2能够确定该元素的放在哪个Segment；\n3. 将得到的h1进行第三次hash，得到hash值h3，也即h3 = hash3(h1)，通过h3能够确定该元素放置在哪个HashEntry。\n\n## 初始化\n先看看ConcurrentHashMap的初始化做了哪些事情，构造函数的源码如下：\n\n```\npublic ConcurrentHashMap(int initialCapacity,\n                             float loadFactor, int concurrencyLevel) {\n        if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)\n            throw new IllegalArgumentException();\n        if (concurrencyLevel > MAX_SEGMENTS)\n            concurrencyLevel = MAX_SEGMENTS;\n        // Find power-of-two sizes best matching arguments\n        int sshift = 0;\n        int ssize = 1;\n        while (ssize < concurrencyLevel) {\n            ++sshift;\n            ssize <<= 1;\n        }\n        this.segmentShift = 32 - sshift;\n        this.segmentMask = ssize - 1;\n        if (initialCapacity > MAXIMUM_CAPACITY)\n            initialCapacity = MAXIMUM_CAPACITY;\n        int c = initialCapacity / ssize;\n        if (c * ssize < initialCapacity)\n            ++c;\n        int cap = MIN_SEGMENT_TABLE_CAPACITY;\n        while (cap < c)\n            cap <<= 1;\n        // create segments and segments[0]\n        Segment<K,V> s0 =\n            new Segment<K,V>(loadFactor, (int)(cap * loadFactor),\n                             (HashEntry<K,V>[])new HashEntry[cap]);\n        Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];\n        UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]\n        this.segments = ss;\n    }\n```\n传入的参数有initialCapacity，loadFactor，concurrencyLevel这三个。\n\n* initialCapacity表示新创建的这个ConcurrentHashMap的初始容量，也就是上面的结构图中的Entry数量。默认值为`static final int DEFAULT_INITIAL_CAPACITY = 16;`\n* loadFactor表示负载因子，就是当ConcurrentHashMap中的元素个数大于**loadFactor * 最大容量**时就需要rehash，扩容。默认值为`static final float DEFAULT_LOAD_FACTOR = 0.75f;`\n* concurrencyLevel表示并发级别，这个值用来确定Segment的个数，Segment的个数是大于等于concurrencyLevel的第一个2的n次方的数。比如，如果concurrencyLevel为12，13，14，15，16这些数，则Segment的数目为16(2的4次方)。默认值为`static final int DEFAULT_CONCURRENCY_LEVEL = 16;`。理想情况下ConcurrentHashMap的真正的并发访问量能够达到concurrencyLevel，因为有concurrencyLevel个Segment，假如有concurrencyLevel个线程需要访问Map，并且需要访问的数据都恰好分别落在不同的Segment中，则这些线程能够无竞争地自由访问（因为他们不需要竞争同一把锁），达到同时访问的效果。这也是为什么这个参数起名为“并发级别”的原因。\n\n初始化的一些动作：\n\n1. 验证参数的合法性，如果不合法，直接抛出异常。\n2. concurrencyLevel也就是Segment的个数不能超过规定的最大Segment的个数，默认值为`static final int MAX_SEGMENTS = 1 << 16;`，如果超过这个值，设置为这个值。\n3. 然后使用循环找到大于等于concurrencyLevel的第一个2的n次方的数ssize，这个数就是Segment数组的大小，并记录一共向左按位移动的次数sshift，并令`segmentShift = 32 - sshift`，并且segmentMask的值等于ssize - 1，segmentMask的各个二进制位都为1，目的是之后可以通过key的hash值与这个值做**&运算**确定Segment的索引。\n4. 检查给的容量值是否大于允许的最大容量值，如果大于该值，设置为该值。最大容量值为`static final int MAXIMUM_CAPACITY = 1 << 30;`。\n5. 然后计算每个Segment平均应该放置多少个元素，这个值c是向上取整的值。比如初始容量为15，Segment个数为4，则每个Segment平均需要放置4个元素。\n6. 最后创建一个Segment实例，将其当做Segment数组的第一个元素。\n\n## put操作\nput操作的源码如下：\n\n```\n  public V put(K key, V value) {\n        Segment<K,V> s;\n        if (value == null)\n            throw new NullPointerException();\n        int hash = hash(key);\n        int j = (hash >>> segmentShift) & segmentMask;\n        if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck\n             (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment\n            s = ensureSegment(j);\n        return s.put(key, hash, value, false);\n    }\n```\n操作步骤如下：\n\n1. 判断value是否为null，如果为null，直接抛出异常。\n2. key通过一次hash运算得到一个hash值。(这个hash运算下文详说)\n3. 将得到hash值向右按位移动segmentShift位，然后再与segmentMask做&运算得到segment的索引j。\n   在初始化的时候我们说过segmentShift的值等于32-sshift，例如concurrencyLevel等于16，则sshift等于4，则segmentShift为28。hash值是一个32位的整数，将其向右移动28位就变成这个样子：\n   0000 0000 0000 0000 0000 0000 0000 xxxx，然后再用这个值与segmentMask做&运算，也就是取最后四位的值。这个值确定Segment的索引。\n4. 使用Unsafe的方式从Segment数组中获取该索引对应的Segment对象。\n5. 向这个Segment对象中put值，这个put操作也基本是一样的步骤（通过&运算获取HashEntry的索引，然后set）。\n\n\n\n## get操作\nget操作的源码如下：\n\n```\npublic V get(Object key) {\n        Segment<K,V> s; // manually integrate access methods to reduce overhead\n        HashEntry<K,V>[] tab;\n        int h = hash(key);\n        long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;\n        if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&\n            (tab = s.table) != null) {\n            for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile\n                     (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);\n                 e != null; e = e.next) {\n                K k;\n                if ((k = e.key) == key || (e.hash == h && key.equals(k)))\n                    return e.value;\n            }\n        }\n        return null;\n    }\n```\n操作步骤为：\n\n1. 和put操作一样，先通过key进行两次hash确定应该去哪个Segment中取数据。\n2. 使用Unsafe获取对应的Segment，然后再进行一次&运算得到HashEntry链表的位置，然后从链表头开始遍历整个链表（因为Hash可能会有碰撞，所以用一个链表保存），如果找到对应的key，则返回对应的value值，如果链表遍历完都没有找到对应的key，则说明Map中不包含该key，返回null。\n\n\n## size操作\nsize操作与put和get操作最大的区别在于，size操作需要遍历所有的Segment才能算出整个Map的大小，而put和get都只关心一个Segment。假设我们当前遍历的Segment为SA，那么在遍历SA过程中其他的Segment比如SB可能会被修改，于是这一次运算出来的size值可能并不是Map当前的真正大小。所以一个比较简单的办法就是计算Map大小的时候所有的Segment都Lock住，不能更新(包含put，remove等等)数据，计算完之后再Unlock。这是普通人能够想到的方案，但是牛逼的作者还有一个更好的Idea：**先给3次机会，不lock所有的Segment，遍历所有Segment，累加各个Segment的大小得到整个Map的大小，如果某相邻的两次计算获取的所有Segment的更新的次数（每个Segment都有一个modCount变量，这个变量在Segment中的Entry被修改时会加一，通过这个值可以得到每个Segment的更新操作的次数）是一样的，说明计算过程中没有更新操作，则直接返回这个值。如果这三次不加锁的计算过程中Map的更新次数有变化，则之后的计算先对所有的Segment加锁，再遍历所有Segment计算Map大小，最后再解锁所有Segment。**源代码如下：\n\n```\npublic int size() {\n        // Try a few times to get accurate count. On failure due to\n        // continuous async changes in table, resort to locking.\n        final Segment<K,V>[] segments = this.segments;\n        int size;\n        boolean overflow; // true if size overflows 32 bits\n        long sum;         // sum of modCounts\n        long last = 0L;   // previous sum\n        int retries = -1; // first iteration isn't retry\n        try {\n            for (;;) {\n                if (retries++ == RETRIES_BEFORE_LOCK) {\n                    for (int j = 0; j < segments.length; ++j)\n                        ensureSegment(j).lock(); // force creation\n                }\n                sum = 0L;\n                size = 0;\n                overflow = false;\n                for (int j = 0; j < segments.length; ++j) {\n                    Segment<K,V> seg = segmentAt(segments, j);\n                    if (seg != null) {\n                        sum += seg.modCount;\n                        int c = seg.count;\n                        if (c < 0 || (size += c) < 0)\n                            overflow = true;\n                    }\n                }\n                if (sum == last)\n                    break;\n                last = sum;\n            }\n        } finally {\n            if (retries > RETRIES_BEFORE_LOCK) {\n                for (int j = 0; j < segments.length; ++j)\n                    segmentAt(segments, j).unlock();\n            }\n        }\n        return overflow ? Integer.MAX_VALUE : size;\n    }\n```\n举个例子：\n> 一个Map有4个Segment，标记为S1，S2，S3，S4，现在我们要获取Map的size。计算过程是这样的：第一次计算，不对S1，S2，S3，S4加锁，遍历所有的Segment，假设每个Segment的大小分别为1，2，3，4，更新操作次数分别为：2，2，3，1，则这次计算可以得到Map的总大小为1+2+3+4=10，总共更新操作次数为2+2+3+1=8；第二次计算，不对S1,S2,S3,S4加锁，遍历所有Segment，假设这次每个Segment的大小变成了2，2，3，4，更新次数分别为3，2，3，1，因为两次计算得到的Map更新次数不一致(第一次是8，第二次是9)则可以断定这段时间Map数据被更新，则此时应该再试一次；第三次计算，不对S1，S2，S3，S4加锁，遍历所有Segment，假设每个Segment的更新操作次数还是为3，2，3，1，则因为第二次计算和第三次计算得到的Map的更新操作的次数是一致的，就能说明第二次计算和第三次计算这段时间内Map数据没有被更新，此时可以直接返回第三次计算得到的Map的大小。最坏的情况：第三次计算得到的数据更新次数和第二次也不一样，则只能先对所有Segment加锁再计算最后解锁。\n\n\n## containsValue操作\ncontainsValue操作采用了和size操作一样的想法:\n\n```\npublic boolean containsValue(Object value) {\n        // Same idea as size()\n        if (value == null)\n            throw new NullPointerException();\n        final Segment<K,V>[] segments = this.segments;\n        boolean found = false;\n        long last = 0;\n        int retries = -1;\n        try {\n            outer: for (;;) {\n                if (retries++ == RETRIES_BEFORE_LOCK) {\n                    for (int j = 0; j < segments.length; ++j)\n                        ensureSegment(j).lock(); // force creation\n                }\n                long hashSum = 0L;\n                int sum = 0;\n                for (int j = 0; j < segments.length; ++j) {\n                    HashEntry<K,V>[] tab;\n                    Segment<K,V> seg = segmentAt(segments, j);\n                    if (seg != null && (tab = seg.table) != null) {\n                        for (int i = 0 ; i < tab.length; i++) {\n                            HashEntry<K,V> e;\n                            for (e = entryAt(tab, i); e != null; e = e.next) {\n                                V v = e.value;\n                                if (v != null && value.equals(v)) {\n                                    found = true;\n                                    break outer;\n                                }\n                            }\n                        }\n                        sum += seg.modCount;\n                    }\n                }\n                if (retries > 0 && sum == last)\n                    break;\n                last = sum;\n            }\n        } finally {\n            if (retries > RETRIES_BEFORE_LOCK) {\n                for (int j = 0; j < segments.length; ++j)\n                    segmentAt(segments, j).unlock();\n            }\n        }\n        return found;\n    }\n```\n\n# 关于hash\n大家一定还记得使用一个key定位Segment之前进行过一次hash操作吧？这次hash的作用是什么呢？看看hash的源代码：\n\n```\nprivate int hash(Object k) {\n        int h = hashSeed;\n\n        if ((0 != h) && (k instanceof String)) {\n            return sun.misc.Hashing.stringHash32((String) k);\n        }\n\n        h ^= k.hashCode();\n\n        // Spread bits to regularize both segment and index locations,\n        // using variant of single-word Wang/Jenkins hash.\n        h += (h <<  15) ^ 0xffffcd7d;\n        h ^= (h >>> 10);\n        h += (h <<   3);\n        h ^= (h >>>  6);\n        h += (h <<   2) + (h << 14);\n        return h ^ (h >>> 16);\n    }\n```\n源码中的注释是这样的：\n>Applies a supplemental hash function to a given hashCode, which defends against poor quality hash functions.  This is critical because ConcurrentHashMap uses power-of-two length hash tables, that otherwise encounter collisions for hashCodes that do not differ in lower or upper bits.\n \n这里用到了Wang/Jenkins hash算法的变种，主要的目的是为了减少哈希冲突，使元素能够均匀的分布在不同的Segment上，从而提高容器的存取效率。假如哈希的质量差到极点，那么所有的元素都在一个Segment中，不仅存取元素缓慢，分段锁也会失去意义。\n\n举个简单的例子：\n\n```\nSystem.out.println(Integer.parseInt(\"0001111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"0011111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"0111111\", 2) & 15);\nSystem.out.println(Integer.parseInt(\"1111111\", 2) & 15);\n\n```\n这些数字得到的hash值都是一样的，全是15，所以如果不进行第一次预hash，发生冲突的几率还是很大的，但是如果我们先把上例中的二进制数字使用hash()函数先进行一次预hash，得到的结果是这样的：\n>0100｜0111｜0110｜0111｜1101｜1010｜0100｜1110  \n1111｜0111｜0100｜0011｜0000｜0001｜1011｜1000  \n0111｜0111｜0110｜1001｜0100｜0110｜0011｜1110  \n1000｜0011｜0000｜0000｜1100｜1000｜0001｜1010  \n\n上面这个例子引用自: [InfoQ](http://www.infoq.com/cn/articles/ConcurrentHashMap/)\n可以看到每一位的数据都散开了，并且ConcurrentHashMap中是使用预hash值的高位参与运算的。比如之前说的先将hash值向右按位移动28位，再与15做&运算，得到的结果都别为：4，15，7，8，没有冲突！\n\n# 注意事项\n\n* ConcurrentHashMap中的key和value值都不能为null。\n* ConcurrentHashMap的整个操作过程中大量使用了Unsafe类来获取Segment/HashEntry，这里Unsafe的主要作用是提供原子操作。Unsafe这个类比较恐怖，破坏力极强，一般场景不建议使用，如果有兴趣可以到这里做详细的了解[Java中鲜为人知的特性](http://blog.csdn.net/fenglibing/article/details/17138079)\n* ConcurrentHashMap是线程安全的类并不能保证使用了ConcurrentHashMap的操作都是线程安全的！\n* 本文为作者个人理解，如果有误，请留言相告，感激不尽。\n* 转载请注明出处：[http://qifuguang.me/2015/09/10/[Java并发包学习八]深度剖析ConcurrentHashMap/](http://qifuguang.me/2015/09/10/[Java并发包学习八]深度剖析ConcurrentHashMap/)\n\n\n","slug":"[Java并发包学习八]深度剖析ConcurrentHashMap","published":1,"updated":"2015-10-19T14:23:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovaq001ylo6bwgf18qxw"},{"title":"[Java并发包学习五]CountDownLatch和CyclicBarrier介绍","date":"2015-08-24T17:06:01.000Z","_content":"# 概述\nJDK中提供了一些用于线程之间协同等待的工具类，CountDownLatch和CyclicBarrier就是最典型的两个线程同步辅助类。下面分别详细介绍这两个类，以及他们之间的异同点。\n<!--more-->\n\n# CountDownLatch类\nCountDownLatch顾名思义：**倒计数锁存器**。没错，他就是一个计数器，并且是倒着计数的。他的应用场景如下：\n> 一个任务A，他需要等待其他的一些任务都执行完毕之后它才能执行。就比如说赛跑的时候，发令员需要等待所有运动员都准备好了才能发令，否则不被K才怪嘞！\n\n此时CountDownLatch就可以大展身手了。\n\n## 常用操作\n本节介绍CountDownLatch的基本操作函数。\n### 构造函数\n函数签名如下：\n\n```\npublic CountDownLatch(int count)\n```\n用一个给定的数值初始化CountDownLatch，之后计数器就从这个值开始倒计数，直到计数值达到零。\n\n### await函数\nawait函数用两种形式，签名分别如下：\n\n```\npublic void await() throws InterruptedException\npublic boolean await(long timeout, TimeUnit unit)\n```\n这两个函数的作用都是让线程阻塞等待其他线程，直到CountDownLatch的计数值变为0才继续执行之后的操作。区别在于第一个函数没有等待时间限制，可以等到天荒地老，海枯石烂，第二个函数给定一个等待超时时间，超过该时间就直接放弃了，并且第二个函数具有返回值，超时时间之内CountDownLatch的值达到0就返回**true**,等待时间结束计数值都还没达到0就返回**false**。这两个操作在等待过程中如果等待的线程被中断，则会抛出InterruptedException异常。\n\n### countDown函数\n这个函数用来将CountDownLatch的计数值减一，函数签名如下：\n\n```\npublic void countDown()\n```\n需要说明的是，如果调用这个函数的时候CountDownLatch的计数值已经为0，那么这个函数什么也不会做。\n\n### getCount函数\n该函数用来获取当前CountDownLatch的计数值，函数签名如下：\n\n```\npublic void countDown()\n```\n\n## 模拟实验\n理论知识讲完了，需要真枪实战地来演示一下这个类的作用，我们就以下面这个场景为例子，用CountDownLatch来实现这个需求：\n> 有5个运动员赛跑，开跑之前，裁判需要等待5个运动员都准备好才能发令，并且5个运动员准备好之后也都需要等待裁判发令才能开跑。\n\n首先分析一下依赖关系：\n> 裁判发令 -> 5个运动员都准备好；  \n> 5个运动员开跑 -> 裁判发令。\n\n好，依赖关系已经出来了，代码实现：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.CountDownLatch;\n\n/**\n * @author qifuguang\n * @date 15/8/24 23:35\n */\npublic class TestCountDownLatch {\n    private static final int RUNNER_NUMBER = 5; // 运动员个数\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) {\n        // 用于判断发令之前运动员是否已经完全进入准备状态，需要等待5个运动员，所以参数为5\n        CountDownLatch readyLatch = new CountDownLatch(RUNNER_NUMBER);\n        // 用于判断裁判是否已经发令，只需要等待一个裁判，所以参数为1\n        CountDownLatch startLatch = new CountDownLatch(1);\n        for (int i = 0; i < RUNNER_NUMBER; i++) {\n            Thread t = new Thread(new Runner((i + 1) + \"号运动员\", readyLatch, startLatch));\n            t.start();\n        }\n        try {\n            readyLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        startLatch.countDown();\n        System.out.println(\"裁判：所有运动员准备完毕，开始...\");\n    }\n\n    static class Runner implements Runnable {\n        private CountDownLatch readyLatch;\n        private CountDownLatch startLatch;\n        private String name;\n\n        public Runner(String name, CountDownLatch readyLatch, CountDownLatch startLatch) {\n            this.name = name;\n            this.readyLatch = readyLatch;\n            this.startLatch = startLatch;\n        }\n\n        public void run() {\n            int readyTime = RANDOM.nextInt(1000);\n            System.out.println(name + \"：我需要\" + readyTime + \"秒时间准备.\");\n            try {\n                Thread.sleep(readyTime);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：我已经准备完毕.\");\n            readyLatch.countDown();\n            try {\n                startLatch.await();  // 等待裁判发开始命令\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：开跑...\");\n        }\n    }\n}\n```\n运行结果如下：\n\n>1号运动员：我需要389秒时间准备.  \n2号运动员：我需要449秒时间准备.  \n3号运动员：我需要160秒时间准备.  \n4号运动员：我需要325秒时间准备.  \n5号运动员：我需要978秒时间准备.  \n3号运动员：我已经准备完毕.  \n4号运动员：我已经准备完毕.  \n1号运动员：我已经准备完毕.  \n2号运动员：我已经准备完毕.  \n5号运动员：我已经准备完毕.  \n裁判：所有运动员准备完毕，开始...  \n1号运动员：开跑...  \n5号运动员：开跑...  \n2号运动员：开跑...  \n4号运动员：开跑...  \n3号运动员：开跑...  \n\n可以看到，一切都是如此地完美，运动员准备好了之后裁判才发令，裁判发令之后运动员才开跑。\n\n# CyclicBarrier类\nCyclicBarrier翻译过来就是：循环的屏障。什么是循环？可以重复利用呗，对这个类就是一个可以重复利用的屏障类。CyclicBarrier主要用于一组固定大小的线程之间，各个线程之间相互等待，当所有线程都完成某项任务之后，才能执行之后的任务。\n如下场景：\n\n> 有若干个线程都需要向一个数据库写数据，但是必须要所有的线程都讲数据写入完毕他们才能继续做之后的事情。\n\n分析一下这个场景的特征： \n \n* 各个线程都必须完成某项任务(写数据)才能继续做后续的任务；  \n* 各个线程需要相互等待，不能独善其身。\n\n这种场景便可以利用CyclicBarrier来完美解决。\n\n## 常用函数\n本节介绍CyclicBarrier的基本操作函数。\n### 构造函数\n有两种类型的构造函数，函数签名分别如下：\n\n```\npublic CyclicBarrier(int parties, Runnable barrierAction)\npublic CyclicBarrier(int parties)\n```\n参数parties表示一共有多少线程参与这次“活动”，参数barrierAction是可选的，用来指定当所有线程都完成这些必须的“神秘任务”之后需要干的事情，所以barrierAction这里的动作在一个相互等待的循环内只会执行一次。\n\n### getParties函数\ngetParties用来获取当前的CyclicBarrier一共有多少线程参数与，函数签名如下：\n \n```\npublic int getParties()\n```\n返回参与“活动”的线程个数。\n\n### await函数\nawait函数用来执行等待操作，有两种类型的函数签名：\n\n```\npublic int await() throws InterruptedException, BrokenBarrierException\npublic int await(long timeout, TimeUnit unit)\n        throws InterruptedException,\n               BrokenBarrierException,\n               TimeoutException \n```\n第一个函数是一个无参函数，第二个函数可以指定等待的超时时间。它们的作用是：一直等待知道所有参与“活动”的线程都调用过await函数，如果当前线程不是即将调用await函数的的最后一个线程，当前线程将会被挂起，直到下列某一种情况发生：\n\n* 最后一个线程调用了await函数；\n* 某个线程打断了当前线程；\n* 某个线程打断了其他某个正在等待的线程；\n* 其他某个线程等待时间超过给定的超时时间；\n* 其他某个线程调用了reset函数。\n\n如果等待过程中线程被打断了，则会抛出InterruptedException异常；  \n如果等待过程中出现下列情况中的某一种情况，则会抛出BrokenBarrierException异常：\n\n* 其他线程被打断了；\n* 当前线程等待超时了；\n* 当前CyclicBarrier被reset了；\n* 等待过程中CyclicBarrier损坏了；\n* 构造函数中指定的barrierAction在执行过程中发生了异常。\n\n如果等待时间超过给定的最大等待时间，则会抛出TimeoutException异常，并且这个时候其他已经嗲用过await函数的线程将会继续后续的动作。\n\n返回值：返回当前线程在调用过await函数的所以线程中的编号，编号为**parties-1**的表示第一个调用await函数，编号为0表示是最后一个调用await函数。\n\n### isBroken函数\n给函数用来判断barrier是否已经损坏，函数签名如下：\n\n```\npublic boolean isBroken()\n```\n如果因为任何原因被损坏返回**true**，否则返回**false**。\n\n### reset函数\n顾名思义，这个函数用来重置barrier，函数签名如下：\n\n```\npublic void reset()\n```\n如果调用了该函数，则在等待的线程将会抛出BrokenBarrierException异常。\n\n### getNumberWaiting函数\n该函数用来获取当前正在等待该barrier的线程数，函数签名如下：\n\n```\npublic int getNumberWaiting()\n```\n\n## 模拟实验\n下面用代码实现下面的场景：\n> 有5个线程都需要向一个数据库写数据，但是必须要所有的线程都讲数据写入完毕他们才能继续做之后的事情。\n\n### 一般情况\n代码：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(); // 等待所有线程都调用过此函数才能进行后续动作\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果如下：\n\n> 10：我需要16毫秒时间写入数据.  \n11：我需要353毫秒时间写入数据.  \n12：我需要101毫秒时间写入数据.  \n13：我需要744毫秒时间写入数据.  \n14：我需要51毫秒时间写入数据.  \n10：写入数据完毕，等待其他小伙伴...  \n14：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n11：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n13：我宣布，所有小伙伴写入数据完毕  \n13：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n12：所有线程都写入数据完毕，继续干活...  \n14：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...   \n\n可以看到，线程小伙伴们非常团结，写完自己的数据之后都在等待其他小伙伴，所有小伙伴都完成之后才继续后续的动作。\n\n### 重复使用\n上面的例子并没有体现CyclicBarrier可以循环使用的特点，所以有如下代码：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) throws Exception {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n        Thread.sleep(10000);\n        System.out.println(\"================barrier重用==========================\");\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(); // 等待所有线程都调用过此函数才能进行后续动作\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果：\n>10：我需要228毫秒时间写入数据.  \n11：我需要312毫秒时间写入数据.  \n12：我需要521毫秒时间写入数据.  \n13：我需要720毫秒时间写入数据.  \n14：我需要377毫秒时间写入数据.  \n10：写入数据完毕，等待其他小伙伴...  \n11：写入数据完毕，等待其他小伙伴...  \n14：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n13：我宣布，所有小伙伴写入数据完毕  \n13：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...  \n14：所有线程都写入数据完毕，继续干活...  \n12：所有线程都写入数据完毕，继续干活...  \n================barrier重用==========================  \n15：我需要212毫秒时间写入数据.  \n16：我需要691毫秒时间写入数据.  \n17：我需要530毫秒时间写入数据.  \n18：我需要758毫秒时间写入数据.  \n19：我需要604毫秒时间写入数据.  \n15：写入数据完毕，等待其他小伙伴...  \n17：写入数据完毕，等待其他小伙伴...  \n19：写入数据完毕，等待其他小伙伴...  \n16：写入数据完毕，等待其他小伙伴...  \n18：写入数据完毕，等待其他小伙伴...  \n18：我宣布，所有小伙伴写入数据完毕  \n18：所有线程都写入数据完毕，继续干活...  \n15：所有线程都写入数据完毕，继续干活...  \n19：所有线程都写入数据完毕，继续干活...  \n16：所有线程都写入数据完毕，继续干活...  \n17：所有线程都写入数据完毕，继续干活...  \n\n可以看到，barrier的确是重用了。\n\n### 等待超时\n如果await的时候设置了一个最长等待时间，并且等待超时，则会怎么样呢？下面的例子故意让一个线程延迟一段时间才开始写数据，这样就会出现先等待的线程等待最后一个线程抛出等待超时异常的情况。\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) throws Exception {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            if (i < THREAD_NUMBER - 1) {\n                Thread t = new Thread(new Worker(barrier));\n                t.start();\n            } else {  //最后一个线程故意延迟3s创建。\n                Thread.sleep(3000);\n                Thread t = new Thread(new Worker(barrier));\n                t.start();\n            }\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(2000, TimeUnit.MILLISECONDS); // 只等待2s，必然会等待最后一个线程超时\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            } catch (TimeoutException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果：\n> 10：我需要820毫秒时间写入数据.  \n11：我需要140毫秒时间写入数据.  \n12：我需要640毫秒时间写入数据.  \n13：我需要460毫秒时间写入数据.  \n11：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n10：写入数据完毕，等待其他小伙伴...  \njava.util.concurrent.BrokenBarrierException  \n12：所有线程都写入数据完毕，继续干活...  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n13：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.BrokenBarrierException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.TimeoutException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:257)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.BrokenBarrierException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \n14：我需要850毫秒时间写入数据.  \njava.util.concurrent.BrokenBarrierException  \n14：写入数据完毕，等待其他小伙伴...  \n14：所有线程都写入数据完毕，继续干活...  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:207)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \n\n\n可以看到，前面四个线程等待最后一个线程超时了，这个时候他们不再等待最后这个小伙伴了，而是抛出异常并都继续后续的动作。最后这个线程屁颠屁颠地完成写入数据操作之后也继续了后续的动作。需要说明的是，发生了超时异常时候，还没有完成“神秘任务”的线程在完成任务之后不会做任何等待，而是会直接执行后续的操作。\n\n# 总结\nCountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：\n\n* CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；\n* CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；\n* CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。\n\n# 注意事项\n转载请注明出处：[http://qifuguang.me/2015/08/25/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍](http://qifuguang.me/2015/08/25/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍)\n","source":"_posts/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍.md","raw":"title: '[Java并发包学习五]CountDownLatch和CyclicBarrier介绍'\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-08-25 01:06:01\n---\n# 概述\nJDK中提供了一些用于线程之间协同等待的工具类，CountDownLatch和CyclicBarrier就是最典型的两个线程同步辅助类。下面分别详细介绍这两个类，以及他们之间的异同点。\n<!--more-->\n\n# CountDownLatch类\nCountDownLatch顾名思义：**倒计数锁存器**。没错，他就是一个计数器，并且是倒着计数的。他的应用场景如下：\n> 一个任务A，他需要等待其他的一些任务都执行完毕之后它才能执行。就比如说赛跑的时候，发令员需要等待所有运动员都准备好了才能发令，否则不被K才怪嘞！\n\n此时CountDownLatch就可以大展身手了。\n\n## 常用操作\n本节介绍CountDownLatch的基本操作函数。\n### 构造函数\n函数签名如下：\n\n```\npublic CountDownLatch(int count)\n```\n用一个给定的数值初始化CountDownLatch，之后计数器就从这个值开始倒计数，直到计数值达到零。\n\n### await函数\nawait函数用两种形式，签名分别如下：\n\n```\npublic void await() throws InterruptedException\npublic boolean await(long timeout, TimeUnit unit)\n```\n这两个函数的作用都是让线程阻塞等待其他线程，直到CountDownLatch的计数值变为0才继续执行之后的操作。区别在于第一个函数没有等待时间限制，可以等到天荒地老，海枯石烂，第二个函数给定一个等待超时时间，超过该时间就直接放弃了，并且第二个函数具有返回值，超时时间之内CountDownLatch的值达到0就返回**true**,等待时间结束计数值都还没达到0就返回**false**。这两个操作在等待过程中如果等待的线程被中断，则会抛出InterruptedException异常。\n\n### countDown函数\n这个函数用来将CountDownLatch的计数值减一，函数签名如下：\n\n```\npublic void countDown()\n```\n需要说明的是，如果调用这个函数的时候CountDownLatch的计数值已经为0，那么这个函数什么也不会做。\n\n### getCount函数\n该函数用来获取当前CountDownLatch的计数值，函数签名如下：\n\n```\npublic void countDown()\n```\n\n## 模拟实验\n理论知识讲完了，需要真枪实战地来演示一下这个类的作用，我们就以下面这个场景为例子，用CountDownLatch来实现这个需求：\n> 有5个运动员赛跑，开跑之前，裁判需要等待5个运动员都准备好才能发令，并且5个运动员准备好之后也都需要等待裁判发令才能开跑。\n\n首先分析一下依赖关系：\n> 裁判发令 -> 5个运动员都准备好；  \n> 5个运动员开跑 -> 裁判发令。\n\n好，依赖关系已经出来了，代码实现：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.CountDownLatch;\n\n/**\n * @author qifuguang\n * @date 15/8/24 23:35\n */\npublic class TestCountDownLatch {\n    private static final int RUNNER_NUMBER = 5; // 运动员个数\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) {\n        // 用于判断发令之前运动员是否已经完全进入准备状态，需要等待5个运动员，所以参数为5\n        CountDownLatch readyLatch = new CountDownLatch(RUNNER_NUMBER);\n        // 用于判断裁判是否已经发令，只需要等待一个裁判，所以参数为1\n        CountDownLatch startLatch = new CountDownLatch(1);\n        for (int i = 0; i < RUNNER_NUMBER; i++) {\n            Thread t = new Thread(new Runner((i + 1) + \"号运动员\", readyLatch, startLatch));\n            t.start();\n        }\n        try {\n            readyLatch.await();\n        } catch (InterruptedException e) {\n            e.printStackTrace();\n        }\n        startLatch.countDown();\n        System.out.println(\"裁判：所有运动员准备完毕，开始...\");\n    }\n\n    static class Runner implements Runnable {\n        private CountDownLatch readyLatch;\n        private CountDownLatch startLatch;\n        private String name;\n\n        public Runner(String name, CountDownLatch readyLatch, CountDownLatch startLatch) {\n            this.name = name;\n            this.readyLatch = readyLatch;\n            this.startLatch = startLatch;\n        }\n\n        public void run() {\n            int readyTime = RANDOM.nextInt(1000);\n            System.out.println(name + \"：我需要\" + readyTime + \"秒时间准备.\");\n            try {\n                Thread.sleep(readyTime);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：我已经准备完毕.\");\n            readyLatch.countDown();\n            try {\n                startLatch.await();  // 等待裁判发开始命令\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(name + \"：开跑...\");\n        }\n    }\n}\n```\n运行结果如下：\n\n>1号运动员：我需要389秒时间准备.  \n2号运动员：我需要449秒时间准备.  \n3号运动员：我需要160秒时间准备.  \n4号运动员：我需要325秒时间准备.  \n5号运动员：我需要978秒时间准备.  \n3号运动员：我已经准备完毕.  \n4号运动员：我已经准备完毕.  \n1号运动员：我已经准备完毕.  \n2号运动员：我已经准备完毕.  \n5号运动员：我已经准备完毕.  \n裁判：所有运动员准备完毕，开始...  \n1号运动员：开跑...  \n5号运动员：开跑...  \n2号运动员：开跑...  \n4号运动员：开跑...  \n3号运动员：开跑...  \n\n可以看到，一切都是如此地完美，运动员准备好了之后裁判才发令，裁判发令之后运动员才开跑。\n\n# CyclicBarrier类\nCyclicBarrier翻译过来就是：循环的屏障。什么是循环？可以重复利用呗，对这个类就是一个可以重复利用的屏障类。CyclicBarrier主要用于一组固定大小的线程之间，各个线程之间相互等待，当所有线程都完成某项任务之后，才能执行之后的任务。\n如下场景：\n\n> 有若干个线程都需要向一个数据库写数据，但是必须要所有的线程都讲数据写入完毕他们才能继续做之后的事情。\n\n分析一下这个场景的特征： \n \n* 各个线程都必须完成某项任务(写数据)才能继续做后续的任务；  \n* 各个线程需要相互等待，不能独善其身。\n\n这种场景便可以利用CyclicBarrier来完美解决。\n\n## 常用函数\n本节介绍CyclicBarrier的基本操作函数。\n### 构造函数\n有两种类型的构造函数，函数签名分别如下：\n\n```\npublic CyclicBarrier(int parties, Runnable barrierAction)\npublic CyclicBarrier(int parties)\n```\n参数parties表示一共有多少线程参与这次“活动”，参数barrierAction是可选的，用来指定当所有线程都完成这些必须的“神秘任务”之后需要干的事情，所以barrierAction这里的动作在一个相互等待的循环内只会执行一次。\n\n### getParties函数\ngetParties用来获取当前的CyclicBarrier一共有多少线程参数与，函数签名如下：\n \n```\npublic int getParties()\n```\n返回参与“活动”的线程个数。\n\n### await函数\nawait函数用来执行等待操作，有两种类型的函数签名：\n\n```\npublic int await() throws InterruptedException, BrokenBarrierException\npublic int await(long timeout, TimeUnit unit)\n        throws InterruptedException,\n               BrokenBarrierException,\n               TimeoutException \n```\n第一个函数是一个无参函数，第二个函数可以指定等待的超时时间。它们的作用是：一直等待知道所有参与“活动”的线程都调用过await函数，如果当前线程不是即将调用await函数的的最后一个线程，当前线程将会被挂起，直到下列某一种情况发生：\n\n* 最后一个线程调用了await函数；\n* 某个线程打断了当前线程；\n* 某个线程打断了其他某个正在等待的线程；\n* 其他某个线程等待时间超过给定的超时时间；\n* 其他某个线程调用了reset函数。\n\n如果等待过程中线程被打断了，则会抛出InterruptedException异常；  \n如果等待过程中出现下列情况中的某一种情况，则会抛出BrokenBarrierException异常：\n\n* 其他线程被打断了；\n* 当前线程等待超时了；\n* 当前CyclicBarrier被reset了；\n* 等待过程中CyclicBarrier损坏了；\n* 构造函数中指定的barrierAction在执行过程中发生了异常。\n\n如果等待时间超过给定的最大等待时间，则会抛出TimeoutException异常，并且这个时候其他已经嗲用过await函数的线程将会继续后续的动作。\n\n返回值：返回当前线程在调用过await函数的所以线程中的编号，编号为**parties-1**的表示第一个调用await函数，编号为0表示是最后一个调用await函数。\n\n### isBroken函数\n给函数用来判断barrier是否已经损坏，函数签名如下：\n\n```\npublic boolean isBroken()\n```\n如果因为任何原因被损坏返回**true**，否则返回**false**。\n\n### reset函数\n顾名思义，这个函数用来重置barrier，函数签名如下：\n\n```\npublic void reset()\n```\n如果调用了该函数，则在等待的线程将会抛出BrokenBarrierException异常。\n\n### getNumberWaiting函数\n该函数用来获取当前正在等待该barrier的线程数，函数签名如下：\n\n```\npublic int getNumberWaiting()\n```\n\n## 模拟实验\n下面用代码实现下面的场景：\n> 有5个线程都需要向一个数据库写数据，但是必须要所有的线程都讲数据写入完毕他们才能继续做之后的事情。\n\n### 一般情况\n代码：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(); // 等待所有线程都调用过此函数才能进行后续动作\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果如下：\n\n> 10：我需要16毫秒时间写入数据.  \n11：我需要353毫秒时间写入数据.  \n12：我需要101毫秒时间写入数据.  \n13：我需要744毫秒时间写入数据.  \n14：我需要51毫秒时间写入数据.  \n10：写入数据完毕，等待其他小伙伴...  \n14：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n11：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n13：我宣布，所有小伙伴写入数据完毕  \n13：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n12：所有线程都写入数据完毕，继续干活...  \n14：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...   \n\n可以看到，线程小伙伴们非常团结，写完自己的数据之后都在等待其他小伙伴，所有小伙伴都完成之后才继续后续的动作。\n\n### 重复使用\n上面的例子并没有体现CyclicBarrier可以循环使用的特点，所以有如下代码：\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) throws Exception {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n        Thread.sleep(10000);\n        System.out.println(\"================barrier重用==========================\");\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            Thread t = new Thread(new Worker(barrier));\n            t.start();\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(); // 等待所有线程都调用过此函数才能进行后续动作\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果：\n>10：我需要228毫秒时间写入数据.  \n11：我需要312毫秒时间写入数据.  \n12：我需要521毫秒时间写入数据.  \n13：我需要720毫秒时间写入数据.  \n14：我需要377毫秒时间写入数据.  \n10：写入数据完毕，等待其他小伙伴...  \n11：写入数据完毕，等待其他小伙伴...  \n14：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n13：我宣布，所有小伙伴写入数据完毕  \n13：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...  \n14：所有线程都写入数据完毕，继续干活...  \n12：所有线程都写入数据完毕，继续干活...  \n================barrier重用==========================  \n15：我需要212毫秒时间写入数据.  \n16：我需要691毫秒时间写入数据.  \n17：我需要530毫秒时间写入数据.  \n18：我需要758毫秒时间写入数据.  \n19：我需要604毫秒时间写入数据.  \n15：写入数据完毕，等待其他小伙伴...  \n17：写入数据完毕，等待其他小伙伴...  \n19：写入数据完毕，等待其他小伙伴...  \n16：写入数据完毕，等待其他小伙伴...  \n18：写入数据完毕，等待其他小伙伴...  \n18：我宣布，所有小伙伴写入数据完毕  \n18：所有线程都写入数据完毕，继续干活...  \n15：所有线程都写入数据完毕，继续干活...  \n19：所有线程都写入数据完毕，继续干活...  \n16：所有线程都写入数据完毕，继续干活...  \n17：所有线程都写入数据完毕，继续干活...  \n\n可以看到，barrier的确是重用了。\n\n### 等待超时\n如果await的时候设置了一个最长等待时间，并且等待超时，则会怎么样呢？下面的例子故意让一个线程延迟一段时间才开始写数据，这样就会出现先等待的线程等待最后一个线程抛出等待超时异常的情况。\n\n```\npackage com.winwill.test;\n\nimport java.util.Random;\nimport java.util.concurrent.BrokenBarrierException;\nimport java.util.concurrent.CyclicBarrier;\nimport java.util.concurrent.TimeUnit;\nimport java.util.concurrent.TimeoutException;\n\n/**\n * @author qifuguang\n * @date 15/8/25 00:34\n */\npublic class TestCyclicBarrier {\n    private static final int THREAD_NUMBER = 5;\n    private static final Random RANDOM = new Random();\n\n    public static void main(String[] args) throws Exception {\n        CyclicBarrier barrier = new CyclicBarrier(THREAD_NUMBER, new Runnable() {\n            public void run() {\n                System.out.println(Thread.currentThread().getId() + \"：我宣布，所有小伙伴写入数据完毕\");\n            }\n        });\n        for (int i = 0; i < THREAD_NUMBER; i++) {\n            if (i < THREAD_NUMBER - 1) {\n                Thread t = new Thread(new Worker(barrier));\n                t.start();\n            } else {  //最后一个线程故意延迟3s创建。\n                Thread.sleep(3000);\n                Thread t = new Thread(new Worker(barrier));\n                t.start();\n            }\n        }\n    }\n\n    static class Worker implements Runnable {\n        private CyclicBarrier barrier;\n\n        public Worker(CyclicBarrier barrier) {\n            this.barrier = barrier;\n        }\n\n        public void run() {\n            int time = RANDOM.nextInt(1000);\n            System.out.println(Thread.currentThread().getId() + \"：我需要\" + time + \"毫秒时间写入数据.\");\n            try {\n                Thread.sleep(time);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：写入数据完毕，等待其他小伙伴...\");\n            try {\n                barrier.await(2000, TimeUnit.MILLISECONDS); // 只等待2s，必然会等待最后一个线程超时\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            } catch (BrokenBarrierException e) {\n                e.printStackTrace();\n            } catch (TimeoutException e) {\n                e.printStackTrace();\n            }\n            System.out.println(Thread.currentThread().getId() + \"：所有线程都写入数据完毕，继续干活...\");\n        }\n    }\n}\n\n```\n运行结果：\n> 10：我需要820毫秒时间写入数据.  \n11：我需要140毫秒时间写入数据.  \n12：我需要640毫秒时间写入数据.  \n13：我需要460毫秒时间写入数据.  \n11：写入数据完毕，等待其他小伙伴...  \n13：写入数据完毕，等待其他小伙伴...  \n12：写入数据完毕，等待其他小伙伴...  \n10：写入数据完毕，等待其他小伙伴...  \njava.util.concurrent.BrokenBarrierException  \n12：所有线程都写入数据完毕，继续干活...  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n13：所有线程都写入数据完毕，继续干活...  \n11：所有线程都写入数据完毕，继续干活...  \n10：所有线程都写入数据完毕，继续干活...  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.BrokenBarrierException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.TimeoutException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:257)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \njava.util.concurrent.BrokenBarrierException  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:250)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \n14：我需要850毫秒时间写入数据.  \njava.util.concurrent.BrokenBarrierException  \n14：写入数据完毕，等待其他小伙伴...  \n14：所有线程都写入数据完毕，继续干活...  \n    at java.util.concurrent.CyclicBarrier.dowait(CyclicBarrier.java:207)  \n    at java.util.concurrent.CyclicBarrier.await(CyclicBarrier.java:435)  \n    at com.winwill.test.TestCyclicBarrier$Worker.run(TestCyclicBarrier.java:52)  \n    at java.lang.Thread.run(Thread.java:744)  \n\n\n可以看到，前面四个线程等待最后一个线程超时了，这个时候他们不再等待最后这个小伙伴了，而是抛出异常并都继续后续的动作。最后这个线程屁颠屁颠地完成写入数据操作之后也继续了后续的动作。需要说明的是，发生了超时异常时候，还没有完成“神秘任务”的线程在完成任务之后不会做任何等待，而是会直接执行后续的操作。\n\n# 总结\nCountDownLatch和CyclicBarrier都能够实现线程之间的等待，只不过它们侧重点不同：\n\n* CountDownLatch一般用于某个线程A等待若干个其他线程执行完任务之后，它才执行；\n* CyclicBarrier一般用于一组线程互相等待至某个状态，然后这一组线程再同时执行；\n* CountDownLatch是不能够重用的，而CyclicBarrier是可以重用的。\n\n# 注意事项\n转载请注明出处：[http://qifuguang.me/2015/08/25/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍](http://qifuguang.me/2015/08/25/[Java并发包学习五]CountDownLatch和CyclicBarrier介绍)\n","slug":"[Java并发包学习五]CountDownLatch和CyclicBarrier介绍","published":1,"updated":"2015-09-11T03:13:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovas0021lo6bv9lxi5f5"},{"title":"[Java并发包学习二]Executors介绍","date":"2015-08-12T08:52:56.000Z","_content":"# 概述\nExecutors类是JDK 1.5开始自带的一个非常强大的主要用于创建各类线程池的工具类。\n<!--more-->\n\n# 常用方法介绍\n## newFixedThreadPool\nnewFixedThreadPool方法有两种函数签名：  \n\n```\npublic static ExecutorService newFixedThreadPool(int nThreads)  \npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory)\n```\n这两个函数用于创建一个最大线程数目固定的线程池，该线程池用一个共享的无界队列来存储提交的任务。参数nThreads指定线程池的最大线程数，参数[threadFactory](http://winwill2012.com/2015/08/11/JDK8-%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0-ThreadFactory%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%BA%8C%EF%BC%89/)是线程工厂类，主要用于自定义线程池中创建新线程时的行为。需要说明的是，创建线程池时，如果线程池没有接收到任何任务，则线程池中不会创建新线程，在线程池中线程数目少于最大线程数时，每来一个新任务就创建一个新线程，当线程数达到最大线程数时，不再创建新线程，新来的任务存储在队列中，之后线程数目不再变化！\n\n## newWorkStealingPool\nnewWorkStealingPool方法有两种函数签名：\n\n```\npublic static ExecutorService newWorkStealingPool(int parallelism)\npublic static ExecutorService newWorkStealingPool()\n```\n这两个方法用于创建ForkJoin框架中用到的ForkJoinPool线程池，第一个函数中的参数用于指定并行数，第二个函数没有参数，它默认使用当前机器可用的CPU个数作为并行数。\n\n## newSingleThreadExecutor\nnewSingleThreadExecutor用于创建只有一个线程的线程池，有两种函数签名：\n\n```\npublic static ExecutorService newSingleThreadExecutor()\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory)\n```\n线程池中的任务使用无界队列存储，第二个函数可以指定threadFactory，自定义创建线程时的行为。\n\n## newCachedThreadPool\nnewCachedThreadPoolf方法用于创建线程数数目可以随着实际情况自动调节的线程池，也有两种类型的函数签名：\n\n```\npublic static ExecutorService newCachedThreadPool()\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory)\n```\n这种线程池的最大线程数只受到操作系统可以创建的最大线程数数目限制，当线程池有很多任务需要处理时，会不断地创建新线程，当任务处理完毕之后，如果某个线程空闲时间大于60s，则该线程将会被销毁。因为这种线程池能够自动调节线程数量，所以比较适合执行大量的短期的小任务。\n\n## newSingleThreadScheduledExecutor\nnewSingleThreadScheduledExecutor该方法用于创建只有一个线程的线程池，并且该线程定时周期性地执行给定的任务，有两种类型的函数签名：\n\n```\npublic static ScheduledExecutorService newSingleThreadScheduledExecutor()\npublic static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory)\n```\n需要注意的是: **线程在周期性地执行任务时如果遇到Exception，则以后将不再周期性地执行任务。**\n\n## newScheduledThreadPool\nnewScheduledThreadPool用于创建一个线程池，线程池中得线程能够周期性地执行给定的任务，有两种函数签名：\n\n```\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)\npublic static ScheduledExecutorService newScheduledThreadPool(\n            int corePoolSize, ThreadFactory threadFactory)\n```\n\n## unconfigurableExecutorService\nunconfigurableExecutorService主要用于包装现有的线程池，包装之后的线程池不能修改，相当于final的，函数签名如下：\n\n```\npublic static ExecutorService unconfigurableExecutorService(ExecutorService executor)\n```\n\n## unconfigurableScheduledExecutorService\nunconfigurableScheduledExecutorService用于包装可以周期性执行任务的线程池，包装之后的线程池不能修改，相当于final，函数签名如下：\n\n```\npublic static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor)\n```\n\n## defaultThreadFactory\ndefaultThreadFactory方法返回默认的工厂方法类，默认的工厂方法为线程池中新创建的线程命名为：\n> pool-[虚拟机中线程池编号]-thread-[线程编号]\n\n函数签名如下：\n\n```\npublic static ThreadFactory defaultThreadFactory()\n```\n\n\n","source":"_posts/[Java并发包学习二]Executors介绍.md","raw":"title: \"[Java并发包学习二]Executors介绍\"\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-08-12 16:52:56\n---\n# 概述\nExecutors类是JDK 1.5开始自带的一个非常强大的主要用于创建各类线程池的工具类。\n<!--more-->\n\n# 常用方法介绍\n## newFixedThreadPool\nnewFixedThreadPool方法有两种函数签名：  \n\n```\npublic static ExecutorService newFixedThreadPool(int nThreads)  \npublic static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory)\n```\n这两个函数用于创建一个最大线程数目固定的线程池，该线程池用一个共享的无界队列来存储提交的任务。参数nThreads指定线程池的最大线程数，参数[threadFactory](http://winwill2012.com/2015/08/11/JDK8-%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0-ThreadFactory%E4%BB%8B%E7%BB%8D%EF%BC%88%E4%BA%8C%EF%BC%89/)是线程工厂类，主要用于自定义线程池中创建新线程时的行为。需要说明的是，创建线程池时，如果线程池没有接收到任何任务，则线程池中不会创建新线程，在线程池中线程数目少于最大线程数时，每来一个新任务就创建一个新线程，当线程数达到最大线程数时，不再创建新线程，新来的任务存储在队列中，之后线程数目不再变化！\n\n## newWorkStealingPool\nnewWorkStealingPool方法有两种函数签名：\n\n```\npublic static ExecutorService newWorkStealingPool(int parallelism)\npublic static ExecutorService newWorkStealingPool()\n```\n这两个方法用于创建ForkJoin框架中用到的ForkJoinPool线程池，第一个函数中的参数用于指定并行数，第二个函数没有参数，它默认使用当前机器可用的CPU个数作为并行数。\n\n## newSingleThreadExecutor\nnewSingleThreadExecutor用于创建只有一个线程的线程池，有两种函数签名：\n\n```\npublic static ExecutorService newSingleThreadExecutor()\npublic static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory)\n```\n线程池中的任务使用无界队列存储，第二个函数可以指定threadFactory，自定义创建线程时的行为。\n\n## newCachedThreadPool\nnewCachedThreadPoolf方法用于创建线程数数目可以随着实际情况自动调节的线程池，也有两种类型的函数签名：\n\n```\npublic static ExecutorService newCachedThreadPool()\npublic static ExecutorService newCachedThreadPool(ThreadFactory threadFactory)\n```\n这种线程池的最大线程数只受到操作系统可以创建的最大线程数数目限制，当线程池有很多任务需要处理时，会不断地创建新线程，当任务处理完毕之后，如果某个线程空闲时间大于60s，则该线程将会被销毁。因为这种线程池能够自动调节线程数量，所以比较适合执行大量的短期的小任务。\n\n## newSingleThreadScheduledExecutor\nnewSingleThreadScheduledExecutor该方法用于创建只有一个线程的线程池，并且该线程定时周期性地执行给定的任务，有两种类型的函数签名：\n\n```\npublic static ScheduledExecutorService newSingleThreadScheduledExecutor()\npublic static ScheduledExecutorService newSingleThreadScheduledExecutor(ThreadFactory threadFactory)\n```\n需要注意的是: **线程在周期性地执行任务时如果遇到Exception，则以后将不再周期性地执行任务。**\n\n## newScheduledThreadPool\nnewScheduledThreadPool用于创建一个线程池，线程池中得线程能够周期性地执行给定的任务，有两种函数签名：\n\n```\npublic static ScheduledExecutorService newScheduledThreadPool(int corePoolSize)\npublic static ScheduledExecutorService newScheduledThreadPool(\n            int corePoolSize, ThreadFactory threadFactory)\n```\n\n## unconfigurableExecutorService\nunconfigurableExecutorService主要用于包装现有的线程池，包装之后的线程池不能修改，相当于final的，函数签名如下：\n\n```\npublic static ExecutorService unconfigurableExecutorService(ExecutorService executor)\n```\n\n## unconfigurableScheduledExecutorService\nunconfigurableScheduledExecutorService用于包装可以周期性执行任务的线程池，包装之后的线程池不能修改，相当于final，函数签名如下：\n\n```\npublic static ScheduledExecutorService unconfigurableScheduledExecutorService(ScheduledExecutorService executor)\n```\n\n## defaultThreadFactory\ndefaultThreadFactory方法返回默认的工厂方法类，默认的工厂方法为线程池中新创建的线程命名为：\n> pool-[虚拟机中线程池编号]-thread-[线程编号]\n\n函数签名如下：\n\n```\npublic static ThreadFactory defaultThreadFactory()\n```\n\n\n","slug":"[Java并发包学习二]Executors介绍","published":1,"updated":"2015-08-21T07:56:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovau0024lo6b193ot3dl"},{"title":"[Java并发包学习三]ThreadFactory介绍","date":"2015-08-13T12:48:37.000Z","_content":"# 概述\nThreadFactory翻译过来是线程工厂，顾名思义，就是用来创建线程的，它用到了工厂模式的思想。它通常和线程池一起使用，主要用来控制创建新线程时的一些行为，比如设置线程的优先级，名字等等。它是一个接口，接口中只有一个方法:\n<!--more-->\n```\n    /**\n     * Constructs a new {@code Thread}.  Implementations may also initialize\n     * priority, name, daemon status, {@code ThreadGroup}, etc.\n     *\n     * @param r a runnable to be executed by new thread instance\n     * @return constructed thread, or {@code null} if the request to\n     *         create a thread is rejected\n     */\n    Thread newThread(Runnable r);\n```\n子类实现此方法并在其中完成自定义的行为。  \n\n\n# 实验\n下面我们通过一个简单的实验来解释ThreadFactory的作用，下面的代码首先创建一个类MyThreadFactoryTest，实现了ThreadFactory，newThread()方法中做了一些简单的行为：  \n\n* 创建新线程时，为线程设置一个名字；  \n* 创建新线程时，在控制台打印一条提示信息，并附上新线程的名字\n\n\n\n\n```\npackage com.winwill.thread;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * @author qifuguang\n * @date 15/8/11 20:28\n */\npublic class MyThreadFactoryTest implements ThreadFactory {\n    private final AtomicInteger count = new AtomicInteger(0);\n\n    public Thread newThread(Runnable r) {\n        int c = count.incrementAndGet();\n        Thread t = new Thread(r);\n        t.setName(\"test_thread_no.\" + c);\n        System.out.println(\"Create new thread, thread name: \" + t.getName());\n        return t;\n    }\n\n    public static void main(String[] args) throws Exception {\n        ExecutorService service = Executors.newFixedThreadPool(5, new MyThreadFactoryTest());\n        for (int i = 0; i < 5; i++) {\n            service.submit(new Runnable() {\n                public void run() {\n                    System.out.println(\"Start execute...\");\n                }\n            });\n        }\n    }\n}\n```\n运行这段程序会得到如下的结果：\n> Create new thread, thread name: test_thread_no.1\nCreate new thread, thread name: test_thread_no.2\nStart execute...\nStart execute...\nCreate new thread, thread name: test_thread_no.3\nStart execute...\nCreate new thread, thread name: test_thread_no.4\nStart execute...\nCreate new thread, thread name: test_thread_no.5\nStart execute...\n\n可以看到，运行结果符合我们的预期。\n\n# JDK中默认的ThreadFactory\n在JDK的Executors类中有一个DefaultThreadFactory类，它实现了ThreadFactory，它是JDK中默认的线程工厂类，从源码可以看到这个线程工厂类为线程池中新创建的线程设置的名字为：\n> pool-[线程池编号]-thread-[该线程池的线程编号]\n\n```\n /**\n     * The default thread factory\n     */\n    static class DefaultThreadFactory implements ThreadFactory {\n        private static final AtomicInteger poolNumber = new AtomicInteger(1);\n        private final ThreadGroup group;\n        private final AtomicInteger threadNumber = new AtomicInteger(1);\n        private final String namePrefix;\n\n        DefaultThreadFactory() {\n            SecurityManager s = System.getSecurityManager();\n            group = (s != null) ? s.getThreadGroup() :\n                                  Thread.currentThread().getThreadGroup();\n            namePrefix = \"pool-\" +\n                          poolNumber.getAndIncrement() +\n                         \"-thread-\";\n        }\n\n        public Thread newThread(Runnable r) {\n            Thread t = new Thread(group, r,\n                                  namePrefix + threadNumber.getAndIncrement(),\n                                  0);\n            if (t.isDaemon())\n                t.setDaemon(false);\n            if (t.getPriority() != Thread.NORM_PRIORITY)\n                t.setPriority(Thread.NORM_PRIORITY);\n            return t;\n        }\n    }\n```\n","source":"_posts/[Java并发包学习三]ThreadFactory介绍.md","raw":"title: \"[Java并发包学习三]ThreadFactory介绍\"\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-08-13 20:48:37\n---\n# 概述\nThreadFactory翻译过来是线程工厂，顾名思义，就是用来创建线程的，它用到了工厂模式的思想。它通常和线程池一起使用，主要用来控制创建新线程时的一些行为，比如设置线程的优先级，名字等等。它是一个接口，接口中只有一个方法:\n<!--more-->\n```\n    /**\n     * Constructs a new {@code Thread}.  Implementations may also initialize\n     * priority, name, daemon status, {@code ThreadGroup}, etc.\n     *\n     * @param r a runnable to be executed by new thread instance\n     * @return constructed thread, or {@code null} if the request to\n     *         create a thread is rejected\n     */\n    Thread newThread(Runnable r);\n```\n子类实现此方法并在其中完成自定义的行为。  \n\n\n# 实验\n下面我们通过一个简单的实验来解释ThreadFactory的作用，下面的代码首先创建一个类MyThreadFactoryTest，实现了ThreadFactory，newThread()方法中做了一些简单的行为：  \n\n* 创建新线程时，为线程设置一个名字；  \n* 创建新线程时，在控制台打印一条提示信息，并附上新线程的名字\n\n\n\n\n```\npackage com.winwill.thread;\n\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\nimport java.util.concurrent.ThreadFactory;\nimport java.util.concurrent.atomic.AtomicInteger;\n\n/**\n * @author qifuguang\n * @date 15/8/11 20:28\n */\npublic class MyThreadFactoryTest implements ThreadFactory {\n    private final AtomicInteger count = new AtomicInteger(0);\n\n    public Thread newThread(Runnable r) {\n        int c = count.incrementAndGet();\n        Thread t = new Thread(r);\n        t.setName(\"test_thread_no.\" + c);\n        System.out.println(\"Create new thread, thread name: \" + t.getName());\n        return t;\n    }\n\n    public static void main(String[] args) throws Exception {\n        ExecutorService service = Executors.newFixedThreadPool(5, new MyThreadFactoryTest());\n        for (int i = 0; i < 5; i++) {\n            service.submit(new Runnable() {\n                public void run() {\n                    System.out.println(\"Start execute...\");\n                }\n            });\n        }\n    }\n}\n```\n运行这段程序会得到如下的结果：\n> Create new thread, thread name: test_thread_no.1\nCreate new thread, thread name: test_thread_no.2\nStart execute...\nStart execute...\nCreate new thread, thread name: test_thread_no.3\nStart execute...\nCreate new thread, thread name: test_thread_no.4\nStart execute...\nCreate new thread, thread name: test_thread_no.5\nStart execute...\n\n可以看到，运行结果符合我们的预期。\n\n# JDK中默认的ThreadFactory\n在JDK的Executors类中有一个DefaultThreadFactory类，它实现了ThreadFactory，它是JDK中默认的线程工厂类，从源码可以看到这个线程工厂类为线程池中新创建的线程设置的名字为：\n> pool-[线程池编号]-thread-[该线程池的线程编号]\n\n```\n /**\n     * The default thread factory\n     */\n    static class DefaultThreadFactory implements ThreadFactory {\n        private static final AtomicInteger poolNumber = new AtomicInteger(1);\n        private final ThreadGroup group;\n        private final AtomicInteger threadNumber = new AtomicInteger(1);\n        private final String namePrefix;\n\n        DefaultThreadFactory() {\n            SecurityManager s = System.getSecurityManager();\n            group = (s != null) ? s.getThreadGroup() :\n                                  Thread.currentThread().getThreadGroup();\n            namePrefix = \"pool-\" +\n                          poolNumber.getAndIncrement() +\n                         \"-thread-\";\n        }\n\n        public Thread newThread(Runnable r) {\n            Thread t = new Thread(group, r,\n                                  namePrefix + threadNumber.getAndIncrement(),\n                                  0);\n            if (t.isDaemon())\n                t.setDaemon(false);\n            if (t.getPriority() != Thread.NORM_PRIORITY)\n                t.setPriority(Thread.NORM_PRIORITY);\n            return t;\n        }\n    }\n```\n","slug":"[Java并发包学习三]ThreadFactory介绍","published":1,"updated":"2015-08-30T11:17:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovaw0027lo6bo8xk0ui7"},{"title":"[Java并发包学习七]解密ThreadLocal","date":"2015-09-01T17:21:19.000Z","_content":"# 概述\n相信读者在网上也看了很多关于ThreadLocal的资料，很多博客都这样说：ThreadLocal为解决多线程程序的并发问题提供了一种新的思路；ThreadLocal的目的是为了解决多线程访问资源时的共享问题。如果你也这样认为的，那现在给你10秒钟，清空之前对ThreadLocal的**错误**的认知！\n<!--more-->\n看看JDK中的源码是怎么写的：\n>This class provides thread-local variables.  These variables differ from\n their normal counterparts in that each thread that accesses one (via its\n {@code get} or {@code set} method) has its own, independently initialized\n copy of the variable.  {@code ThreadLocal} instances are typically private\n static fields in classes that wish to associate state with a thread (e.g.,\n a user ID or Transaction ID).\n \n翻译过来大概是这样的(英文不好，如有更好的翻译，请留言说明)：  \n>ThreadLocal类用来提供线程内部的局部变量。这种变量在多线程环境下访问(通过get或set方法访问)时能保证各个线程里的变量相对独立于其他线程内的变量。ThreadLocal实例通常来说都是`private static`类型的，用于关联线程和线程的上下文。\n\n可以总结为一句话：**ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。**  \n举个例子，我出门需要先坐公交再做地铁，这里的坐公交和坐地铁就好比是同一个线程内的两个函数，我就是一个线程，我要完成这两个函数都需要同一个东西：公交卡（北京公交和地铁都使用公交卡），那么我为了不向这两个函数都传递公交卡这个变量（相当于不是一直带着公交卡上路），我可以这么做：将公交卡事先交给一个机构，当我需要刷卡的时候再向这个机构要公交卡（当然每次拿的都是同一张公交卡）。这样就能达到只要是我(同一个线程)需要公交卡，何时何地都能向这个机构要的目的。\n\n有人要说了：*你可以将公交卡设置为全局变量啊，这样不是也能何时何地都能取公交卡吗？*但是如果有很多个人（很多个线程）呢？大家可不能都使用同一张公交卡吧(我们假设公交卡是实名认证的)，这样不就乱套了嘛。现在明白了吧？这就是ThreadLocal设计的初衷：提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。\n\n# ThreadLocal基本操作\n## 构造函数\nThreadLocal的构造函数签名是这样的：\n\n```\n    /**\n     * Creates a thread local variable.\n     * @see #withInitial(java.util.function.Supplier)\n     */\n    public ThreadLocal() {\n    }\n```\n内部啥也没做。\n\n## initialValue函数\ninitialValue函数用来设置ThreadLocal的初始值，函数签名如下：\n\n```\n    protected T initialValue() {\n        return null;\n    }\n```\n该函数在调用`get`函数的时候会第一次调用，但是如果一开始就调用了`set`函数，则该函数不会被调用。通常该函数只会被调用一次，除非手动调用了`remove`函数之后又调用`get`函数，这种情况下，`get`函数中还是会调用`initialValue`函数。该函数是protected类型的，很显然是建议在子类重载该函数的，所以通常该函数都会以匿名内部类的形式被重载，以指定初始值，比如：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/2 00:05\n */\npublic class TestThreadLocal {\n    private static final ThreadLocal<Integer> value = new ThreadLocal<Integer>() {\n        @Override\n        protected Integer initialValue() {\n            return Integer.valueOf(1);\n        }\n    };\n}\n\n```\n\n## get函数\n该函数用来获取与当前线程关联的ThreadLocal的值，函数签名如下：\n\n```\npublic T get()\n```\n如果当前线程没有该ThreadLocal的值，则调用`initialValue`函数获取初始值返回。\n\n## set函数\nset函数用来设置当前线程的该ThreadLocal的值，函数签名如下：\n\n```\npublic void set(T value)\n```\n设置当前线程的ThreadLocal的值为value。\n\n## remove函数\nremove函数用来将当前线程的ThreadLocal绑定的值删除，函数签名如下：\n\n```\npublic void remove()\n```\n在某些情况下需要手动调用该函数，防止内存泄露。\n\n# 代码演示\n学习了最基本的操作之后，我们用一段代码来演示ThreadLocal的用法，该例子实现下面这个场景：\n\n> 有5个线程，这5个线程都有一个值value，初始值为0，线程运行时用一个循环往value值相加数字。\n\n代码实现：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/2 00:05\n */\npublic class TestThreadLocal {\n    private static final ThreadLocal<Integer> value = new ThreadLocal<Integer>() {\n        @Override\n        protected Integer initialValue() {\n            return 0;\n        }\n    };\n\n    public static void main(String[] args) {\n        for (int i = 0; i < 5; i++) {\n            new Thread(new MyThread(i)).start();\n        }\n    }\n\n    static class MyThread implements Runnable {\n        private int index;\n\n        public MyThread(int index) {\n            this.index = index;\n        }\n\n        public void run() {\n            System.out.println(\"线程\" + index + \"的初始value:\" + value.get());\n            for (int i = 0; i < 10; i++) {\n                value.set(value.get() + i);\n            }\n            System.out.println(\"线程\" + index + \"的累加value:\" + value.get());\n        }\n    }\n}\n```\n执行结果为：\n> 线程0的初始value:0  \n线程3的初始value:0  \n线程2的初始value:0  \n线程2的累加value:45  \n线程1的初始value:0  \n线程3的累加value:45  \n线程0的累加value:45  \n线程1的累加value:45  \n线程4的初始value:0  \n线程4的累加value:45  \n\n可以看到，各个线程的value值是相互独立的，本线程的累加操作不会影响到其他线程的值，真正达到了线程内部隔离的效果。\n\n# 如何实现的\n看了基本介绍，也看了最简单的效果演示之后，我们更应该好好研究下ThreadLocal内部的实现原理。如果给你设计，你会怎么设计？相信大部分人会有这样的想法：  \n> 每个ThreadLocal类创建一个Map，然后用线程的ID作为Map的key，实例对象作为Map的value，这样就能达到各个线程的值隔离的效果。\n\n没错，这是最简单的设计方案，JDK最早期的ThreadLocal就是这样设计的。JDK1.3（不确定是否是1.3）之后ThreadLocal的设计换了一种方式。\n\n我们先看看JDK8的ThreadLocal的`get`方法的源码:\n\n```\n  public T get() {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n```\n其中getMap的源码：\n\n```\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n```\nsetInitialValue函数的源码：\n\n```\n    private T setInitialValue() {\n        T value = initialValue();\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n        return value;\n    }\n```\ncreateMap函数的源码：\n\n```\n    void createMap(Thread t, T firstValue) {\n        t.threadLocals = new ThreadLocalMap(this, firstValue);\n    }\n```\n简单解析一下，get方法的流程是这样的：  \n\n1. 首先获取当前线程\n2. 根据当前线程获取一个Map\n3. 如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5\n4. 如果e不为null，则返回e.value，否则转到5\n5. Map为空或者e为空，则通过`initialValue`函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map\n\n然后需要注意的是Thread类中包含一个成员变量：\n\n```\nThreadLocal.ThreadLocalMap threadLocals = null;\n```\n\n所以，可以总结一下ThreadLocal的设计思路：  \n**每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。**  \n这个方案刚好与我们开始说的简单的设计方案相反。查阅了一下资料，这样设计的主要有以下几点优势：  \n\n* 这样设计之后每个Map的Entry数量变小了：之前是Thread的数量，现在是ThreadLocal的数量，能提高性能，据说性能的提升不是一点两点(没有亲测)\n* 当Thread销毁之后对应的ThreadLocalMap也就随之销毁了，能减少内存使用量。\n\n# 再深入一点\n先交代一个事实：**ThreadLocalMap是使用ThreadLocal的弱引用作为Key的**：\n\n```\nstatic class ThreadLocalMap {\n\n        /**\n         * The entries in this hash map extend WeakReference, using\n         * its main ref field as the key (which is always a\n         * ThreadLocal object).  Note that null keys (i.e. entry.get()\n         * == null) mean that the key is no longer referenced, so the\n         * entry can be expunged from table.  Such entries are referred to\n         * as \"stale entries\" in the code that follows.\n         */\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n        ...\n        ...\n}\n\n```\n下图是本文介绍到的一些对象之间的引用关系图，实线表示强引用，虚线表示弱引用：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/解密ThreadLocal/ThreadLocal.png)\n\n然后网上就传言，ThreadLocal会引发内存泄露，他们的理由是这样的：\n\n>如上图，ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：  \n**ThreadLocal Ref -> Thread -> ThreaLocalMap -> Entry -> value**  \n永远无法回收，造成内存泄露。\n\n我们来看看到底会不会出现这种情况。\n其实，在JDK的ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施，下面是ThreadLocalMap的`getEntry`方法的源码：\n\n```\n        private Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n```\n`getEntryAfterMiss`函数的源码：\n\n```\n       private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {\n            Entry[] tab = table;\n            int len = tab.length;\n\n            while (e != null) {\n                ThreadLocal<?> k = e.get();\n                if (k == key)\n                    return e;\n                if (k == null)\n                    expungeStaleEntry(i);\n                else\n                    i = nextIndex(i, len);\n                e = tab[i];\n            }\n            return null;\n        }\n```\n`expungeStaleEntry`函数的源码：\n\n```\n private int expungeStaleEntry(int staleSlot) {\n            Entry[] tab = table;\n            int len = tab.length;\n\n            // expunge entry at staleSlot\n            tab[staleSlot].value = null;\n            tab[staleSlot] = null;\n            size--;\n\n            // Rehash until we encounter null\n            Entry e;\n            int i;\n            for (i = nextIndex(staleSlot, len);\n                 (e = tab[i]) != null;\n                 i = nextIndex(i, len)) {\n                ThreadLocal<?> k = e.get();\n                if (k == null) {\n                    e.value = null;\n                    tab[i] = null;\n                    size--;\n                } else {\n                    int h = k.threadLocalHashCode & (len - 1);\n                    if (h != i) {\n                        tab[i] = null;\n\n                        // Unlike Knuth 6.4 Algorithm R, we must scan until\n                        // null because multiple entries could have been stale.\n                        while (tab[h] != null)\n                            h = nextIndex(h, len);\n                        tab[h] = e;\n                    }\n                }\n            }\n            return i;\n        }\n```\n整理一下ThreadLocalMap的`getEntry`函数的流程：\n\n1. 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode & (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e；\n2. 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询\n\n在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。仔细研究代码可以发现，`set`操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。\n但是光这样还是不够的，上面的设计思路依赖一个前提条件：**要调用ThreadLocalMap的`genEntry`函数或者`set`函数。**这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的`remove`函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成`private static`的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。\n\n# 声明\n本文为作者自己的个人见解，如理解有误，请留言相告，谢谢。  \n**转载请注明出处：**\n[http://qifuguang.me/2015/09/02/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E4%B8%83]%E8%A7%A3%E5%AF%86ThreadLocal/](http://qifuguang.me/2015/09/02/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E4%B8%83]%E8%A7%A3%E5%AF%86ThreadLocal/)\n","source":"_posts/[Java并发包学习七]解密ThreadLocal.md","raw":"title: '[Java并发包学习七]解密ThreadLocal'\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-09-02 01:21:19\n---\n# 概述\n相信读者在网上也看了很多关于ThreadLocal的资料，很多博客都这样说：ThreadLocal为解决多线程程序的并发问题提供了一种新的思路；ThreadLocal的目的是为了解决多线程访问资源时的共享问题。如果你也这样认为的，那现在给你10秒钟，清空之前对ThreadLocal的**错误**的认知！\n<!--more-->\n看看JDK中的源码是怎么写的：\n>This class provides thread-local variables.  These variables differ from\n their normal counterparts in that each thread that accesses one (via its\n {@code get} or {@code set} method) has its own, independently initialized\n copy of the variable.  {@code ThreadLocal} instances are typically private\n static fields in classes that wish to associate state with a thread (e.g.,\n a user ID or Transaction ID).\n \n翻译过来大概是这样的(英文不好，如有更好的翻译，请留言说明)：  \n>ThreadLocal类用来提供线程内部的局部变量。这种变量在多线程环境下访问(通过get或set方法访问)时能保证各个线程里的变量相对独立于其他线程内的变量。ThreadLocal实例通常来说都是`private static`类型的，用于关联线程和线程的上下文。\n\n可以总结为一句话：**ThreadLocal的作用是提供线程内的局部变量，这种变量在线程的生命周期内起作用，减少同一个线程内多个函数或者组件之间一些公共变量的传递的复杂度。**  \n举个例子，我出门需要先坐公交再做地铁，这里的坐公交和坐地铁就好比是同一个线程内的两个函数，我就是一个线程，我要完成这两个函数都需要同一个东西：公交卡（北京公交和地铁都使用公交卡），那么我为了不向这两个函数都传递公交卡这个变量（相当于不是一直带着公交卡上路），我可以这么做：将公交卡事先交给一个机构，当我需要刷卡的时候再向这个机构要公交卡（当然每次拿的都是同一张公交卡）。这样就能达到只要是我(同一个线程)需要公交卡，何时何地都能向这个机构要的目的。\n\n有人要说了：*你可以将公交卡设置为全局变量啊，这样不是也能何时何地都能取公交卡吗？*但是如果有很多个人（很多个线程）呢？大家可不能都使用同一张公交卡吧(我们假设公交卡是实名认证的)，这样不就乱套了嘛。现在明白了吧？这就是ThreadLocal设计的初衷：提供线程内部的局部变量，在本线程内随时随地可取，隔离其他线程。\n\n# ThreadLocal基本操作\n## 构造函数\nThreadLocal的构造函数签名是这样的：\n\n```\n    /**\n     * Creates a thread local variable.\n     * @see #withInitial(java.util.function.Supplier)\n     */\n    public ThreadLocal() {\n    }\n```\n内部啥也没做。\n\n## initialValue函数\ninitialValue函数用来设置ThreadLocal的初始值，函数签名如下：\n\n```\n    protected T initialValue() {\n        return null;\n    }\n```\n该函数在调用`get`函数的时候会第一次调用，但是如果一开始就调用了`set`函数，则该函数不会被调用。通常该函数只会被调用一次，除非手动调用了`remove`函数之后又调用`get`函数，这种情况下，`get`函数中还是会调用`initialValue`函数。该函数是protected类型的，很显然是建议在子类重载该函数的，所以通常该函数都会以匿名内部类的形式被重载，以指定初始值，比如：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/2 00:05\n */\npublic class TestThreadLocal {\n    private static final ThreadLocal<Integer> value = new ThreadLocal<Integer>() {\n        @Override\n        protected Integer initialValue() {\n            return Integer.valueOf(1);\n        }\n    };\n}\n\n```\n\n## get函数\n该函数用来获取与当前线程关联的ThreadLocal的值，函数签名如下：\n\n```\npublic T get()\n```\n如果当前线程没有该ThreadLocal的值，则调用`initialValue`函数获取初始值返回。\n\n## set函数\nset函数用来设置当前线程的该ThreadLocal的值，函数签名如下：\n\n```\npublic void set(T value)\n```\n设置当前线程的ThreadLocal的值为value。\n\n## remove函数\nremove函数用来将当前线程的ThreadLocal绑定的值删除，函数签名如下：\n\n```\npublic void remove()\n```\n在某些情况下需要手动调用该函数，防止内存泄露。\n\n# 代码演示\n学习了最基本的操作之后，我们用一段代码来演示ThreadLocal的用法，该例子实现下面这个场景：\n\n> 有5个线程，这5个线程都有一个值value，初始值为0，线程运行时用一个循环往value值相加数字。\n\n代码实现：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/2 00:05\n */\npublic class TestThreadLocal {\n    private static final ThreadLocal<Integer> value = new ThreadLocal<Integer>() {\n        @Override\n        protected Integer initialValue() {\n            return 0;\n        }\n    };\n\n    public static void main(String[] args) {\n        for (int i = 0; i < 5; i++) {\n            new Thread(new MyThread(i)).start();\n        }\n    }\n\n    static class MyThread implements Runnable {\n        private int index;\n\n        public MyThread(int index) {\n            this.index = index;\n        }\n\n        public void run() {\n            System.out.println(\"线程\" + index + \"的初始value:\" + value.get());\n            for (int i = 0; i < 10; i++) {\n                value.set(value.get() + i);\n            }\n            System.out.println(\"线程\" + index + \"的累加value:\" + value.get());\n        }\n    }\n}\n```\n执行结果为：\n> 线程0的初始value:0  \n线程3的初始value:0  \n线程2的初始value:0  \n线程2的累加value:45  \n线程1的初始value:0  \n线程3的累加value:45  \n线程0的累加value:45  \n线程1的累加value:45  \n线程4的初始value:0  \n线程4的累加value:45  \n\n可以看到，各个线程的value值是相互独立的，本线程的累加操作不会影响到其他线程的值，真正达到了线程内部隔离的效果。\n\n# 如何实现的\n看了基本介绍，也看了最简单的效果演示之后，我们更应该好好研究下ThreadLocal内部的实现原理。如果给你设计，你会怎么设计？相信大部分人会有这样的想法：  \n> 每个ThreadLocal类创建一个Map，然后用线程的ID作为Map的key，实例对象作为Map的value，这样就能达到各个线程的值隔离的效果。\n\n没错，这是最简单的设计方案，JDK最早期的ThreadLocal就是这样设计的。JDK1.3（不确定是否是1.3）之后ThreadLocal的设计换了一种方式。\n\n我们先看看JDK8的ThreadLocal的`get`方法的源码:\n\n```\n  public T get() {\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null) {\n            ThreadLocalMap.Entry e = map.getEntry(this);\n            if (e != null) {\n                @SuppressWarnings(\"unchecked\")\n                T result = (T)e.value;\n                return result;\n            }\n        }\n        return setInitialValue();\n    }\n```\n其中getMap的源码：\n\n```\n    ThreadLocalMap getMap(Thread t) {\n        return t.threadLocals;\n    }\n```\nsetInitialValue函数的源码：\n\n```\n    private T setInitialValue() {\n        T value = initialValue();\n        Thread t = Thread.currentThread();\n        ThreadLocalMap map = getMap(t);\n        if (map != null)\n            map.set(this, value);\n        else\n            createMap(t, value);\n        return value;\n    }\n```\ncreateMap函数的源码：\n\n```\n    void createMap(Thread t, T firstValue) {\n        t.threadLocals = new ThreadLocalMap(this, firstValue);\n    }\n```\n简单解析一下，get方法的流程是这样的：  \n\n1. 首先获取当前线程\n2. 根据当前线程获取一个Map\n3. 如果获取的Map不为空，则在Map中以ThreadLocal的引用作为key来在Map中获取对应的value e，否则转到5\n4. 如果e不为null，则返回e.value，否则转到5\n5. Map为空或者e为空，则通过`initialValue`函数获取初始值value，然后用ThreadLocal的引用和value作为firstKey和firstValue创建一个新的Map\n\n然后需要注意的是Thread类中包含一个成员变量：\n\n```\nThreadLocal.ThreadLocalMap threadLocals = null;\n```\n\n所以，可以总结一下ThreadLocal的设计思路：  \n**每个Thread维护一个ThreadLocalMap映射表，这个映射表的key是ThreadLocal实例本身，value是真正需要存储的Object。**  \n这个方案刚好与我们开始说的简单的设计方案相反。查阅了一下资料，这样设计的主要有以下几点优势：  \n\n* 这样设计之后每个Map的Entry数量变小了：之前是Thread的数量，现在是ThreadLocal的数量，能提高性能，据说性能的提升不是一点两点(没有亲测)\n* 当Thread销毁之后对应的ThreadLocalMap也就随之销毁了，能减少内存使用量。\n\n# 再深入一点\n先交代一个事实：**ThreadLocalMap是使用ThreadLocal的弱引用作为Key的**：\n\n```\nstatic class ThreadLocalMap {\n\n        /**\n         * The entries in this hash map extend WeakReference, using\n         * its main ref field as the key (which is always a\n         * ThreadLocal object).  Note that null keys (i.e. entry.get()\n         * == null) mean that the key is no longer referenced, so the\n         * entry can be expunged from table.  Such entries are referred to\n         * as \"stale entries\" in the code that follows.\n         */\n        static class Entry extends WeakReference<ThreadLocal<?>> {\n            /** The value associated with this ThreadLocal. */\n            Object value;\n\n            Entry(ThreadLocal<?> k, Object v) {\n                super(k);\n                value = v;\n            }\n        }\n        ...\n        ...\n}\n\n```\n下图是本文介绍到的一些对象之间的引用关系图，实线表示强引用，虚线表示弱引用：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/解密ThreadLocal/ThreadLocal.png)\n\n然后网上就传言，ThreadLocal会引发内存泄露，他们的理由是这样的：\n\n>如上图，ThreadLocalMap使用ThreadLocal的弱引用作为key，如果一个ThreadLocal没有外部强引用引用他，那么系统gc的时候，这个ThreadLocal势必会被回收，这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：  \n**ThreadLocal Ref -> Thread -> ThreaLocalMap -> Entry -> value**  \n永远无法回收，造成内存泄露。\n\n我们来看看到底会不会出现这种情况。\n其实，在JDK的ThreadLocalMap的设计中已经考虑到这种情况，也加上了一些防护措施，下面是ThreadLocalMap的`getEntry`方法的源码：\n\n```\n        private Entry getEntry(ThreadLocal<?> key) {\n            int i = key.threadLocalHashCode & (table.length - 1);\n            Entry e = table[i];\n            if (e != null && e.get() == key)\n                return e;\n            else\n                return getEntryAfterMiss(key, i, e);\n        }\n```\n`getEntryAfterMiss`函数的源码：\n\n```\n       private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {\n            Entry[] tab = table;\n            int len = tab.length;\n\n            while (e != null) {\n                ThreadLocal<?> k = e.get();\n                if (k == key)\n                    return e;\n                if (k == null)\n                    expungeStaleEntry(i);\n                else\n                    i = nextIndex(i, len);\n                e = tab[i];\n            }\n            return null;\n        }\n```\n`expungeStaleEntry`函数的源码：\n\n```\n private int expungeStaleEntry(int staleSlot) {\n            Entry[] tab = table;\n            int len = tab.length;\n\n            // expunge entry at staleSlot\n            tab[staleSlot].value = null;\n            tab[staleSlot] = null;\n            size--;\n\n            // Rehash until we encounter null\n            Entry e;\n            int i;\n            for (i = nextIndex(staleSlot, len);\n                 (e = tab[i]) != null;\n                 i = nextIndex(i, len)) {\n                ThreadLocal<?> k = e.get();\n                if (k == null) {\n                    e.value = null;\n                    tab[i] = null;\n                    size--;\n                } else {\n                    int h = k.threadLocalHashCode & (len - 1);\n                    if (h != i) {\n                        tab[i] = null;\n\n                        // Unlike Knuth 6.4 Algorithm R, we must scan until\n                        // null because multiple entries could have been stale.\n                        while (tab[h] != null)\n                            h = nextIndex(h, len);\n                        tab[h] = e;\n                    }\n                }\n            }\n            return i;\n        }\n```\n整理一下ThreadLocalMap的`getEntry`函数的流程：\n\n1. 首先从ThreadLocal的直接索引位置(通过ThreadLocal.threadLocalHashCode & (len-1)运算得到)获取Entry e，如果e不为null并且key相同则返回e；\n2. 如果e为null或者key不一致则向下一个位置查询，如果下一个位置的key和当前需要查询的key相等，则返回对应的Entry，否则，如果key值为null，则擦除该位置的Entry，否则继续向下一个位置查询\n\n在这个过程中遇到的key为null的Entry都会被擦除，那么Entry内的value也就没有强引用链，自然会被回收。仔细研究代码可以发现，`set`操作也有类似的思想，将key为null的这些Entry都删除，防止内存泄露。\n但是光这样还是不够的，上面的设计思路依赖一个前提条件：**要调用ThreadLocalMap的`genEntry`函数或者`set`函数。**这当然是不可能任何情况都成立的，所以很多情况下需要使用者手动调用ThreadLocal的`remove`函数，手动删除不再需要的ThreadLocal，防止内存泄露。所以JDK建议将ThreadLocal变量定义成`private static`的，这样的话ThreadLocal的生命周期就更长，由于一直存在ThreadLocal的强引用，所以ThreadLocal也就不会被回收，也就能保证任何时候都能根据ThreadLocal的弱引用访问到Entry的value值，然后remove它，防止内存泄露。\n\n# 声明\n本文为作者自己的个人见解，如理解有误，请留言相告，谢谢。  \n**转载请注明出处：**\n[http://qifuguang.me/2015/09/02/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E4%B8%83]%E8%A7%A3%E5%AF%86ThreadLocal/](http://qifuguang.me/2015/09/02/[Java%E5%B9%B6%E5%8F%91%E5%8C%85%E5%AD%A6%E4%B9%A0%E4%B8%83]%E8%A7%A3%E5%AF%86ThreadLocal/)\n","slug":"[Java并发包学习七]解密ThreadLocal","published":1,"updated":"2015-10-13T06:03:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovax002alo6b6zp6qu5q"},{"title":"[Java并发包学习一]Executor和ExecutorService","date":"2015-08-10T17:05:45.000Z","_content":"本文介绍jdk8并发包中的Executor/ExecutorService这两个接口。\n# Executor接口\n## 概述\n该类提供一个提交任务的方法，提交的任务可以在提交程序本线程运行，也可以在不同的线程运行，也可以在一个线程池中的线程运行，全看如何使用。\n> However, the {@code Executor} interface does not strictly\n require that execution be asynchronous. In the simplest case, an executor can run the submitted task immediately in the caller's thread\n\n然而，该接口并没有严格规定提交的任务是异步执行的，最简单的情况，提交的任务可以直接由任务的caller thread执行。\n>More typically, tasks are executed in some thread other\nthan the caller's thread.  The executor below spawns a new thread for each task\n<!--more-->\n更典型的情况是提交的任务并不是由caller thread执行，而是创建了新的线程去执行，比如线程池。\n\n## execute方法\n该接口提供一个方法：\n```\nvoid execute(Runnable command);\n```\n该方法的作用是提交一个任务，这个任务在未来的某一时刻会被执行，该任务可能被新的线程执行，可能被线程池中的线程执行，也有可能就被提交者本身的线程执行。\n\n# ExecutorService接口\n## 概述\nExecutorService继承于Executor，它提供一些可以管理任务的执行、取消、结束的方法。\n## shutdown方法\n```\nvoid shutdown();\n```\nshutdown方法调用之后，马上拒绝接收新的任务，但是之前已经提交的任务会继续执行。\n\n## shutdownNow方法\n```\nList<Runnable> shutdownNow();\n```\n该函数调用之后，马上拒绝接收新的任务，并且会尝试结束当前正在执行的任务，直到所有任务真正结束为止，并且会返回等待执行的任务的列表。\n\n## isShutdown方法\n```\nboolean isShutdown();\n```\n该函数判断service是否已经被shutdown，如果调用过shutdown函数，则返回true，否则返回false。\n\n## isTerminated方法\n```\nboolean isTerminated();\n```\n该函数判断service中得所有任务是否已经全部执行完毕，并且应该注意的是：**如果没有调用过shutdown函数或者shutdownNow函数，该函数的返回值不可能为true。**\n\n## awaitTermination方法\n```\nboolean awaitTermination(long timeout, TimeUnit unit)\n        throws InterruptedException;\n```\n该函数会一直阻塞直到所有的任务已经被执行或者等待时间到。\n\n## submit方法\n```\n<T> Future<T> submit(Callable<T> task);\n<T> Future<T> submit(Runnable task, T result);\nFuture<?> submit(Runnable task);\n```\n这些函数都是向service提交一个任务，并且返回一个Futrue对象，用于追踪任务的执行情况。区别在于第一个函数在任务执行完毕之后Futrue.get()将会返回任务执行的结果，第二个函数在任务执行完毕之后Future.get()将会返回给定的result结果，而第三个函数在任务执行完毕之后Future.get()将会返回null。\n\n## invokeAll方法\n```\n<T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks) throws InterruptedException;\n\n<T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,long timeout, TimeUnit unit)\nthrows InterruptedException;\n```\n这些方法比较好理解，就是执行任务列表中的所有任务，并返回与每个任务对应的Futue。也就是说，任务彼此之间不会相互影响，可以通过future跟踪每一个任务的执行情况，比如是否被取消，是正常完成，还是异常完成，这主要使用Future类提供的API。invokeAll是一个阻塞方法，会等待任务列表中的所有任务都执行完成。不管任务是正常完成，还是异常终止，Future.isDone()始终返回true。通过\nFuture.isCanceled()可以判断任务是否在执行的过程中被取消。通过Future.get()可以获取任务的返回结果，或者是任务在执行中抛出的异常。\n\n## invokeAny方法\n```\n<T> T invokeAny(Collection<? extends Callable<T>> tasks)\n        throws InterruptedException, ExecutionException;\n\n<T> T invokeAny(Collection<? extends Callable<T>> tasks,\n      long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;\n```\n上面的函数执行给定的一系列任务，当某一个任务成功执行（没有抛出异常）时，返回该任务对应的Future对象，其他所有未被执行的任务都将取消。如果执行过程中修改了tasks列表，则返回的结果是不确定的。第二个函数带有超时时间。此外还应该注意：\n>* 一旦有1个任务正常完成(执行过程中没有抛异常)，线程池会终止>其他未完成的任务 。\n>* 如果提交的任务列表中，没有1个正常完成的任务，那么调用invokeAny会抛异常，究竟抛的是哪儿个任务的异常，无关紧要\n>* invokeAny()和任务的提交顺序无关，只是返回最早正常执行完成的任务\n>* 如果在超时之前，所有任务已经都是异常终止，那就没有必要在等下去了；如果超时之后，仍然有正在运行或等待运行的任务，那么会抛出TimeoutException。 \n\n","source":"_posts/[Java并发包学习一]Executor和ExecutorService.md","raw":"title: \"[Java并发包学习一]Executor和ExecutorService\"\ndate: 2015-08-11 01:05:45\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\n---\n本文介绍jdk8并发包中的Executor/ExecutorService这两个接口。\n# Executor接口\n## 概述\n该类提供一个提交任务的方法，提交的任务可以在提交程序本线程运行，也可以在不同的线程运行，也可以在一个线程池中的线程运行，全看如何使用。\n> However, the {@code Executor} interface does not strictly\n require that execution be asynchronous. In the simplest case, an executor can run the submitted task immediately in the caller's thread\n\n然而，该接口并没有严格规定提交的任务是异步执行的，最简单的情况，提交的任务可以直接由任务的caller thread执行。\n>More typically, tasks are executed in some thread other\nthan the caller's thread.  The executor below spawns a new thread for each task\n<!--more-->\n更典型的情况是提交的任务并不是由caller thread执行，而是创建了新的线程去执行，比如线程池。\n\n## execute方法\n该接口提供一个方法：\n```\nvoid execute(Runnable command);\n```\n该方法的作用是提交一个任务，这个任务在未来的某一时刻会被执行，该任务可能被新的线程执行，可能被线程池中的线程执行，也有可能就被提交者本身的线程执行。\n\n# ExecutorService接口\n## 概述\nExecutorService继承于Executor，它提供一些可以管理任务的执行、取消、结束的方法。\n## shutdown方法\n```\nvoid shutdown();\n```\nshutdown方法调用之后，马上拒绝接收新的任务，但是之前已经提交的任务会继续执行。\n\n## shutdownNow方法\n```\nList<Runnable> shutdownNow();\n```\n该函数调用之后，马上拒绝接收新的任务，并且会尝试结束当前正在执行的任务，直到所有任务真正结束为止，并且会返回等待执行的任务的列表。\n\n## isShutdown方法\n```\nboolean isShutdown();\n```\n该函数判断service是否已经被shutdown，如果调用过shutdown函数，则返回true，否则返回false。\n\n## isTerminated方法\n```\nboolean isTerminated();\n```\n该函数判断service中得所有任务是否已经全部执行完毕，并且应该注意的是：**如果没有调用过shutdown函数或者shutdownNow函数，该函数的返回值不可能为true。**\n\n## awaitTermination方法\n```\nboolean awaitTermination(long timeout, TimeUnit unit)\n        throws InterruptedException;\n```\n该函数会一直阻塞直到所有的任务已经被执行或者等待时间到。\n\n## submit方法\n```\n<T> Future<T> submit(Callable<T> task);\n<T> Future<T> submit(Runnable task, T result);\nFuture<?> submit(Runnable task);\n```\n这些函数都是向service提交一个任务，并且返回一个Futrue对象，用于追踪任务的执行情况。区别在于第一个函数在任务执行完毕之后Futrue.get()将会返回任务执行的结果，第二个函数在任务执行完毕之后Future.get()将会返回给定的result结果，而第三个函数在任务执行完毕之后Future.get()将会返回null。\n\n## invokeAll方法\n```\n<T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks) throws InterruptedException;\n\n<T> List<Future<T>> invokeAll(Collection<? extends Callable<T>> tasks,long timeout, TimeUnit unit)\nthrows InterruptedException;\n```\n这些方法比较好理解，就是执行任务列表中的所有任务，并返回与每个任务对应的Futue。也就是说，任务彼此之间不会相互影响，可以通过future跟踪每一个任务的执行情况，比如是否被取消，是正常完成，还是异常完成，这主要使用Future类提供的API。invokeAll是一个阻塞方法，会等待任务列表中的所有任务都执行完成。不管任务是正常完成，还是异常终止，Future.isDone()始终返回true。通过\nFuture.isCanceled()可以判断任务是否在执行的过程中被取消。通过Future.get()可以获取任务的返回结果，或者是任务在执行中抛出的异常。\n\n## invokeAny方法\n```\n<T> T invokeAny(Collection<? extends Callable<T>> tasks)\n        throws InterruptedException, ExecutionException;\n\n<T> T invokeAny(Collection<? extends Callable<T>> tasks,\n      long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;\n```\n上面的函数执行给定的一系列任务，当某一个任务成功执行（没有抛出异常）时，返回该任务对应的Future对象，其他所有未被执行的任务都将取消。如果执行过程中修改了tasks列表，则返回的结果是不确定的。第二个函数带有超时时间。此外还应该注意：\n>* 一旦有1个任务正常完成(执行过程中没有抛异常)，线程池会终止>其他未完成的任务 。\n>* 如果提交的任务列表中，没有1个正常完成的任务，那么调用invokeAny会抛异常，究竟抛的是哪儿个任务的异常，无关紧要\n>* invokeAny()和任务的提交顺序无关，只是返回最早正常执行完成的任务\n>* 如果在超时之前，所有任务已经都是异常终止，那就没有必要在等下去了；如果超时之后，仍然有正在运行或等待运行的任务，那么会抛出TimeoutException。 \n\n","slug":"[Java并发包学习一]Executor和ExecutorService","published":1,"updated":"2015-08-30T11:17:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovay002dlo6b0befu9eo"},{"title":"[Java]虚拟机基本结构","date":"2015-07-31T19:37:06.000Z","_content":"* java堆用于存放对象示例，与数据相关，java栈主要与线程的函数调用相关\n* 函数调用一次出入java栈一次，调用的时候入栈，调用结束（return或者throw）出栈，函数参数和函数局部  变量保存在栈帧中，所以函数调用结束之后栈帧被弹出，相应的局部变量也就失效了。\n<!--more-->\n* 函数参数和局部变量越多，需要栈帧中保存的局部变量表就越大，函数调用的层次就会越少。\n* 局部变量是垃圾回收的很重要的根节点，任何被局部变量直接或者间接引用的对象都不会被回收。\n* 对已非逃逸对象，虚拟机可以进行内存分配优化，将这些对象分配在栈上。\n* 栈上分配依赖逃逸分析和变量替换的实现。\n* 方法区所有线程共享，用于保存类，类的方法，类的变量等，在JDK1.6和JDK1.7中，方法区就是永久区，在JDK1.8中，永久区已经被彻底移除，取而代之的是元数据区。\n","source":"_posts/[Java]虚拟机基本结构.md","raw":"title: \"[Java]虚拟机基本结构\"\ndate: 2015-08-01 03:37:06\ntags: [Java]\ncategories: [Java]\n---\n* java堆用于存放对象示例，与数据相关，java栈主要与线程的函数调用相关\n* 函数调用一次出入java栈一次，调用的时候入栈，调用结束（return或者throw）出栈，函数参数和函数局部  变量保存在栈帧中，所以函数调用结束之后栈帧被弹出，相应的局部变量也就失效了。\n<!--more-->\n* 函数参数和局部变量越多，需要栈帧中保存的局部变量表就越大，函数调用的层次就会越少。\n* 局部变量是垃圾回收的很重要的根节点，任何被局部变量直接或者间接引用的对象都不会被回收。\n* 对已非逃逸对象，虚拟机可以进行内存分配优化，将这些对象分配在栈上。\n* 栈上分配依赖逃逸分析和变量替换的实现。\n* 方法区所有线程共享，用于保存类，类的方法，类的变量等，在JDK1.6和JDK1.7中，方法区就是永久区，在JDK1.8中，永久区已经被彻底移除，取而代之的是元数据区。\n","slug":"[Java]虚拟机基本结构","published":1,"updated":"2015-08-21T08:19:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovb1002glo6bksajfdoz"},{"title":"[Java]直接内存和堆内存的性能比较","date":"2015-07-31T19:39:32.000Z","_content":"## 背景知识\n>在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。**这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。**\n显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。服务器管理员配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但经常会忽略掉直接内存，使得各个内存区域的总和大于物理内存限制（包括物理上的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。\n<!--more-->\n上面这段话引用自[该文章](http://book.51cto.com/art/201107/278886.htm)\n\n## 代码实验\n注意到上面这段话中的黑体字：这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据，然而这个“一些场景”具体指什么呢？我们通过代码做个实验看看。\n    \n```\npackage com.winwill.jvm;\n\nimport org.junit.Test;\n\nimport java.nio.ByteBuffer;\n\n/**\n * @author qifuguang\n * @date 15-5-26 下午8:23\n */\npublic class TestDirectMemory {\n    /**\n     * 测试DirectMemory和Heap读写速度。\n     */\n    @Test\n    public void testDirectMemoryWriteAndReadSpeed() {\n        long tsStart = System.currentTimeMillis();\n        ByteBuffer buffer = ByteBuffer.allocateDirect(400);\n        for (int i = 0; i < 100000; i++) {\n            for (int j = 0; j < 100; j++) {\n                buffer.putInt(j);\n            }\n            buffer.flip();\n            for (byte j = 0; j < 100; j++) {\n                buffer.getInt();\n            }\n            buffer.clear();\n        }\n        System.out.println(\"DirectMemory读写耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n        tsStart = System.currentTimeMillis();\n        buffer = ByteBuffer.allocate(400);\n        for (int i = 0; i < 100000; i++) {\n            for (int j = 0; j < 100; j++) {\n                buffer.putInt(j);\n            }\n            buffer.flip();\n            for (byte j = 0; j < 100; j++) {\n                buffer.getInt();\n            }\n            buffer.clear();\n        }\n        System.out.println(\"Heap读写耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n\n    /**\n     * 测试DirectMemory和Heap内存申请速度。\n     */\n    @Test\n    public void testDirectMemoryAllocate() {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 100000; i++) {\n            ByteBuffer buffer = ByteBuffer.allocateDirect(400);\n\n        }\n        System.out.println(\"DirectMemory申请内存耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n        tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 100000; i++) {\n            ByteBuffer buffer = ByteBuffer.allocate(400);\n        }\n        System.out.println(\"Heap申请内存耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n```\n执行这段代码，得到的结果如下：\n![代码执行结果](http://img.blog.csdn.net/20150527134843409)\n\n## 结论\n从上面的实验结果可以看出，直接内存在读和写的性能都优于堆内内存，但是内存申请速度却不如堆内内存，所以可以归纳一下： **直接内存适用于不常申请，但是需要频繁读取的场景，在需要频繁申请的场景下不应该使用直接内存(DirectMemory)，而应该使用堆内内存(HeapMemory)。**\n","source":"_posts/[Java]直接内存和堆内存的性能比较.md","raw":"title: \"[Java]直接内存和堆内存的性能比较\"\ndate: 2015-08-01 03:39:32\ntags: [Java]\ncategories: [Java]\n---\n## 背景知识\n>在JDK 1.4中新加入了NIO（New Input/Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。**这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。**\n显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，则肯定还是会受到本机总内存（包括RAM及SWAP区或者分页文件）的大小及处理器寻址空间的限制。服务器管理员配置虚拟机参数时，一般会根据实际内存设置-Xmx等参数信息，但经常会忽略掉直接内存，使得各个内存区域的总和大于物理内存限制（包括物理上的和操作系统级的限制），从而导致动态扩展时出现OutOfMemoryError异常。\n<!--more-->\n上面这段话引用自[该文章](http://book.51cto.com/art/201107/278886.htm)\n\n## 代码实验\n注意到上面这段话中的黑体字：这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据，然而这个“一些场景”具体指什么呢？我们通过代码做个实验看看。\n    \n```\npackage com.winwill.jvm;\n\nimport org.junit.Test;\n\nimport java.nio.ByteBuffer;\n\n/**\n * @author qifuguang\n * @date 15-5-26 下午8:23\n */\npublic class TestDirectMemory {\n    /**\n     * 测试DirectMemory和Heap读写速度。\n     */\n    @Test\n    public void testDirectMemoryWriteAndReadSpeed() {\n        long tsStart = System.currentTimeMillis();\n        ByteBuffer buffer = ByteBuffer.allocateDirect(400);\n        for (int i = 0; i < 100000; i++) {\n            for (int j = 0; j < 100; j++) {\n                buffer.putInt(j);\n            }\n            buffer.flip();\n            for (byte j = 0; j < 100; j++) {\n                buffer.getInt();\n            }\n            buffer.clear();\n        }\n        System.out.println(\"DirectMemory读写耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n        tsStart = System.currentTimeMillis();\n        buffer = ByteBuffer.allocate(400);\n        for (int i = 0; i < 100000; i++) {\n            for (int j = 0; j < 100; j++) {\n                buffer.putInt(j);\n            }\n            buffer.flip();\n            for (byte j = 0; j < 100; j++) {\n                buffer.getInt();\n            }\n            buffer.clear();\n        }\n        System.out.println(\"Heap读写耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n\n    /**\n     * 测试DirectMemory和Heap内存申请速度。\n     */\n    @Test\n    public void testDirectMemoryAllocate() {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 100000; i++) {\n            ByteBuffer buffer = ByteBuffer.allocateDirect(400);\n\n        }\n        System.out.println(\"DirectMemory申请内存耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n        tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 100000; i++) {\n            ByteBuffer buffer = ByteBuffer.allocate(400);\n        }\n        System.out.println(\"Heap申请内存耗用： \" + (System.currentTimeMillis() - tsStart) + \" ms\");\n    }\n}\n```\n执行这段代码，得到的结果如下：\n![代码执行结果](http://img.blog.csdn.net/20150527134843409)\n\n## 结论\n从上面的实验结果可以看出，直接内存在读和写的性能都优于堆内内存，但是内存申请速度却不如堆内内存，所以可以归纳一下： **直接内存适用于不常申请，但是需要频繁读取的场景，在需要频繁申请的场景下不应该使用直接内存(DirectMemory)，而应该使用堆内内存(HeapMemory)。**\n","slug":"[Java]直接内存和堆内存的性能比较","published":1,"updated":"2015-08-21T08:20:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovb3002jlo6bq433xm1n"},{"title":"[Java]常用虚拟机参数","date":"2015-07-31T19:38:29.000Z","_content":"* -XX:+PrintGC   启动java虚拟机后，只要遇到gc，就打印日志。\n* -XX:+PrintGCDetails  gc发生时，打印更详细的日志。\n* -XX:+PrintHeapAtGC  gc发生时，打印更详细的堆信息。\n<!--more-->\n* -XX:+PrintGCTimeStamps gc发生时，额外打印gc时间，该时间为虚拟机启动到现在的时间偏移量。\n* -XX:+PrintGCApplicationConcurrentTime gc时打印应用程序执行的时间。\n* -XX:+PrintGCApplicationStoppedTime gc时打印应用程序由于gc产生停顿的时间。\n* -XX:+PrintReferenceGC  跟踪系统内的软引用，若引用，虚引用和Finallize队列。\n* -Xloggc 指定gc日志的保存路径。\n* -XX:+TraceClassLoading  跟踪类加载。\n* -XX:+TraceClassUnloading 跟踪类卸载。\n* -XX:+PrintVMOptions 程序运行时，打印虚拟机接收到的命令行显示参数。\n* -XX:+PrintCommandLineFlags 打印传递给虚拟机的显式和隐式参数。\n* -XX:+PrintFlagsFinal 打印所有系统参数的值。\n* -Xms 指定初始堆空间的大小，例如-Xms20m\n* -Xmx 指定最大堆空间的大小，例如-Xmx100m\n* -Xmn 指定新生代的大小，例如-Xmn1m\n* -XX:MaxHeapSize 指定最大内存。\n* -XX:SurvivorRatio 指定新生代中eden区和from/to区的比例关系。\n* -XX:NewRatio 设置新生代和老生带的比例，注意：这个值的含义是 老生带/新生代。\n* -XX:+HeapDumpOnOutOfMemoryError 内存溢出时，导出整个堆的信息，和下一个参数配合使用。\n* -XX:HeapDumpPath 导出的堆信息的保存路径，和上一个参数配合使用。\n* -XX:OnOutOfMemoryError 内存溢出发生错误时执行一个脚本文件。\n* -XX:PermSize 配置初始永久区的大小(JDK8中永久区已经被彻底移除，使用了新的元数据区存放类的元数据)。\n* -XX:MaxPermSize 配置最大永久区的大小(JDK8中永久区已经被彻底移除，使用了新的元数据区存放类的元数据)。\n* -XX:MaxMetaspaceSize 指定永久区最大可用值。\n* -Xss 指定线程的栈大小。\n* -XX:MaxDirectMemorySize 指定最大可用直接内存值。\n* -server 指定虚拟机在server模式下工作。\n* -client 指定虚拟机在client模式下工作。\n","source":"_posts/[Java]常用虚拟机参数.md","raw":"title: \"[Java]常用虚拟机参数\"\ndate: 2015-08-01 03:38:29\ntags: [Java]\ncategories: [Java]\n---\n* -XX:+PrintGC   启动java虚拟机后，只要遇到gc，就打印日志。\n* -XX:+PrintGCDetails  gc发生时，打印更详细的日志。\n* -XX:+PrintHeapAtGC  gc发生时，打印更详细的堆信息。\n<!--more-->\n* -XX:+PrintGCTimeStamps gc发生时，额外打印gc时间，该时间为虚拟机启动到现在的时间偏移量。\n* -XX:+PrintGCApplicationConcurrentTime gc时打印应用程序执行的时间。\n* -XX:+PrintGCApplicationStoppedTime gc时打印应用程序由于gc产生停顿的时间。\n* -XX:+PrintReferenceGC  跟踪系统内的软引用，若引用，虚引用和Finallize队列。\n* -Xloggc 指定gc日志的保存路径。\n* -XX:+TraceClassLoading  跟踪类加载。\n* -XX:+TraceClassUnloading 跟踪类卸载。\n* -XX:+PrintVMOptions 程序运行时，打印虚拟机接收到的命令行显示参数。\n* -XX:+PrintCommandLineFlags 打印传递给虚拟机的显式和隐式参数。\n* -XX:+PrintFlagsFinal 打印所有系统参数的值。\n* -Xms 指定初始堆空间的大小，例如-Xms20m\n* -Xmx 指定最大堆空间的大小，例如-Xmx100m\n* -Xmn 指定新生代的大小，例如-Xmn1m\n* -XX:MaxHeapSize 指定最大内存。\n* -XX:SurvivorRatio 指定新生代中eden区和from/to区的比例关系。\n* -XX:NewRatio 设置新生代和老生带的比例，注意：这个值的含义是 老生带/新生代。\n* -XX:+HeapDumpOnOutOfMemoryError 内存溢出时，导出整个堆的信息，和下一个参数配合使用。\n* -XX:HeapDumpPath 导出的堆信息的保存路径，和上一个参数配合使用。\n* -XX:OnOutOfMemoryError 内存溢出发生错误时执行一个脚本文件。\n* -XX:PermSize 配置初始永久区的大小(JDK8中永久区已经被彻底移除，使用了新的元数据区存放类的元数据)。\n* -XX:MaxPermSize 配置最大永久区的大小(JDK8中永久区已经被彻底移除，使用了新的元数据区存放类的元数据)。\n* -XX:MaxMetaspaceSize 指定永久区最大可用值。\n* -Xss 指定线程的栈大小。\n* -XX:MaxDirectMemorySize 指定最大可用直接内存值。\n* -server 指定虚拟机在server模式下工作。\n* -client 指定虚拟机在client模式下工作。\n","slug":"[Java]常用虚拟机参数","published":1,"updated":"2015-08-21T08:16:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovb5002mlo6bukl0v2xj"},{"title":"[Java]垃圾回收算法概述","date":"2015-08-01T00:58:57.000Z","_content":"* **引用计数**：一个对象被引用计数器加一，取消引用计数器减一，引用计数器为0才能被回收。优点：简单。缺点：不能解决循环引用的问题，比如A引用B，B引用A，但是这两个对象没有被其他任何对象引用，属于垃圾对象，却不能回收；每次引用都会附件一个加减法，影响性能。\n<!--more-->\n* **标记清除法**：分为两个阶段：标记阶段和清除阶段。标记阶段通过根节点标记所有可达对象，清除阶段清除所有不可达对象。缺点：因为清除不可达对象之后剩余的内存不连续，会产生大量内存碎片，不利于大对象的分配。\n* **复制算法**：将内存空间分成相同的两块，每次只是用其中的一块，垃圾回收时，将正在使用的内存中的存活对象复制到另外一块空间，然后清除正在使用的内存空间中的所有对象，这种回收算法适用于新生代垃圾回收。优点：垃圾回收对象比较多时需要复制的对象恨少，性能较好；不会存在内存碎片。缺点：将系统内存折半。\n* **标记压缩算法**：是一种老年代回收算法，在标记清除的基础上做了一些优化，首先从根节点开始标记所有不可达的对象，然后将所有可达的对象移动到内存的一端，最后清除所有不可达的对象。优点：不用将内存分为两块；不会产生内存碎片。\n* **分代算法**：新生代使用复制算法，老生带使用标记清除算法或者标记压缩算法。几乎所有的垃圾回收期都区分新生代和老生带。\n* **分区算法**：将整个堆空间分成很多个连续的不同的小空间，每个小空间独立使用，独立回收。为了更好的控制gc停顿时间，可以根据目标停顿时间合理地回收若干个小区间，而不是整个堆空间，从而减少gc停顿时间。\n","source":"_posts/[Java]垃圾回收算法概述.md","raw":"title: \"[Java]垃圾回收算法概述\"\ndate: 2015-08-01 08:58:57\ntags: [Java]\ncategories: [Java]\n---\n* **引用计数**：一个对象被引用计数器加一，取消引用计数器减一，引用计数器为0才能被回收。优点：简单。缺点：不能解决循环引用的问题，比如A引用B，B引用A，但是这两个对象没有被其他任何对象引用，属于垃圾对象，却不能回收；每次引用都会附件一个加减法，影响性能。\n<!--more-->\n* **标记清除法**：分为两个阶段：标记阶段和清除阶段。标记阶段通过根节点标记所有可达对象，清除阶段清除所有不可达对象。缺点：因为清除不可达对象之后剩余的内存不连续，会产生大量内存碎片，不利于大对象的分配。\n* **复制算法**：将内存空间分成相同的两块，每次只是用其中的一块，垃圾回收时，将正在使用的内存中的存活对象复制到另外一块空间，然后清除正在使用的内存空间中的所有对象，这种回收算法适用于新生代垃圾回收。优点：垃圾回收对象比较多时需要复制的对象恨少，性能较好；不会存在内存碎片。缺点：将系统内存折半。\n* **标记压缩算法**：是一种老年代回收算法，在标记清除的基础上做了一些优化，首先从根节点开始标记所有不可达的对象，然后将所有可达的对象移动到内存的一端，最后清除所有不可达的对象。优点：不用将内存分为两块；不会产生内存碎片。\n* **分代算法**：新生代使用复制算法，老生带使用标记清除算法或者标记压缩算法。几乎所有的垃圾回收期都区分新生代和老生带。\n* **分区算法**：将整个堆空间分成很多个连续的不同的小空间，每个小空间独立使用，独立回收。为了更好的控制gc停顿时间，可以根据目标停顿时间合理地回收若干个小区间，而不是整个堆空间，从而减少gc停顿时间。\n","slug":"[Java]垃圾回收算法概述","published":1,"updated":"2015-08-21T08:20:20.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovb7002plo6baq7cetj2"},{"title":"[Java]四种引用类型","date":"2015-08-01T01:06:40.000Z","_content":"### 强引用\n一般程序中通过new创建的对象的引用都是强引用，强引用只有在从根节点不可达的情况下才会被垃圾回收器回收，所以可能产生内存溢出。\n<!--more-->\n### 软引用\n使用SoftReference创建，弱于强引用，在内存紧张的时候会被回收，不会产生内存溢出。\n\n### 弱引用\n使用WeakReference创建，弱于软引用，在系统gc时只要发现弱引用直接回收，不会产生内存溢出。\n\n### 虚引用\n使用PhantomReference创建，最弱的引用类型，随时都可以被垃圾回收器回收，配合引用队列使用可以跟踪对象的回收，因此可以将一些资源的释放放在虚引用中执行和记录。\n\n### 代码示例\n```\npackage com.winwill.reference;\n\nimport org.junit.Test;\n\nimport java.lang.ref.PhantomReference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\nimport java.lang.ref.WeakReference;\n\n/**\n * @author qifuguang\n * @date 15-5-27 下午4:45\n */\npublic class TestReference {\n    public static class User {\n        private String name;\n        private int id;\n\n        public User(String name, int id) {\n            this.name = name;\n            this.id = id;\n        }\n\n        @Override\n        public String toString() {\n            return id + \":\" + name;\n        }\n    }\n\n    @Test\n    public void testReference() throws Exception {\n        /** 创建强引用对象*/\n        User u = new User(\"winwill\", 1);\n\n        /**使用强引用对象创建软引用对象*/\n        SoftReference<User> userSoftReference = new SoftReference<User>(u);\n        /**使用强引用对象创建弱引用对象*/\n        WeakReference<User> userWeakReference = new WeakReference<User>(u);\n\n        /**使用强引用对象创建虚引用对象*/\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<User>();\n        PhantomReference<User> userPhantomReference = new PhantomReference<User>(u, referenceQueue);\n        /**删除强引用*/\n        u = null;\n\n        /**通过软引用获取*/\n        System.out.println(userSoftReference.get());\n        /**通过虚引用获取*/\n        System.out.println(userWeakReference.get());\n        /**通过虚引用获取*/\n        System.out.println(userPhantomReference.get());\n    }\n}\n```\n代码输出结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150527172210655)\n\n可以看到，**无法使用虚引用获取它引用的对象**，再者，虚引用配合引用队列可以跟踪对象的回收时间，因此，可以将一些资源的释放操作放置在虚引用中执行和记录.\n","source":"_posts/[Java]四种引用类型.md","raw":"title: \"[Java]四种引用类型\"\ndate: 2015-08-01 09:06:40\ntags: [Java]\ncategories: [Java]\n---\n### 强引用\n一般程序中通过new创建的对象的引用都是强引用，强引用只有在从根节点不可达的情况下才会被垃圾回收器回收，所以可能产生内存溢出。\n<!--more-->\n### 软引用\n使用SoftReference创建，弱于强引用，在内存紧张的时候会被回收，不会产生内存溢出。\n\n### 弱引用\n使用WeakReference创建，弱于软引用，在系统gc时只要发现弱引用直接回收，不会产生内存溢出。\n\n### 虚引用\n使用PhantomReference创建，最弱的引用类型，随时都可以被垃圾回收器回收，配合引用队列使用可以跟踪对象的回收，因此可以将一些资源的释放放在虚引用中执行和记录。\n\n### 代码示例\n```\npackage com.winwill.reference;\n\nimport org.junit.Test;\n\nimport java.lang.ref.PhantomReference;\nimport java.lang.ref.ReferenceQueue;\nimport java.lang.ref.SoftReference;\nimport java.lang.ref.WeakReference;\n\n/**\n * @author qifuguang\n * @date 15-5-27 下午4:45\n */\npublic class TestReference {\n    public static class User {\n        private String name;\n        private int id;\n\n        public User(String name, int id) {\n            this.name = name;\n            this.id = id;\n        }\n\n        @Override\n        public String toString() {\n            return id + \":\" + name;\n        }\n    }\n\n    @Test\n    public void testReference() throws Exception {\n        /** 创建强引用对象*/\n        User u = new User(\"winwill\", 1);\n\n        /**使用强引用对象创建软引用对象*/\n        SoftReference<User> userSoftReference = new SoftReference<User>(u);\n        /**使用强引用对象创建弱引用对象*/\n        WeakReference<User> userWeakReference = new WeakReference<User>(u);\n\n        /**使用强引用对象创建虚引用对象*/\n        ReferenceQueue<User> referenceQueue = new ReferenceQueue<User>();\n        PhantomReference<User> userPhantomReference = new PhantomReference<User>(u, referenceQueue);\n        /**删除强引用*/\n        u = null;\n\n        /**通过软引用获取*/\n        System.out.println(userSoftReference.get());\n        /**通过虚引用获取*/\n        System.out.println(userWeakReference.get());\n        /**通过虚引用获取*/\n        System.out.println(userPhantomReference.get());\n    }\n}\n```\n代码输出结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150527172210655)\n\n可以看到，**无法使用虚引用获取它引用的对象**，再者，虚引用配合引用队列可以跟踪对象的回收时间，因此，可以将一些资源的释放操作放置在虚引用中执行和记录.\n","slug":"[Java]四种引用类型","published":1,"updated":"2015-08-21T08:17:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovb8002slo6bcb1epbea"},{"title":"[Java]初探Java虚拟机","date":"2015-07-31T19:36:01.000Z","_content":"* java 7开始，数字之间可以使用下划线分隔，增加可读性\n* char在java中占2字节，在C中占1字节\n<!--more-->\n* 数字在计算机中使用补码表示，正数的补码为原码，负数的补码为反码+1\n","source":"_posts/[Java]初探Java虚拟机.md","raw":"title: \"[Java]初探Java虚拟机\"\ndate: 2015-08-01 03:36:01\ntags: [Java]\ncategories: [Java]\n---\n* java 7开始，数字之间可以使用下划线分隔，增加可读性\n* char在java中占2字节，在C中占1字节\n<!--more-->\n* 数字在计算机中使用补码表示，正数的补码为原码，负数的补码为反码+1\n","slug":"[Java]初探Java虚拟机","published":1,"updated":"2015-08-21T08:19:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbb002vlo6b6g7z5wkc"},{"title":"[Java]finalize-方法对垃圾回收的影响","date":"2015-08-01T01:08:10.000Z","_content":"### 概述\n>Java中提供了一个类似C++析构函数的机制: finalize()方法，该函数允许子类重载，用于在对象被回收是释放资源。\n\n但是一般情况下，尽量不要使用finalize函数进行资源的释放，原因主要有一下几点:\n<!--more-->\n* finalize函数调用时，有可能导致对象复活。\n* finalize函数执行的时间没有保障，他完全由GC线程决定，正常情况下，若不发生gc，则finalize一直都没有机会被执行。\n* 一个糟糕的finalize函数会严重影响gc的性能。\n\n### 实验\n下面通过一个实验来看看：\n\n```\npackage com.winwill.jvm;\n\n/**\n * @author qifuguang\n * @date 15-5-29 下午8:24\n */\npublic class TestFinalizer {\n    public static class LY {\n        private byte[] content = new byte[512];\n\n        @Override\n        protected void finalize() {\n            try {\n                System.out.println(\"回收线程:\" + Thread.currentThread().getId());\n                Thread.sleep(1000);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 50000; i++) {\n            LY ly = new LY();\n        }\n        System.out.println(\"耗时:\" + (System.currentTimeMillis() - tsStart));\n    }\n}\n```\n上面这个例子创建了一个内部类TestFinalizer$LY，这个类有一个成员变量，只占用512字节，还重载了finalize函数，其中的sleep操作模拟一个比较耗时的动作。然后主函数中通过一个循环不断地创建LY对象，因为循环中创建的对象没有被其他对象引用，所以创建之后就应该被回收。\n\n### 实验结果\n我们使用如下参数运行该程序：\n>-Xmx10m  -Xms10m  -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/qifuguang/dump.bin\n\n也就是将虚拟机的初始和最大堆内存都设置为10m，并且如果发生OOM，则将内存信息dump出来。按照前文所说，每个对象创建之后都应该立马被回收，所以10m空间创建这么多对象应该是没有问题的，只不过会多发生几次gc而已，但是运行的结果却是这样的：\n>回收线程:3\njava.lang.OutOfMemoryError: Java heap space\nDumping heap to /home/qifuguang/dump.bin ...\nHeap dump file created [11569716 bytes in 0.046 secs]\nException in thread \"main\" \nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n\n发生了内存溢出！！！\n\n### 结果分析\n为什么会出现上面的结果呢？我们找到dump出来的文件，然后使用eclipse的MAT插件打开这个文件之后可以看到内存中存在大量的java.lang.ref.Finalizer对象。\n![这里写图片描述](http://img.blog.csdn.net/20150529205328228)\n\n这会是什么原因呢？原来finalize函数是由FinalizerThread线程处理的，每一个即将回收的并且包含finalize函数的对象都会在正式回收前加入FinalizerThread的执行队列，该队列为java.lang.ref.ReferenceQueue引用队列，内部实现为链表结构，队列中的每一项为java.lang.ref.Finalizer引用对象，它本质为一个引用，在该例中这些引用就指向了LF对象。由于LF对象被加入了引用队列，并且被“强引用”，所以就阻止了对象的正常回收，并且引用队列中的对象排队执行finalize函数，处理得比较慢，回收速度比不上创建对象的速度，所以就出现了OOM(Out Of Memory)错误。\n\n### 结论\n但是话又说回来了，虽然finalize函数不推荐使用，但是在某些场合，使用finalize函数可以起到双保险为作用，比如在Mysql的JDBC驱动中，com.mysql.jdbc.ConnectionImpl就实现了finalize函数，在函数中执行了连接的关闭操作，这样如果开发人员开发过程中忘记关闭不需要的连接，在对象回收时也会被强制关闭，确保数据库没有连接泄露。\n\n","source":"_posts/[Java]finalize-方法对垃圾回收的影响.md","raw":"title: \"[Java]finalize-方法对垃圾回收的影响\"\ndate: 2015-08-01 09:08:10\ntags: [Java]\ncategories: [Java]\n---\n### 概述\n>Java中提供了一个类似C++析构函数的机制: finalize()方法，该函数允许子类重载，用于在对象被回收是释放资源。\n\n但是一般情况下，尽量不要使用finalize函数进行资源的释放，原因主要有一下几点:\n<!--more-->\n* finalize函数调用时，有可能导致对象复活。\n* finalize函数执行的时间没有保障，他完全由GC线程决定，正常情况下，若不发生gc，则finalize一直都没有机会被执行。\n* 一个糟糕的finalize函数会严重影响gc的性能。\n\n### 实验\n下面通过一个实验来看看：\n\n```\npackage com.winwill.jvm;\n\n/**\n * @author qifuguang\n * @date 15-5-29 下午8:24\n */\npublic class TestFinalizer {\n    public static class LY {\n        private byte[] content = new byte[512];\n\n        @Override\n        protected void finalize() {\n            try {\n                System.out.println(\"回收线程:\" + Thread.currentThread().getId());\n                Thread.sleep(1000);\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        long tsStart = System.currentTimeMillis();\n        for (int i = 0; i < 50000; i++) {\n            LY ly = new LY();\n        }\n        System.out.println(\"耗时:\" + (System.currentTimeMillis() - tsStart));\n    }\n}\n```\n上面这个例子创建了一个内部类TestFinalizer$LY，这个类有一个成员变量，只占用512字节，还重载了finalize函数，其中的sleep操作模拟一个比较耗时的动作。然后主函数中通过一个循环不断地创建LY对象，因为循环中创建的对象没有被其他对象引用，所以创建之后就应该被回收。\n\n### 实验结果\n我们使用如下参数运行该程序：\n>-Xmx10m  -Xms10m  -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/qifuguang/dump.bin\n\n也就是将虚拟机的初始和最大堆内存都设置为10m，并且如果发生OOM，则将内存信息dump出来。按照前文所说，每个对象创建之后都应该立马被回收，所以10m空间创建这么多对象应该是没有问题的，只不过会多发生几次gc而已，但是运行的结果却是这样的：\n>回收线程:3\njava.lang.OutOfMemoryError: Java heap space\nDumping heap to /home/qifuguang/dump.bin ...\nHeap dump file created [11569716 bytes in 0.046 secs]\nException in thread \"main\" \nException: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread \"main\"\n\n发生了内存溢出！！！\n\n### 结果分析\n为什么会出现上面的结果呢？我们找到dump出来的文件，然后使用eclipse的MAT插件打开这个文件之后可以看到内存中存在大量的java.lang.ref.Finalizer对象。\n![这里写图片描述](http://img.blog.csdn.net/20150529205328228)\n\n这会是什么原因呢？原来finalize函数是由FinalizerThread线程处理的，每一个即将回收的并且包含finalize函数的对象都会在正式回收前加入FinalizerThread的执行队列，该队列为java.lang.ref.ReferenceQueue引用队列，内部实现为链表结构，队列中的每一项为java.lang.ref.Finalizer引用对象，它本质为一个引用，在该例中这些引用就指向了LF对象。由于LF对象被加入了引用队列，并且被“强引用”，所以就阻止了对象的正常回收，并且引用队列中的对象排队执行finalize函数，处理得比较慢，回收速度比不上创建对象的速度，所以就出现了OOM(Out Of Memory)错误。\n\n### 结论\n但是话又说回来了，虽然finalize函数不推荐使用，但是在某些场合，使用finalize函数可以起到双保险为作用，比如在Mysql的JDBC驱动中，com.mysql.jdbc.ConnectionImpl就实现了finalize函数，在函数中执行了连接的关闭操作，这样如果开发人员开发过程中忘记关闭不需要的连接，在对象回收时也会被强制关闭，确保数据库没有连接泄露。\n\n","slug":"[Java]finalize-方法对垃圾回收的影响","published":1,"updated":"2015-08-21T08:18:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbd002ylo6bvhccls77"},{"title":"[Java]ToStringBuilder介绍","date":"2015-07-31T19:33:39.000Z","_content":"### ToStringBuilder简单介绍\nToStringBuilder是用于构建一个类的toString字符串的工具类，提供了多种不同的格式，同时还能自定义打印哪些变量。\n\n### ToStringBuilder主要方法\n\n* append()方法： 该方法用于自定义添加需要打印哪些变量，只有使用append添加的变量才会在toString函数中打印。\n* reflectionToString()方法： 该方法使用反射机制打印一个类中的所有变量，该函数还提供一个变量style，用于指定使用什么样的格式打印变量，几种不的style将在下面介绍。\n<!--more-->\n### 使用示例\n下面的代码使用了ToStringBuilder的append方法将index变量添加进去\n\n```\npackage com.xiaomi.test;\n\nimport org.apache.commons.lang.builder.ToStringBuilder;\n\n/**\n * @author qifuguang\n * @date 15/5/10 22:39\n */\npublic class Subject {\n    private int index;\n    private String name;\n\n    public Subject(int index, String name) {\n        this.index = index;\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return new ToStringBuilder(this).append(\"index\", index).toString();\n    }\n\n    public static void main(String[] args) {\n        System.out.println(new Subject(1, \"subject1\").toString());\n    }\n}\n```\n\n运行结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230514295)\n可以看到toString仅仅打印了index，但是并没有打印name，所以只有append添加的变量才会被打印。\n\n下面的代码使用了ToStringBuilder的静态方法reflectionToString打印\n\n```\npackage com.xiaomi.test;\n\nimport org.apache.commons.lang.builder.ToStringBuilder;\n\n/**\n * @author qifuguang\n * @date 15/5/10 22:39\n */\npublic class Subject {\n    private int index;\n    private String name;\n\n    public Subject(int index, String name) {\n        this.index = index;\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return ToStringBuilder.reflectionToString(this, ToStringStyle.DEFAULT_STYLE);\n    }\n\n    public static void main(String[] args) {\n        System.out.println(new Subject(1, \"subject1\").toString());\n    }\n}\n\n```\n运行结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230428412)\n由此可见reflectionToString这个函数默认打印所有变量，上面的示例使用的是默认的style，也就是ToStringStyle.DEFAULT_STYLE；\n如果将style换成ToStringStyle.NO_FIELD_NAMES_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230651452)\n可以看到并没有打印变量的名字，仅仅打印了变量的值；\n如果换成ToStringStyle.MULTI_LINE_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230607254)\n可以看到每个变量打印一行；\n如果换成ToStringStyle.SHORT_PREFIX_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230839248)\n可以看到类前面没有了包名；\n如果换成ToStringStyle.SIMPLE_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230738499)\n可以看到，这次直接没有了类名，直接只一次打印了变量的值。\n\n### 结语\n在自定义类的时候往往需要重写toString方法，ToStringBuilder工具类提供了很好支持，如果能够使用该类重写toString，那想必是极好的了。\n","source":"_posts/[Java]ToStringBuilder介绍.md","raw":"title: \"[Java]ToStringBuilder介绍\"\ndate: 2015-08-01 03:33:39\ntags: [Java]\ncategories: [Java]\n---\n### ToStringBuilder简单介绍\nToStringBuilder是用于构建一个类的toString字符串的工具类，提供了多种不同的格式，同时还能自定义打印哪些变量。\n\n### ToStringBuilder主要方法\n\n* append()方法： 该方法用于自定义添加需要打印哪些变量，只有使用append添加的变量才会在toString函数中打印。\n* reflectionToString()方法： 该方法使用反射机制打印一个类中的所有变量，该函数还提供一个变量style，用于指定使用什么样的格式打印变量，几种不的style将在下面介绍。\n<!--more-->\n### 使用示例\n下面的代码使用了ToStringBuilder的append方法将index变量添加进去\n\n```\npackage com.xiaomi.test;\n\nimport org.apache.commons.lang.builder.ToStringBuilder;\n\n/**\n * @author qifuguang\n * @date 15/5/10 22:39\n */\npublic class Subject {\n    private int index;\n    private String name;\n\n    public Subject(int index, String name) {\n        this.index = index;\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return new ToStringBuilder(this).append(\"index\", index).toString();\n    }\n\n    public static void main(String[] args) {\n        System.out.println(new Subject(1, \"subject1\").toString());\n    }\n}\n```\n\n运行结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230514295)\n可以看到toString仅仅打印了index，但是并没有打印name，所以只有append添加的变量才会被打印。\n\n下面的代码使用了ToStringBuilder的静态方法reflectionToString打印\n\n```\npackage com.xiaomi.test;\n\nimport org.apache.commons.lang.builder.ToStringBuilder;\n\n/**\n * @author qifuguang\n * @date 15/5/10 22:39\n */\npublic class Subject {\n    private int index;\n    private String name;\n\n    public Subject(int index, String name) {\n        this.index = index;\n        this.name = name;\n    }\n\n    @Override\n    public String toString() {\n        return ToStringBuilder.reflectionToString(this, ToStringStyle.DEFAULT_STYLE);\n    }\n\n    public static void main(String[] args) {\n        System.out.println(new Subject(1, \"subject1\").toString());\n    }\n}\n\n```\n运行结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230428412)\n由此可见reflectionToString这个函数默认打印所有变量，上面的示例使用的是默认的style，也就是ToStringStyle.DEFAULT_STYLE；\n如果将style换成ToStringStyle.NO_FIELD_NAMES_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230651452)\n可以看到并没有打印变量的名字，仅仅打印了变量的值；\n如果换成ToStringStyle.MULTI_LINE_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230607254)\n可以看到每个变量打印一行；\n如果换成ToStringStyle.SHORT_PREFIX_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230839248)\n可以看到类前面没有了包名；\n如果换成ToStringStyle.SIMPLE_STYLE，则打印结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150510230738499)\n可以看到，这次直接没有了类名，直接只一次打印了变量的值。\n\n### 结语\n在自定义类的时候往往需要重写toString方法，ToStringBuilder工具类提供了很好支持，如果能够使用该类重写toString，那想必是极好的了。\n","slug":"[Java]ToStringBuilder介绍","published":1,"updated":"2015-08-21T08:18:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbf0031lo6bnsb9k8ur"},{"title":"[JDK工具学习四]jmap命令使用","date":"2015-08-01T01:34:05.000Z","_content":"## 概述\njmap是一个多功能的命令。它可以生成java程序的堆dump文件，也可以查看堆内对象实例的统计信息，查看ClassLoader的信息以及Finalizer队列。\n<!--more-->\n## 使用示例\n### 导出对象统计信息\n下面的命令生成PID为2500的java成粗的对象的统计信息，并输出到out.txt文件中：\n```\n[qifuguang@winwill~]$ jmap -histo 2500 > out.txt\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n```\n生成的文件如下：\n![这里写图片描述](http://img.blog.csdn.net/20150602231204933)\n从文件中可以看到，统计信息显示了内存中实例的数量和合计。\n\n### 导出程序堆快照\n下面的命令导出PID为2500的java程序当前的堆快照：\n```\n[qifuguang@winwill~]$ jmap -dump:format=b,file=dump.bin 2500\nDumping heap to /home/qifuguang/dump.bin ...\nHeap dump file created\n```\n该命令成功地将运用程序的当前的堆快照导出到了dump.bin文件，之后可以使用Visual VM，MAT等工具分析对快照文件。\n\n### 查看Finalizer队列\n下面的命令查看虚拟机Finalizer队列的信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602233132638)\n从图中可以看到，队列中堆积了大量的TestFinalizer$LY对象实例，还有其他一些对象。\n\n### 查看ClassLoader信息\n下面的命令显示了虚拟机当前的ClassLoader信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602233406536)\n从图中可以看到，当前虚拟机一共有3个ClassLoader，bootstrap加载了492个对象，对象总大小为943655byte，同时还显示了各个ClassLoader之间的父子关系。\n","source":"_posts/[JDK工具学习四]jmap命令使用.md","raw":"title: \"[JDK工具学习四]jmap命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:34:05\n---\n## 概述\njmap是一个多功能的命令。它可以生成java程序的堆dump文件，也可以查看堆内对象实例的统计信息，查看ClassLoader的信息以及Finalizer队列。\n<!--more-->\n## 使用示例\n### 导出对象统计信息\n下面的命令生成PID为2500的java成粗的对象的统计信息，并输出到out.txt文件中：\n```\n[qifuguang@winwill~]$ jmap -histo 2500 > out.txt\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n```\n生成的文件如下：\n![这里写图片描述](http://img.blog.csdn.net/20150602231204933)\n从文件中可以看到，统计信息显示了内存中实例的数量和合计。\n\n### 导出程序堆快照\n下面的命令导出PID为2500的java程序当前的堆快照：\n```\n[qifuguang@winwill~]$ jmap -dump:format=b,file=dump.bin 2500\nDumping heap to /home/qifuguang/dump.bin ...\nHeap dump file created\n```\n该命令成功地将运用程序的当前的堆快照导出到了dump.bin文件，之后可以使用Visual VM，MAT等工具分析对快照文件。\n\n### 查看Finalizer队列\n下面的命令查看虚拟机Finalizer队列的信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602233132638)\n从图中可以看到，队列中堆积了大量的TestFinalizer$LY对象实例，还有其他一些对象。\n\n### 查看ClassLoader信息\n下面的命令显示了虚拟机当前的ClassLoader信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602233406536)\n从图中可以看到，当前虚拟机一共有3个ClassLoader，bootstrap加载了492个对象，对象总大小为943655byte，同时还显示了各个ClassLoader之间的父子关系。\n","slug":"[JDK工具学习四]jmap命令使用","published":1,"updated":"2015-08-30T12:00:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbj0034lo6bpe4uuk20"},{"title":"[JDK工具学习六]jstack命令使用","date":"2015-08-01T01:36:05.000Z","_content":"## 概述\njstack可用于导出java运用程序的线程堆栈，其基本使用语法为：\n> jstack [-l] pid\n\n-l 选项用于打印锁的额外信息。\n<!--more-->\n## 使用示例\n下面这段代码运行之后会出现死锁现象(因为线程1持有lock1，在等待lock2，线程2持有lock2在等待lock1，造成了循环等待，形成死锁)：\n```\npackage com.winwill.deadlock;\n\n/**\n * @author qifuguang\n * @date 15/6/4 16:45\n */\npublic class TestDeadLock {\n    private static final Object lock1 = new Object();\n    private static final Object lock2 = new Object();\n\n    public static void main(String[] args) {\n\n        Thread t1 = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                synchronized (lock1) {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                    synchronized (lock2) {\n                        System.out.println(\"线程1执行....\");\n                    }\n                }\n            }\n        });\n\n        Thread t2 = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                synchronized (lock2) {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                    synchronized (lock1) {\n                        System.out.println(\"线程2执行...\");\n                    }\n                }\n            }\n        });\n\n        t1.start();\n        t2.start();\n    }\n}\n```\n\n我们运行这段代码，然后使用jstack命令导出这个程序的线程堆栈信息：\n>[qifuguang@Mac~]$ jstack -l 21023 > /tmp/deadlock.txt\n\n打开导出的线程堆栈信息文件，文件末尾如下所示：\n\n![这里写图片描述](http://img.blog.csdn.net/20150604165946198)\n\n如图所示，导出的线程堆栈文件中明确提示发现死锁，并且指明了死锁的原因。\n\n## 总结\njstack不仅能够导出线程堆栈，还能自动进行死锁检测，输出线程死锁原因。\n\n","source":"_posts/[JDK工具学习六]jstack命令使用.md","raw":"title: \"[JDK工具学习六]jstack命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:36:05\n---\n## 概述\njstack可用于导出java运用程序的线程堆栈，其基本使用语法为：\n> jstack [-l] pid\n\n-l 选项用于打印锁的额外信息。\n<!--more-->\n## 使用示例\n下面这段代码运行之后会出现死锁现象(因为线程1持有lock1，在等待lock2，线程2持有lock2在等待lock1，造成了循环等待，形成死锁)：\n```\npackage com.winwill.deadlock;\n\n/**\n * @author qifuguang\n * @date 15/6/4 16:45\n */\npublic class TestDeadLock {\n    private static final Object lock1 = new Object();\n    private static final Object lock2 = new Object();\n\n    public static void main(String[] args) {\n\n        Thread t1 = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                synchronized (lock1) {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                    synchronized (lock2) {\n                        System.out.println(\"线程1执行....\");\n                    }\n                }\n            }\n        });\n\n        Thread t2 = new Thread(new Runnable() {\n            @Override\n            public void run() {\n                synchronized (lock2) {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (Exception e) {\n                        e.printStackTrace();\n                    }\n                    synchronized (lock1) {\n                        System.out.println(\"线程2执行...\");\n                    }\n                }\n            }\n        });\n\n        t1.start();\n        t2.start();\n    }\n}\n```\n\n我们运行这段代码，然后使用jstack命令导出这个程序的线程堆栈信息：\n>[qifuguang@Mac~]$ jstack -l 21023 > /tmp/deadlock.txt\n\n打开导出的线程堆栈信息文件，文件末尾如下所示：\n\n![这里写图片描述](http://img.blog.csdn.net/20150604165946198)\n\n如图所示，导出的线程堆栈文件中明确提示发现死锁，并且指明了死锁的原因。\n\n## 总结\njstack不仅能够导出线程堆栈，还能自动进行死锁检测，输出线程死锁原因。\n\n","slug":"[JDK工具学习六]jstack命令使用","published":1,"updated":"2015-08-21T08:09:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbm0039lo6bh3tr2yyd"},{"title":"[JDK工具学习五]jhat命令使用","date":"2015-08-01T01:35:08.000Z","_content":"## 概述\njhat(Java Head Analyse Tool)是jdk自带的用来分析java堆快照的工具，具体的使用方法是：\n> jhat dump_file_name\n<!--more-->\n## 使用示例\n在此以[前文](http://blog.csdn.net/winwill2012/article/details/46337339)dump出来的文件（dump.bin）为例，演示怎么使用jhat分析堆文件。\n![这里写图片描述](http://img.blog.csdn.net/20150602234741933)\n![这里写图片描述](http://img.blog.csdn.net/20150602234954912)\n\n上图中使用jhat命令打开了之前dump出来的堆快照文件，可以看到，命令成功执行后会在命令执行的本机启动一个http服务，可以在浏览器上打开本机的7000端口查看详细的分析结果：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602235100896)\n\n页面中显示了所有非平台类信息，点击链接进入，可以查看选中的类的超类，ClassLoader以及该类的实例等信息。此外，在页面的地步，jhat还为开发人员提供了其他查询方式。如图所示：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602235508379)\n\n通过这些链接，开发人员可以查看所有类信息（包含java平台的类），所有根节点，finalizer对象等等信息。最后提供了OQL查询工具，开发人员可以输入OQL语言查询相应的类。关于OQL，笔者就不过多介绍，想了解更多的可以点击[这里](http://su1216.iteye.com/blog/1535776)了解。\n","source":"_posts/[JDK工具学习五]jhat命令使用.md","raw":"title: \"[JDK工具学习五]jhat命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:35:08\n---\n## 概述\njhat(Java Head Analyse Tool)是jdk自带的用来分析java堆快照的工具，具体的使用方法是：\n> jhat dump_file_name\n<!--more-->\n## 使用示例\n在此以[前文](http://blog.csdn.net/winwill2012/article/details/46337339)dump出来的文件（dump.bin）为例，演示怎么使用jhat分析堆文件。\n![这里写图片描述](http://img.blog.csdn.net/20150602234741933)\n![这里写图片描述](http://img.blog.csdn.net/20150602234954912)\n\n上图中使用jhat命令打开了之前dump出来的堆快照文件，可以看到，命令成功执行后会在命令执行的本机启动一个http服务，可以在浏览器上打开本机的7000端口查看详细的分析结果：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602235100896)\n\n页面中显示了所有非平台类信息，点击链接进入，可以查看选中的类的超类，ClassLoader以及该类的实例等信息。此外，在页面的地步，jhat还为开发人员提供了其他查询方式。如图所示：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602235508379)\n\n通过这些链接，开发人员可以查看所有类信息（包含java平台的类），所有根节点，finalizer对象等等信息。最后提供了OQL查询工具，开发人员可以输入OQL语言查询相应的类。关于OQL，笔者就不过多介绍，想了解更多的可以点击[这里](http://su1216.iteye.com/blog/1535776)了解。\n","slug":"[JDK工具学习五]jhat命令使用","published":1,"updated":"2015-08-21T08:08:39.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbo003clo6bd4bukn6y"},{"title":"[JDK工具学习二]jstat命令使用","date":"2015-08-01T01:30:55.000Z","_content":"jstat是一个可以用于观察java应用程序运行时相关信息的工具，功能非常强大，可以通过它查看堆信息的详细情况。 \n\n## 基本用法\njstat命令的基本使用语法如下：\n<!--more-->\n**jstat -option [-t] [-h] pid [interval] [count]**\n\n * 选项option可以由以下值构成。\n     * **-class**：显示ClassLoader的相关信息。\n     * **-compiler**：显示JIT编译的相关信息。\n     * **-gc**：显示与gc相关的堆信息。\n     * **-gccapacity**：显示各个代的容量及使用情况。\n     *  **-gccause**：显示垃圾回收的相关信息（同-gcutil），同时显示最后一次或当前正在发生的垃圾回收的诱因。\n     *  **-gcnew**：显示新生代信息。\n     *  **-gcnewcapacity**：显示新生代大小与使用情况。\n     *  **-gcold**：显示老生代和永久代的信息。\n     *  **-gcoldcapacity**：显示老年代的大小。\n     *  **-gcpermcapacity**：显示永久代的大小。\n     *  **-gcutil**：显示垃圾收集信息。\n     *  **-printcompilation**：输出JIT编译的方法信息。  \n * -t参数可以在输出信息前面加上一个Timestamp列，显示程序运行的时间。\n * -h参数可以在周期性的数据输出时，输出多少行数据后，跟着输出一个表头信息。\n * interval参数用于指定输出统计数据的周期，单位为毫秒(ms)。\n * count参数用于指定一共输出多少次数据。\n\n## 详细使用\n### -class使用\n下面命令输出pid为2500这个进程的ClassLoader相关信息，每秒统计一次信息，一共输出两次。\n![这里写图片描述](http://img.blog.csdn.net/20150602003709009)\nLoaded表示载入的类的数量，第一个Bytes表示载入的类的合计大小，Unloaded表示卸载的类数量，第二个Bytes表示卸载的类的合计大小，Time表示加载和卸载类花的总的时间。\n\n### -compiler使用\n下面的命令查看JIT编译的信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602004116925)\n\nCompiled表示编译任务执行的次数，Failed表示编译失败的次数，Invalid表示编译不可用的次数，Time表示编译的总耗时，FailedType表示最后一次编译的类型，FailedMethod表示最后一次编译失败的类名和方法名。\n\n### -gc使用\n下面的命令显示与gc相关的堆信息的输出：\n![这里写图片描述](http://img.blog.csdn.net/20150602004613119)\n\n* S0C：s0(from)的大小(KB)\n* S1C：s1(from)的大小(KB)\n* S0U：s0(from)已使用的空间(KB)\n* S1U：s1(from)已经使用的空间(KB)\n* EC：eden区的大小(KB)\n* EU：eden区已经使用的空间(KB)\n* OC：老年代大小(KB)\n* OU：老年代已经使用的空间(KB)\n* PC：永久区大小(KB)\n* PU：永久区已经使用的空间(KB)\n* YGC：新生代gc次数\n* YGCT：新生代gc耗时\n* FGC：Full gc次数\n* FGCT：Full gc耗时\n* GCT：gc总耗时\n\n### -gccapacity使用\n下面的命令显示了各个代的信息，与-gc相比，它不仅输出了各个代的当前大小，还输出了各个代的最大值与最小值：\n![这里写图片描述](http://img.blog.csdn.net/20150602005310719)\n* NGCMN：新生代最小值(KB)\n* NGCMX：新生代最大值(KB)\n* NGC：当前新生代大小(KB)\n* OGCMN：老年大最小值(KB)\n* OGCMX：老年代最大值(KB)\n* OGC：当前老年代大小(KB)\n* PGCMN：永久代最小值(KB)\n* PGCMX：永久代最大值(KB)\n\n### -gccause使用\n下面命令显示最近一次gc的原因，以及当前gc的原因：\n![这里写图片描述](http://img.blog.csdn.net/20150602005843699)\n\n* LGCC：上次gc的原因，从图中可以看到上次gc的原因是Allocation Failure\n* GCC：当前gc的原因，图中当前没有gc\n\n### -gcnew使用\n下面的命令显示新生代的详细信息:\n![这里写图片描述](http://img.blog.csdn.net/20150602005922047)\n* TT：新生代对象晋升到老年代对象的年龄。\n* MTT：新生代对象晋升到老年代对象的年龄的最大值。\n* DSS：所需的Survivor区的大小。\n\n### -gcnewcapacity使用\n下面的命令详细输出了新生代各个区的大小信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602010141932)\n* S0CMX：s0区的最大值(KB)\n* S1CMX：s1区的最大值(KB)\n* ECMX：eden区的最大值(KB)\n\n### -gcold使用\n下面的命令显示老年代gc概况：\n![这里写图片描述](http://img.blog.csdn.net/20150602010345984)\n\n### -gcoldcapacity使用\n下面的命令用于显示老年代的容量信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602010443688)\n\n### -gcpermcapacity使用\n下面的命令用于显示永久区的使用情况：\n![这里写图片描述](http://img.blog.csdn.net/20150602010716581)\n","source":"_posts/[JDK工具学习二]jstat命令使用.md","raw":"title: \"[JDK工具学习二]jstat命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:30:55\n---\njstat是一个可以用于观察java应用程序运行时相关信息的工具，功能非常强大，可以通过它查看堆信息的详细情况。 \n\n## 基本用法\njstat命令的基本使用语法如下：\n<!--more-->\n**jstat -option [-t] [-h] pid [interval] [count]**\n\n * 选项option可以由以下值构成。\n     * **-class**：显示ClassLoader的相关信息。\n     * **-compiler**：显示JIT编译的相关信息。\n     * **-gc**：显示与gc相关的堆信息。\n     * **-gccapacity**：显示各个代的容量及使用情况。\n     *  **-gccause**：显示垃圾回收的相关信息（同-gcutil），同时显示最后一次或当前正在发生的垃圾回收的诱因。\n     *  **-gcnew**：显示新生代信息。\n     *  **-gcnewcapacity**：显示新生代大小与使用情况。\n     *  **-gcold**：显示老生代和永久代的信息。\n     *  **-gcoldcapacity**：显示老年代的大小。\n     *  **-gcpermcapacity**：显示永久代的大小。\n     *  **-gcutil**：显示垃圾收集信息。\n     *  **-printcompilation**：输出JIT编译的方法信息。  \n * -t参数可以在输出信息前面加上一个Timestamp列，显示程序运行的时间。\n * -h参数可以在周期性的数据输出时，输出多少行数据后，跟着输出一个表头信息。\n * interval参数用于指定输出统计数据的周期，单位为毫秒(ms)。\n * count参数用于指定一共输出多少次数据。\n\n## 详细使用\n### -class使用\n下面命令输出pid为2500这个进程的ClassLoader相关信息，每秒统计一次信息，一共输出两次。\n![这里写图片描述](http://img.blog.csdn.net/20150602003709009)\nLoaded表示载入的类的数量，第一个Bytes表示载入的类的合计大小，Unloaded表示卸载的类数量，第二个Bytes表示卸载的类的合计大小，Time表示加载和卸载类花的总的时间。\n\n### -compiler使用\n下面的命令查看JIT编译的信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602004116925)\n\nCompiled表示编译任务执行的次数，Failed表示编译失败的次数，Invalid表示编译不可用的次数，Time表示编译的总耗时，FailedType表示最后一次编译的类型，FailedMethod表示最后一次编译失败的类名和方法名。\n\n### -gc使用\n下面的命令显示与gc相关的堆信息的输出：\n![这里写图片描述](http://img.blog.csdn.net/20150602004613119)\n\n* S0C：s0(from)的大小(KB)\n* S1C：s1(from)的大小(KB)\n* S0U：s0(from)已使用的空间(KB)\n* S1U：s1(from)已经使用的空间(KB)\n* EC：eden区的大小(KB)\n* EU：eden区已经使用的空间(KB)\n* OC：老年代大小(KB)\n* OU：老年代已经使用的空间(KB)\n* PC：永久区大小(KB)\n* PU：永久区已经使用的空间(KB)\n* YGC：新生代gc次数\n* YGCT：新生代gc耗时\n* FGC：Full gc次数\n* FGCT：Full gc耗时\n* GCT：gc总耗时\n\n### -gccapacity使用\n下面的命令显示了各个代的信息，与-gc相比，它不仅输出了各个代的当前大小，还输出了各个代的最大值与最小值：\n![这里写图片描述](http://img.blog.csdn.net/20150602005310719)\n* NGCMN：新生代最小值(KB)\n* NGCMX：新生代最大值(KB)\n* NGC：当前新生代大小(KB)\n* OGCMN：老年大最小值(KB)\n* OGCMX：老年代最大值(KB)\n* OGC：当前老年代大小(KB)\n* PGCMN：永久代最小值(KB)\n* PGCMX：永久代最大值(KB)\n\n### -gccause使用\n下面命令显示最近一次gc的原因，以及当前gc的原因：\n![这里写图片描述](http://img.blog.csdn.net/20150602005843699)\n\n* LGCC：上次gc的原因，从图中可以看到上次gc的原因是Allocation Failure\n* GCC：当前gc的原因，图中当前没有gc\n\n### -gcnew使用\n下面的命令显示新生代的详细信息:\n![这里写图片描述](http://img.blog.csdn.net/20150602005922047)\n* TT：新生代对象晋升到老年代对象的年龄。\n* MTT：新生代对象晋升到老年代对象的年龄的最大值。\n* DSS：所需的Survivor区的大小。\n\n### -gcnewcapacity使用\n下面的命令详细输出了新生代各个区的大小信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602010141932)\n* S0CMX：s0区的最大值(KB)\n* S1CMX：s1区的最大值(KB)\n* ECMX：eden区的最大值(KB)\n\n### -gcold使用\n下面的命令显示老年代gc概况：\n![这里写图片描述](http://img.blog.csdn.net/20150602010345984)\n\n### -gcoldcapacity使用\n下面的命令用于显示老年代的容量信息：\n![这里写图片描述](http://img.blog.csdn.net/20150602010443688)\n\n### -gcpermcapacity使用\n下面的命令用于显示永久区的使用情况：\n![这里写图片描述](http://img.blog.csdn.net/20150602010716581)\n","slug":"[JDK工具学习二]jstat命令使用","published":1,"updated":"2015-08-30T11:56:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbr003flo6by95eskxq"},{"title":"[JDK工具学习三]jinfo命令使用","date":"2015-08-01T01:32:47.000Z","_content":"## 概述\njinfo可以用来查看正在运行的java运用程序的扩展参数，甚至支持在运行时动态地更改部分参数，他的基本使用语法如下：\n>jinfo -< option > < pid >\n<!--more-->\n其中option可以为以下信息：\n* -flag< name >: 打印指定java虚拟机的参数值。\n* -flag [+|-]< name >：设置或取消指定java虚拟机参数的布尔值。\n* -flag < name >=< value >：设置指定java虚拟机的参数的值。\n\n## 使用示例\n1. 下面的命令显示了新生代对象晋升到老年代对象的最大年龄。在运行程序运行时并没有指定这个参数，但是通过jinfo，可以查看这个参数的当前的值。\n    ![这里写图片描述](http://img.blog.csdn.net/20150602225904273)\n    \n2. 下面的命令显示是否打印gc详细信息：\n    ![这里写图片描述](http://img.blog.csdn.net/20150602230032273)\n    \n3. 下面的命令在运用程序运行时动态打开打印详细gc信息开关：\n    ![这里写图片描述](http://img.blog.csdn.net/20150602230121712)\n    \n## 注意事项\njinfo虽然可以在java程序运行时动态地修改虚拟机参数，但并不是所有的参数都支持动态修改。\n\n\n\n\n","source":"_posts/[JDK工具学习三]jinfo命令使用.md","raw":"title: \"[JDK工具学习三]jinfo命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:32:47\n---\n## 概述\njinfo可以用来查看正在运行的java运用程序的扩展参数，甚至支持在运行时动态地更改部分参数，他的基本使用语法如下：\n>jinfo -< option > < pid >\n<!--more-->\n其中option可以为以下信息：\n* -flag< name >: 打印指定java虚拟机的参数值。\n* -flag [+|-]< name >：设置或取消指定java虚拟机参数的布尔值。\n* -flag < name >=< value >：设置指定java虚拟机的参数的值。\n\n## 使用示例\n1. 下面的命令显示了新生代对象晋升到老年代对象的最大年龄。在运行程序运行时并没有指定这个参数，但是通过jinfo，可以查看这个参数的当前的值。\n    ![这里写图片描述](http://img.blog.csdn.net/20150602225904273)\n    \n2. 下面的命令显示是否打印gc详细信息：\n    ![这里写图片描述](http://img.blog.csdn.net/20150602230032273)\n    \n3. 下面的命令在运用程序运行时动态打开打印详细gc信息开关：\n    ![这里写图片描述](http://img.blog.csdn.net/20150602230121712)\n    \n## 注意事项\njinfo虽然可以在java程序运行时动态地修改虚拟机参数，但并不是所有的参数都支持动态修改。\n\n\n\n\n","slug":"[JDK工具学习三]jinfo命令使用","published":1,"updated":"2015-08-21T08:05:22.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbt003ilo6b114veao2"},{"title":"[JDK工具学习七]jcmd命令使用","date":"2015-08-01T01:37:15.000Z","_content":"## 概述\n在JDK 1.7之后，新增了一个命令行工具jcmd。它是一个多功能工具，可以用来导出堆，查看java进程，导出线程信息，执行GC等。\n\n## 使用示例\n下面这个命令能够列出当前运行的所有虚拟机：\n<!--more-->\n![这里写图片描述](http://img.blog.csdn.net/20150604171002087)\n\n参数-l表示列出所有java虚拟机，针对每一个虚拟机，可以使用help命令列出该虚拟机支持的所有命令，如下图所示，以21024这个进程为例：\n\n![这里写图片描述](http://img.blog.csdn.net/20150604171153752)\n\n### 查看虚拟机启动时间VM.uptime\n![这里写图片描述](http://img.blog.csdn.net/20150604171358740)\n\n### 打印线程栈信息Thread.print\n![这里写图片描述](http://img.blog.csdn.net/20150604171538533)\n\n### 查看系统中类统计信息GC.class_histogram\n执行如下命令：\n> [qifuguang@Mac~]$ jcmd 21024 GC.class_histogram\n\n得到结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150604172039832)\n\n### 导出堆信息GC.heap_dump\n使用如下命令可以导出当前堆栈信息，这个命令功能和 [jmap -dump](http://blog.csdn.net/winwill2012/article/details/46337339)\n功能一样\n\n![这里写图片描述](http://img.blog.csdn.net/20150604172154322)\n\n### 获取系统Properties内容VM.system_properties\n![这里写图片描述](http://img.blog.csdn.net/20150604172452662)\n\n### 获取启动参数VM.flags\n![这里写图片描述](http://img.blog.csdn.net/20150604172713990)\n\n### 获取所有性能相关数据PerfCounter.print\n![这里写图片描述](http://img.blog.csdn.net/20150604172655777)\n\n\n## 总结\n从以上示例可以看出，jcmd拥有jmap的大部分功能，并且Oracle官方也建议使用jcmd代替jmap。\n","source":"_posts/[JDK工具学习七]jcmd命令使用.md","raw":"title: \"[JDK工具学习七]jcmd命令使用\"\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\ndate: 2015-08-01 09:37:15\n---\n## 概述\n在JDK 1.7之后，新增了一个命令行工具jcmd。它是一个多功能工具，可以用来导出堆，查看java进程，导出线程信息，执行GC等。\n\n## 使用示例\n下面这个命令能够列出当前运行的所有虚拟机：\n<!--more-->\n![这里写图片描述](http://img.blog.csdn.net/20150604171002087)\n\n参数-l表示列出所有java虚拟机，针对每一个虚拟机，可以使用help命令列出该虚拟机支持的所有命令，如下图所示，以21024这个进程为例：\n\n![这里写图片描述](http://img.blog.csdn.net/20150604171153752)\n\n### 查看虚拟机启动时间VM.uptime\n![这里写图片描述](http://img.blog.csdn.net/20150604171358740)\n\n### 打印线程栈信息Thread.print\n![这里写图片描述](http://img.blog.csdn.net/20150604171538533)\n\n### 查看系统中类统计信息GC.class_histogram\n执行如下命令：\n> [qifuguang@Mac~]$ jcmd 21024 GC.class_histogram\n\n得到结果如下：\n![这里写图片描述](http://img.blog.csdn.net/20150604172039832)\n\n### 导出堆信息GC.heap_dump\n使用如下命令可以导出当前堆栈信息，这个命令功能和 [jmap -dump](http://blog.csdn.net/winwill2012/article/details/46337339)\n功能一样\n\n![这里写图片描述](http://img.blog.csdn.net/20150604172154322)\n\n### 获取系统Properties内容VM.system_properties\n![这里写图片描述](http://img.blog.csdn.net/20150604172452662)\n\n### 获取启动参数VM.flags\n![这里写图片描述](http://img.blog.csdn.net/20150604172713990)\n\n### 获取所有性能相关数据PerfCounter.print\n![这里写图片描述](http://img.blog.csdn.net/20150604172655777)\n\n\n## 总结\n从以上示例可以看出，jcmd拥有jmap的大部分功能，并且Oracle官方也建议使用jcmd代替jmap。\n","slug":"[JDK工具学习七]jcmd命令使用","published":1,"updated":"2015-08-21T08:10:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbv003llo6bzev02id2"},{"title":"[JDK工具学习一]jps命令使用","date":"2015-08-01T01:09:32.000Z","_content":"jps命令类似于linux下的ps命令，用于列出当前正在运行的所有java进程。\n\n### 基本用法\n直接运行不加任何参数就能列出所有java进程的pid和类的短名称。例如：\n<!--more-->\n![这里写图片描述](http://img.blog.csdn.net/20150602000405556)\n### 常用参数\n#### -q参数\n-q可以指定jps只列出pid,而不输出类的短名称，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000630371)\n\n#### -m参数\n-m参数可以用于列出传递给java进程主函数的参数，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000614119)\n这里可以看到传递给jps（jps本身也是java进程）进程的参数就是-m\n\n#### -l参数\n-l参数用于输出主类的完整路径，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000748827)\n\n#### -v参数\n-v参数可以列出传递给java虚拟机的参数，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000948557)\n","source":"_posts/[JDK工具学习一]jps命令使用.md","raw":"title: \"[JDK工具学习一]jps命令使用\"\ndate: 2015-08-01 09:09:32\ntags: [JDK工具学习]\ncategories: [JDK工具学习]\n---\njps命令类似于linux下的ps命令，用于列出当前正在运行的所有java进程。\n\n### 基本用法\n直接运行不加任何参数就能列出所有java进程的pid和类的短名称。例如：\n<!--more-->\n![这里写图片描述](http://img.blog.csdn.net/20150602000405556)\n### 常用参数\n#### -q参数\n-q可以指定jps只列出pid,而不输出类的短名称，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000630371)\n\n#### -m参数\n-m参数可以用于列出传递给java进程主函数的参数，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000614119)\n这里可以看到传递给jps（jps本身也是java进程）进程的参数就是-m\n\n#### -l参数\n-l参数用于输出主类的完整路径，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000748827)\n\n#### -v参数\n-v参数可以列出传递给java虚拟机的参数，例如：\n\n![这里写图片描述](http://img.blog.csdn.net/20150602000948557)\n","slug":"[JDK工具学习一]jps命令使用","published":1,"updated":"2015-08-21T08:04:21.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovbz003olo6bexx0ezxk"},{"title":"[Docker学习二]Ubuntu系统安装Docker","date":"2015-08-01T01:42:01.000Z","_content":"本文仅仅介绍在ubuntu系统主机上安装Docker的方法，OSX,windows等系统请读者参阅：\n\n[window安装点击这里](http://blog.csdn.net/zistxym/article/details/42918339)\n[OSX安装点击这里](http://www.oschina.net/translate/installing-docker-on-mac-os-x)\n<!--more-->\n## 在Ubuntu系统中安装Docker\n\n目前，官方支持在西面的Ubuntu系统中安装Docker：\n\nUbuntu  14.04   64位\nUbuntu  13.04   64位\nUbuntu  13.10   64位\nUbuntu  12.04   64位\n但是，并不是说在上述清单之外的Ubuntu（活着Debian）版本就不能安装Docker。只要有适当的内核和Docker所必须的支持，其他版本的Ubuntu也是可以安装Docker的，只不过这些版本没有得到官方支持，遇到bug无法得到官方的修复。\n\n在Ubuntu系统下安装Docker需要如下步骤：\n\n### 检查前提条件\n\n#### 内核\n\n使用如下命令检查系统内核版本：\n```\n[qifuguang@winwill~]$ uname -a\nLinux qifuguang-OptiPlex-9010 3.13.0-53-generic #89-Ubuntu SMP Wed May 20 10:34:39 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n可以看到我的机器的内核版本是3.13.0-53，安装Docker需要Linux机器内核版本在3.8以上，所以符合要求。\n\n#### 检查Device Mapper\n\n我们将使用Device Mapper作为存储驱动，自2.6.9版本的linux内核已经开始集成了Device Mapper，并且提供了一个将快设备映射到高级虚拟设备的方法。Device Mapper支持“自动精简配置”的概念，可以在一中文件系统中存储多台虚拟设备。因此使用Device Mapper作为Docker的存储驱动再合适不过了。\n\n可以通过如下的命令确认机器是否安装了Device Mapper：\n```\n[qifuguang@winwill~]$ ls -l /sys/class/misc/device-mapper\nlrwxrwxrwx 1 root root 0  6月 26 20:26 /sys/class/misc/device-mapper -> ../../devices/virtual/misc/device-mapper\n```\n\n### 安装Docker\n\n如果上述的条件都符合，就可以安装Docker了。首先要添加Docker的APT仓库，代码如下:\n\n[qifuguang@winwill~]$ sudo sh -c \"echo deb https://get.docker.io/ubuntu docker main > /etc/apt/sources.list.d/docker.list\"\n\n\n接下来，要添加Docker仓库的GPG密钥，命令如下：\n```\n[qifuguang@winwill~]$ curl -s https://get.docker.io/gpg | sudo apt-key add -\nOK\n```\n\n之后，我们更新一下APT源：\n```\n[qifuguang@winwill~]$ sudo apt-get update\n忽略 http://security.ubuntu.com trusty-security InRelease\n忽略 http://ppa.launchpad.net trusty InRelease\n获取：1 http://security.ubuntu.com trusty-security Release.gpg [933 B]\n忽略 http://extras.ubuntu.com trusty InRelease\n获取：2 http://security.ubuntu.com trusty-security Release [63.5 kB]\n忽略 http://ppa.launchpad.net trusty InRelease\n命中 http://extras.ubuntu.com trusty Release.gpg\n获取：3 http://ppa.launchpad.net trusty Release.gpg [316 B]\n命中 http://extras.ubuntu.com trusty Release\n获取：4 https://get.docker.io docker InRelease\n命中 http://ppa.launchpad.net trusty Release.gpg\n命中 http://extras.ubuntu.com trusty/main Sources\n命中 http://extras.ubuntu.com trusty/main amd64 Packages\n获取：5 http://ppa.launchpad.net trusty Release [15.1 kB]\n获取：6 http://security.ubuntu.com trusty-security/main amd64 Packages [304 kB]\n忽略 https://get.docker.io docker InRelease\n命中 http://extras.ubuntu.com trusty/main i386 Packages\n25% [正在连接 cn.archive.ubuntu.com] [正在等待报头] [6 Packages 17.0\n......\n......\n```\n现在，就可以安装Docker软件包了：\n```\n[qifuguang@winwill~]$ sudo apt-get install lxc-docker\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树\n正在读取状态信息... 完成\n将会安装下列额外的软件包：\n  lxc-docker-1.7.0\n  下列软件包将被【卸载】：\n    lxc-docker-1.6.2\n    下列【新】软件包将被安装：\n      lxc-docker-1.7.0\n      下列软件包将被升级：\n        lxc-docker\n        升级了 1 个软件包，新安装了 1 个软件包，要卸载 1 个软件包，有 0 个软件包未被升级。\n        需要下载 4,964 kB 的软件包。\n        解压缩后会消耗掉 820 kB 的额外空间。\n        您希望继续执行吗？ [Y/n]Y\n        ```\n## 检查Docker是否安装成功\n\n        安装完成之后，可以使用docker info命令确认docker是否已经正确安装并运行了：\n        ```\n        [qifuguang@winwill~]$ sudo docker info\n        Containers: 5\n        Images: 72\n        Storage Driver: aufs\n         Root Dir: /var/lib/docker/aufs\n          Backing Filesystem: extfs\n           Dirs: 82\n            Dirperm1 Supported: false\n            Execution Driver: native-0.2\n            Kernel Version: 3.13.0-53-generic\n            Operating System: Ubuntu 14.04.2 LTS\n            CPUs: 8\n            Total Memory: 15.56 GiB\n            Name: qifuguang-OptiPlex-9010\n            ID: SNVW:WBCG:76BZ:2L63:AFQR:ZMDS:KI4Z:XIQZ:ENHV:O7PI:QMDP:6DQ3\n            Username: quinn2012\n            Registry: [https://index.docker.io/v1/]\n            WARNING: No swap limit support\n            ```\n","source":"_posts/[Docker学习二]Ubuntu系统安装Docker.md","raw":"title: \"[Docker学习二]Ubuntu系统安装Docker\"\ntags: [Docker]\ncategories: [Docker]\ndate: 2015-08-01 09:42:01\n---\n本文仅仅介绍在ubuntu系统主机上安装Docker的方法，OSX,windows等系统请读者参阅：\n\n[window安装点击这里](http://blog.csdn.net/zistxym/article/details/42918339)\n[OSX安装点击这里](http://www.oschina.net/translate/installing-docker-on-mac-os-x)\n<!--more-->\n## 在Ubuntu系统中安装Docker\n\n目前，官方支持在西面的Ubuntu系统中安装Docker：\n\nUbuntu  14.04   64位\nUbuntu  13.04   64位\nUbuntu  13.10   64位\nUbuntu  12.04   64位\n但是，并不是说在上述清单之外的Ubuntu（活着Debian）版本就不能安装Docker。只要有适当的内核和Docker所必须的支持，其他版本的Ubuntu也是可以安装Docker的，只不过这些版本没有得到官方支持，遇到bug无法得到官方的修复。\n\n在Ubuntu系统下安装Docker需要如下步骤：\n\n### 检查前提条件\n\n#### 内核\n\n使用如下命令检查系统内核版本：\n```\n[qifuguang@winwill~]$ uname -a\nLinux qifuguang-OptiPlex-9010 3.13.0-53-generic #89-Ubuntu SMP Wed May 20 10:34:39 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n可以看到我的机器的内核版本是3.13.0-53，安装Docker需要Linux机器内核版本在3.8以上，所以符合要求。\n\n#### 检查Device Mapper\n\n我们将使用Device Mapper作为存储驱动，自2.6.9版本的linux内核已经开始集成了Device Mapper，并且提供了一个将快设备映射到高级虚拟设备的方法。Device Mapper支持“自动精简配置”的概念，可以在一中文件系统中存储多台虚拟设备。因此使用Device Mapper作为Docker的存储驱动再合适不过了。\n\n可以通过如下的命令确认机器是否安装了Device Mapper：\n```\n[qifuguang@winwill~]$ ls -l /sys/class/misc/device-mapper\nlrwxrwxrwx 1 root root 0  6月 26 20:26 /sys/class/misc/device-mapper -> ../../devices/virtual/misc/device-mapper\n```\n\n### 安装Docker\n\n如果上述的条件都符合，就可以安装Docker了。首先要添加Docker的APT仓库，代码如下:\n\n[qifuguang@winwill~]$ sudo sh -c \"echo deb https://get.docker.io/ubuntu docker main > /etc/apt/sources.list.d/docker.list\"\n\n\n接下来，要添加Docker仓库的GPG密钥，命令如下：\n```\n[qifuguang@winwill~]$ curl -s https://get.docker.io/gpg | sudo apt-key add -\nOK\n```\n\n之后，我们更新一下APT源：\n```\n[qifuguang@winwill~]$ sudo apt-get update\n忽略 http://security.ubuntu.com trusty-security InRelease\n忽略 http://ppa.launchpad.net trusty InRelease\n获取：1 http://security.ubuntu.com trusty-security Release.gpg [933 B]\n忽略 http://extras.ubuntu.com trusty InRelease\n获取：2 http://security.ubuntu.com trusty-security Release [63.5 kB]\n忽略 http://ppa.launchpad.net trusty InRelease\n命中 http://extras.ubuntu.com trusty Release.gpg\n获取：3 http://ppa.launchpad.net trusty Release.gpg [316 B]\n命中 http://extras.ubuntu.com trusty Release\n获取：4 https://get.docker.io docker InRelease\n命中 http://ppa.launchpad.net trusty Release.gpg\n命中 http://extras.ubuntu.com trusty/main Sources\n命中 http://extras.ubuntu.com trusty/main amd64 Packages\n获取：5 http://ppa.launchpad.net trusty Release [15.1 kB]\n获取：6 http://security.ubuntu.com trusty-security/main amd64 Packages [304 kB]\n忽略 https://get.docker.io docker InRelease\n命中 http://extras.ubuntu.com trusty/main i386 Packages\n25% [正在连接 cn.archive.ubuntu.com] [正在等待报头] [6 Packages 17.0\n......\n......\n```\n现在，就可以安装Docker软件包了：\n```\n[qifuguang@winwill~]$ sudo apt-get install lxc-docker\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树\n正在读取状态信息... 完成\n将会安装下列额外的软件包：\n  lxc-docker-1.7.0\n  下列软件包将被【卸载】：\n    lxc-docker-1.6.2\n    下列【新】软件包将被安装：\n      lxc-docker-1.7.0\n      下列软件包将被升级：\n        lxc-docker\n        升级了 1 个软件包，新安装了 1 个软件包，要卸载 1 个软件包，有 0 个软件包未被升级。\n        需要下载 4,964 kB 的软件包。\n        解压缩后会消耗掉 820 kB 的额外空间。\n        您希望继续执行吗？ [Y/n]Y\n        ```\n## 检查Docker是否安装成功\n\n        安装完成之后，可以使用docker info命令确认docker是否已经正确安装并运行了：\n        ```\n        [qifuguang@winwill~]$ sudo docker info\n        Containers: 5\n        Images: 72\n        Storage Driver: aufs\n         Root Dir: /var/lib/docker/aufs\n          Backing Filesystem: extfs\n           Dirs: 82\n            Dirperm1 Supported: false\n            Execution Driver: native-0.2\n            Kernel Version: 3.13.0-53-generic\n            Operating System: Ubuntu 14.04.2 LTS\n            CPUs: 8\n            Total Memory: 15.56 GiB\n            Name: qifuguang-OptiPlex-9010\n            ID: SNVW:WBCG:76BZ:2L63:AFQR:ZMDS:KI4Z:XIQZ:ENHV:O7PI:QMDP:6DQ3\n            Username: quinn2012\n            Registry: [https://index.docker.io/v1/]\n            WARNING: No swap limit support\n            ```\n","slug":"[Docker学习二]Ubuntu系统安装Docker","published":1,"updated":"2015-08-21T07:52:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovc8003rlo6bu0p487k9"},{"title":"[Docker学习三]Docker入门","date":"2015-08-01T01:44:19.000Z","_content":"前面的文章讲解了怎么安装Docker，本文将迈出使用Docker的第一步，学习第一个Docker容器。\n<!--more-->\n## 确保Docker已经就绪\n\n使用如下命令可以查看docker程序是否存在，功能是否正常：\n```\n[qifuguang@winwill~]$ sudo docker info\nContainers: 5\nImages: 72\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 82\n Dirperm1 Supported: false\nExecution Driver: native-0.2\nKernel Version: 3.13.0-53-generic\nOperating System: Ubuntu 14.04.2 LTS\nCPUs: 8\nTotal Memory: 15.56 GiB\nName: qifuguang-OptiPlex-9010\nID: SNVW:WBCG:76BZ:2L63:AFQR:ZMDS:KI4Z:XIQZ:ENHV:O7PI:QMDP:6DQ3\nUsername: quinn2012\nRegistry: [https://index.docker.io/v1/]\nWARNING: No swap limit support\n```\n上述的info命令返回docker中所有的容器和镜像的数量，docker使用的执行驱动和存储驱动，以及docker的基本配置。\n\n## 运行第一个容器\n\n现在，我们尝试启动第一个容器。我们可以使用docker run命令创建容器，docker run命令提供了容器的创建和启动功能，在本文中我们使用该命里那个创建新容器：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627111304649)\n\n首先，我们告诉docker执行docker run命令，并指定-i和-t两个命令行参数。-i标识保证容器的STDIN是开启的，尽管我们并没有附着在容器中。持久的标准输入是交互式shell的“半边天”，而-t则是另外“半边天”，它告诉docker要为创建的容器分配一个伪tty终端。这样，创建的容器才能提供一个交互式的shell。如果要在命令行创建一个我们能与之进行交互的容器，这两个命令参数最基本的参数。\n\n接下来，告诉docker基于什么镜像来创建容器，上面示例使用的是ubuntu镜像。ubuntu镜像是一个常备镜像，也可以称为“基础镜像”，它由Docker公司提供，保存在Docker Hub Registry上。本例中我们基于ubuntu镜像创建、启动了一个容器，并没有做任何修改。\n\n这个命令背后的执行流程是怎样的呢？首先Docker会检查本地是否有ubuntu镜像，如果没有该镜像的话，Docker连接官方维护的Docker Hub Registry，查看Docker Hub中是否有该镜像，Docker一旦找到该镜像，就会下载该镜像并保存到本地宿主机中。随后Docker在文件系统内部用这个镜像创建 一个新容器。该容器拥有自己的网络，IP地址，以及一个用来和宿主机进行通信的桥接网络接口。最后，告诉Docker要在新容器中执行什么命令，在本例中执行/bin/bash命令启动一个Bash shell。\n\n##使用第一个容器\n我们已经以root用户登录到 了新的容器中，容器ID为faa127f03be9，看起来很不和谐，非常难以记忆，后续会告诉大家怎么为容器命名。\n### 查看/etc/hosts文件\n看看hosts文件的配置情况：\n```\nroot@faa127f03be9:/# cat /etc/hosts\n172.17.0.45 faa127f03be9\n127.0.0.1   localhost\n::1 localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nroot@faa127f03be9:/#\n```\n可以看到，Docker已经使用容器ID在/etc/hosts文件中为容器添加了一条主机配置项。\n### 查看网络配置情况\n我们可以看看容器的网络配置情况：\n```\nroot@faa127f03be9:/# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n100: eth0: <BROADCAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:2d brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.45/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:acff:fe11:2d/64 scope link\n       valid_lft forever preferred_lft forever\nroot@faa127f03be9:/#\n```\n可以看到，这里有lo回环接口，还有IP为172.17.0.45的白哦准的eth0网络接口，和普通的宿主机完全一样。\n### 查看容器中运行的进程\n通过如下的命令可以查看容器中运行的进程：\n```\nroot@faa127f03be9:/# ps -aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0  18164  2020 ?        Ss   03:11   0:00 /bin/bash\nroot        17  0.0  0.0  15564  1152 ?        R+   03:17   0:00 ps -aux\nroot@faa127f03be9:/#\n```\n### 在容器中安装软件\n刚刚启动的容器中是没有vim软件包的：\n```\nroot@faa127f03be9:/# vim /etc/hosts\nbash: vim: command not found\nroot@faa127f03be9:/#\n```\n现在我们在容器中安装vim软件包：\n```\nroot@faa127f03be9:/# sudo apt-get install vim\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libgpm2 libpython2.7 libpython2.7-minimal libpython2.7-stdlib vim-runtime\nSuggested packages:\n  gpm ctags vim-doc vim-scripts\nThe following NEW packages will be installed:\n  libgpm2 libpython2.7 libpython2.7-minimal libpython2.7-stdlib vim\n  vim-runtime\n0 upgraded, 6 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 9083 kB of archives.\nAfter this operation, 42.9 MB of additional disk space will be used.\nDo you want to continue? [Y/n] Y\nGet:1 http://archive.ubuntu.com/ubuntu/ trusty/main libgpm2 amd64 1.20.4-6.1 [16.5 kB]\nGet:2 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7-minimal amd64 2.7.6-8 [307 kB]\nGet:3 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7-stdlib amd64 2.7.6-8 [1872 kB]\nGet:4 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7 amd64 2.7.6-8 [1044 kB]\nGet:5 http://archive.ubuntu.com/ubuntu/ trusty/main vim-runtime all 2:7.4.052-1ubuntu3 [4888 kB]\n......\nProcessing triggers for libc-bin (2.19-0ubuntu6.6) ...\nroot@faa127f03be9:/#\n```\nvim软件包就已经安装好了，怎么样？是不是和普通宿主机安装软件包一样简单！\n\n### 退出容器\n使用如下命令可以退出容器：\n```\nroot@faa127f03be9:/# exit\nexit\n[qifuguang@winwill~]$\n```\n现在，容器已经退出了，我们可以使用如下命令看看当前有哪些容器正在运行：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627112734913)\n\n可以看到，当前没有处于运行状态的容器，但是如果使用如下命令，便会显示所有容器，包含没有处于运行状态的：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627112852973)\n\n也可以使用如下的命令列出最后一次运行的容器，包含正在运行和没有运行的：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627113045970)\n\n## 为容器命名\n上面的例子运行的容器的ID默认是一串没有规律的字符串，可读性非常差，还好，我们可以在创建启动容器的时候给它指定一个名字：\n```\n[qifuguang@winwill~]$ sudo docker run -t -i --name ubuntu ubuntu /bin/bash\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\n```\n上面的命令通过参数项--name为创建的容器命名为ubuntu，我们看看生效没有：\n![这里写图片描述](http://img.blog.csdn.net/20150627113908706)\n从图中可以看到，命名已经生效。\n\n顺便说一下，容器的命名规则：只能包含大小写字母，数字，下划线，圆点，横线，如果用正则表达式表示这些符号就是[a-zA-Z0-9_.]。\n\n## 重启已经停止的容器\n我们可以使用start命令启动已经停止的容器：\n![这里写图片描述](http://img.blog.csdn.net/20150627114405311)\n也可以使用docker restart命令重新启动一个正在运行的容器。\n\n## 附着在容器上\nDocker容器重新启动的时候，会沿用创建容器时（docker run时）指定的参数来运行，因此指定了-t -i参数的容器重新启动之后会运行一个交互式的会话shell，我们可以使用docker attach命令重新附着到该容器的会话上：\n![这里写图片描述](http://img.blog.csdn.net/20150627114728424)\n\n## 创建守护式进程\n除了运行交互式的容器，我们还可以创建长期运行的容器，守护式进程没有交互式会话，非常适合于运用程序和服务，大多数时候我们都需要使用交互式方式运行容器。下面我们启动一个守护式容器：\n```\n[qifuguang@winwill~]$ sudo docker run -d --name deamon_ubuntu ubuntu /bin/bash -c \"while true; do echo hello word; sleep 1; done\"\n48fcd5b118fd86ebee6fefb376cda3235384ddd3c41fa502ef0b59c9e1f2f1d3\n[qifuguang@winwill~]$\n```\n可以看到，这个容器运行之后并没有像交互式容器一样将主机的控制台附着在新的shell会话上，而是仅仅返回一个容器ID。使用docker ps可以看到刚刚创建的交互式的容器正在运行：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627120122298)\n\n## 查看容日日志\n对于守护式的容器，我们不能知道他到底在干些什么，但是我们可以通过查看docker容器的日志了解：\n![这里写图片描述](http://img.blog.csdn.net/20150627120306595)\n可以看到，刚才创建的守护式容器正在后台不停地打印“hello world”。\n\n也可以使用docker logs -f来监控docker容器的日志，就像ubuntu系统下使用tail -f 一样：\n\n## 查看容器内的进程\n除了容器的日志，我们还可以查看容器内部的进程：\n![这里写图片描述](http://img.blog.csdn.net/20150627120548711)\n通过这个命令，我们可以看到容器内部的所有进程，运行进程的用户以及进程ID。\n\n## 在容器内部运行进程\nDocker 1.3之后，可以通过docker exec命令在容器内部额外启动新进程。可以在容器内部运行的进程有两种形式：后台任务和交互式任务。\n```\n[qifuguang@winwill~]$ sudo docker exec -d deamon_ubuntu touch /etc/new_file\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n```\n这里的-d标志表明需要运行一个后台任务，-d后面紧跟的是要在哪个容器内部执行命令，接下来是需要执行的命令。\n\n我们也可以在deamon_ubuntu容器中启动一个打开shell的交互式任务，代码如下：\n```\n[qifuguang@winwill~]$ sudo docker exec -i -t deamon_ubuntu /bin/bash\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\n```\n这里的-i和-t参数和运行容器时的含义是一样的。\n\n## 停止守护式容器\n要停止守护式容器，可以使用stop命令：\n![这里写图片描述](http://img.blog.csdn.net/20150627121343870)\n\n## 自动重启容器\n如果由于某种错误导致容器停止运行，我们可以通过--restart表示，让Docker自动重启容器。--restart会检查容器的推出代码，并以此来决定是否要重启容器，默认行为是docker不会重启容器。\n\n## 深入容器\n可以使用哪个docker inspect查看容器的详细信息：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121639396)\n\n由于信息量太大，还可以使用-f或者--format标识来选定查看结果：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121827553)\n\n## 删除容器\n可以使用docker rm命令删除容器：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121932771)\n\ndocker基本的操作大概就这么多。\n\n","source":"_posts/[Docker学习三]Docker入门.md","raw":"title: \"[Docker学习三]Docker入门\"\ntags: [Docker]\ncategories: [Docker]\ndate: 2015-08-01 09:44:19\n---\n前面的文章讲解了怎么安装Docker，本文将迈出使用Docker的第一步，学习第一个Docker容器。\n<!--more-->\n## 确保Docker已经就绪\n\n使用如下命令可以查看docker程序是否存在，功能是否正常：\n```\n[qifuguang@winwill~]$ sudo docker info\nContainers: 5\nImages: 72\nStorage Driver: aufs\n Root Dir: /var/lib/docker/aufs\n Backing Filesystem: extfs\n Dirs: 82\n Dirperm1 Supported: false\nExecution Driver: native-0.2\nKernel Version: 3.13.0-53-generic\nOperating System: Ubuntu 14.04.2 LTS\nCPUs: 8\nTotal Memory: 15.56 GiB\nName: qifuguang-OptiPlex-9010\nID: SNVW:WBCG:76BZ:2L63:AFQR:ZMDS:KI4Z:XIQZ:ENHV:O7PI:QMDP:6DQ3\nUsername: quinn2012\nRegistry: [https://index.docker.io/v1/]\nWARNING: No swap limit support\n```\n上述的info命令返回docker中所有的容器和镜像的数量，docker使用的执行驱动和存储驱动，以及docker的基本配置。\n\n## 运行第一个容器\n\n现在，我们尝试启动第一个容器。我们可以使用docker run命令创建容器，docker run命令提供了容器的创建和启动功能，在本文中我们使用该命里那个创建新容器：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627111304649)\n\n首先，我们告诉docker执行docker run命令，并指定-i和-t两个命令行参数。-i标识保证容器的STDIN是开启的，尽管我们并没有附着在容器中。持久的标准输入是交互式shell的“半边天”，而-t则是另外“半边天”，它告诉docker要为创建的容器分配一个伪tty终端。这样，创建的容器才能提供一个交互式的shell。如果要在命令行创建一个我们能与之进行交互的容器，这两个命令参数最基本的参数。\n\n接下来，告诉docker基于什么镜像来创建容器，上面示例使用的是ubuntu镜像。ubuntu镜像是一个常备镜像，也可以称为“基础镜像”，它由Docker公司提供，保存在Docker Hub Registry上。本例中我们基于ubuntu镜像创建、启动了一个容器，并没有做任何修改。\n\n这个命令背后的执行流程是怎样的呢？首先Docker会检查本地是否有ubuntu镜像，如果没有该镜像的话，Docker连接官方维护的Docker Hub Registry，查看Docker Hub中是否有该镜像，Docker一旦找到该镜像，就会下载该镜像并保存到本地宿主机中。随后Docker在文件系统内部用这个镜像创建 一个新容器。该容器拥有自己的网络，IP地址，以及一个用来和宿主机进行通信的桥接网络接口。最后，告诉Docker要在新容器中执行什么命令，在本例中执行/bin/bash命令启动一个Bash shell。\n\n##使用第一个容器\n我们已经以root用户登录到 了新的容器中，容器ID为faa127f03be9，看起来很不和谐，非常难以记忆，后续会告诉大家怎么为容器命名。\n### 查看/etc/hosts文件\n看看hosts文件的配置情况：\n```\nroot@faa127f03be9:/# cat /etc/hosts\n172.17.0.45 faa127f03be9\n127.0.0.1   localhost\n::1 localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\nroot@faa127f03be9:/#\n```\n可以看到，Docker已经使用容器ID在/etc/hosts文件中为容器添加了一条主机配置项。\n### 查看网络配置情况\n我们可以看看容器的网络配置情况：\n```\nroot@faa127f03be9:/# ip a\n1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n100: eth0: <BROADCAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:2d brd ff:ff:ff:ff:ff:ff\n    inet 172.17.0.45/16 scope global eth0\n       valid_lft forever preferred_lft forever\n    inet6 fe80::42:acff:fe11:2d/64 scope link\n       valid_lft forever preferred_lft forever\nroot@faa127f03be9:/#\n```\n可以看到，这里有lo回环接口，还有IP为172.17.0.45的白哦准的eth0网络接口，和普通的宿主机完全一样。\n### 查看容器中运行的进程\n通过如下的命令可以查看容器中运行的进程：\n```\nroot@faa127f03be9:/# ps -aux\nUSER       PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot         1  0.0  0.0  18164  2020 ?        Ss   03:11   0:00 /bin/bash\nroot        17  0.0  0.0  15564  1152 ?        R+   03:17   0:00 ps -aux\nroot@faa127f03be9:/#\n```\n### 在容器中安装软件\n刚刚启动的容器中是没有vim软件包的：\n```\nroot@faa127f03be9:/# vim /etc/hosts\nbash: vim: command not found\nroot@faa127f03be9:/#\n```\n现在我们在容器中安装vim软件包：\n```\nroot@faa127f03be9:/# sudo apt-get install vim\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following extra packages will be installed:\n  libgpm2 libpython2.7 libpython2.7-minimal libpython2.7-stdlib vim-runtime\nSuggested packages:\n  gpm ctags vim-doc vim-scripts\nThe following NEW packages will be installed:\n  libgpm2 libpython2.7 libpython2.7-minimal libpython2.7-stdlib vim\n  vim-runtime\n0 upgraded, 6 newly installed, 0 to remove and 0 not upgraded.\nNeed to get 9083 kB of archives.\nAfter this operation, 42.9 MB of additional disk space will be used.\nDo you want to continue? [Y/n] Y\nGet:1 http://archive.ubuntu.com/ubuntu/ trusty/main libgpm2 amd64 1.20.4-6.1 [16.5 kB]\nGet:2 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7-minimal amd64 2.7.6-8 [307 kB]\nGet:3 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7-stdlib amd64 2.7.6-8 [1872 kB]\nGet:4 http://archive.ubuntu.com/ubuntu/ trusty/main libpython2.7 amd64 2.7.6-8 [1044 kB]\nGet:5 http://archive.ubuntu.com/ubuntu/ trusty/main vim-runtime all 2:7.4.052-1ubuntu3 [4888 kB]\n......\nProcessing triggers for libc-bin (2.19-0ubuntu6.6) ...\nroot@faa127f03be9:/#\n```\nvim软件包就已经安装好了，怎么样？是不是和普通宿主机安装软件包一样简单！\n\n### 退出容器\n使用如下命令可以退出容器：\n```\nroot@faa127f03be9:/# exit\nexit\n[qifuguang@winwill~]$\n```\n现在，容器已经退出了，我们可以使用如下命令看看当前有哪些容器正在运行：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627112734913)\n\n可以看到，当前没有处于运行状态的容器，但是如果使用如下命令，便会显示所有容器，包含没有处于运行状态的：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627112852973)\n\n也可以使用如下的命令列出最后一次运行的容器，包含正在运行和没有运行的：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627113045970)\n\n## 为容器命名\n上面的例子运行的容器的ID默认是一串没有规律的字符串，可读性非常差，还好，我们可以在创建启动容器的时候给它指定一个名字：\n```\n[qifuguang@winwill~]$ sudo docker run -t -i --name ubuntu ubuntu /bin/bash\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\nroot@fdbcdbed6749:/#\n```\n上面的命令通过参数项--name为创建的容器命名为ubuntu，我们看看生效没有：\n![这里写图片描述](http://img.blog.csdn.net/20150627113908706)\n从图中可以看到，命名已经生效。\n\n顺便说一下，容器的命名规则：只能包含大小写字母，数字，下划线，圆点，横线，如果用正则表达式表示这些符号就是[a-zA-Z0-9_.]。\n\n## 重启已经停止的容器\n我们可以使用start命令启动已经停止的容器：\n![这里写图片描述](http://img.blog.csdn.net/20150627114405311)\n也可以使用docker restart命令重新启动一个正在运行的容器。\n\n## 附着在容器上\nDocker容器重新启动的时候，会沿用创建容器时（docker run时）指定的参数来运行，因此指定了-t -i参数的容器重新启动之后会运行一个交互式的会话shell，我们可以使用docker attach命令重新附着到该容器的会话上：\n![这里写图片描述](http://img.blog.csdn.net/20150627114728424)\n\n## 创建守护式进程\n除了运行交互式的容器，我们还可以创建长期运行的容器，守护式进程没有交互式会话，非常适合于运用程序和服务，大多数时候我们都需要使用交互式方式运行容器。下面我们启动一个守护式容器：\n```\n[qifuguang@winwill~]$ sudo docker run -d --name deamon_ubuntu ubuntu /bin/bash -c \"while true; do echo hello word; sleep 1; done\"\n48fcd5b118fd86ebee6fefb376cda3235384ddd3c41fa502ef0b59c9e1f2f1d3\n[qifuguang@winwill~]$\n```\n可以看到，这个容器运行之后并没有像交互式容器一样将主机的控制台附着在新的shell会话上，而是仅仅返回一个容器ID。使用docker ps可以看到刚刚创建的交互式的容器正在运行：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627120122298)\n\n## 查看容日日志\n对于守护式的容器，我们不能知道他到底在干些什么，但是我们可以通过查看docker容器的日志了解：\n![这里写图片描述](http://img.blog.csdn.net/20150627120306595)\n可以看到，刚才创建的守护式容器正在后台不停地打印“hello world”。\n\n也可以使用docker logs -f来监控docker容器的日志，就像ubuntu系统下使用tail -f 一样：\n\n## 查看容器内的进程\n除了容器的日志，我们还可以查看容器内部的进程：\n![这里写图片描述](http://img.blog.csdn.net/20150627120548711)\n通过这个命令，我们可以看到容器内部的所有进程，运行进程的用户以及进程ID。\n\n## 在容器内部运行进程\nDocker 1.3之后，可以通过docker exec命令在容器内部额外启动新进程。可以在容器内部运行的进程有两种形式：后台任务和交互式任务。\n```\n[qifuguang@winwill~]$ sudo docker exec -d deamon_ubuntu touch /etc/new_file\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n[qifuguang@winwill~]$\n```\n这里的-d标志表明需要运行一个后台任务，-d后面紧跟的是要在哪个容器内部执行命令，接下来是需要执行的命令。\n\n我们也可以在deamon_ubuntu容器中启动一个打开shell的交互式任务，代码如下：\n```\n[qifuguang@winwill~]$ sudo docker exec -i -t deamon_ubuntu /bin/bash\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\nroot@48fcd5b118fd:/#\n```\n这里的-i和-t参数和运行容器时的含义是一样的。\n\n## 停止守护式容器\n要停止守护式容器，可以使用stop命令：\n![这里写图片描述](http://img.blog.csdn.net/20150627121343870)\n\n## 自动重启容器\n如果由于某种错误导致容器停止运行，我们可以通过--restart表示，让Docker自动重启容器。--restart会检查容器的推出代码，并以此来决定是否要重启容器，默认行为是docker不会重启容器。\n\n## 深入容器\n可以使用哪个docker inspect查看容器的详细信息：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121639396)\n\n由于信息量太大，还可以使用-f或者--format标识来选定查看结果：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121827553)\n\n## 删除容器\n可以使用docker rm命令删除容器：\n\n![这里写图片描述](http://img.blog.csdn.net/20150627121932771)\n\ndocker基本的操作大概就这么多。\n\n","slug":"[Docker学习三]Docker入门","published":1,"updated":"2015-08-21T08:36:04.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovcd003wlo6by5dwqn1g"},{"title":"[Docker学习一]Docker简介","date":"2015-08-01T01:40:51.000Z","_content":"## Docker简介\n\nDocker是一个能够把开发的应用程序很方便地部署到容器的开源引擎。由Docker公司团队编写，基于Apache 2.0开源授权协议发行。Docker的主要目的如下：\n<!--more-->\n### 提供一个简单的，轻量的建模方式\n\nDocker上手快，只需要几分钟就可以将自己的程序Docker化。Docker依赖写时复制技术，使修改应用程序非常迅速，达到“随心所至，代码即改”的境界。Docker启动速度非常快，大多数的Docker容器只需不到1秒钟的时间即可启动。由于除去了管理程序的开销，Docker容器拥有很高的性能，一台宿主机可以同时运行很多容器，要比虚拟机技术牛逼得多。\n\n### 职责的逻辑分离\n\n使用Docker，开发人员只需要关系容器中运行的应用程序，而运维人员只需要关心如何管理容器，分离职责。\n\n### 快速、高效的开发生命周期\n\nDocker的目标之一就是缩短代码从开发，测试到部署，上线运行的周期，让应用程序具备可移植性，易于构建，易于协作。\n\n### 鼓励使用面向服务的架构\n\nDocker鼓励面向服务的架构和微服务架构，推荐单个容器只运行一个进程或程序。这样就形成了一个分布式的应用程序模型，在这种情况下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序变得非常简单，同时也提高了程序的内省性。\n\n## Docker组件\n\nDocker包含如下组件：\n\nDocker客户端和服务器\nDocker镜像（image）\nDocker容器\nRegistry\n至于这些名词具体表示什么意思，后面会有文章做详细的介绍。\n\n## Docker能做什么\n\n我们可以使用Docker做如下一些事情：\n\n加速本地开发和构建流程，使其更加高效，更加轻量化。\n能够让独立服务或者应用程序在不同的环境红，得到相同的运行结果。\n用Docker创建隔离的环境来进行测试。\nDocker可以让开发者很简单地在本机构建一个复杂的环境进行测试。\n构建一个多用户的平台即服务（PaaS）基础设施。\n为开发，测试提供一个轻量级的独立沙盒测试环境。\n提供软件即服务(SaaS)应用程序，如Memcached即服务。\n高性能，超大规模的宿主机部署。\n\n## Docker的核心技术\n\n* **文件系统隔离**：每个容器都拥有自己的root文件系统。\n* **进程隔离**：每个容器都运行在自己的进程环境中。\n* **网络隔离**：容器的虚拟网络接口和IP都是分开的。\n* **资源隔离和分组**：使用cgroups将CPU和内存资源独立分配给每个 Docker容器。\n* **写时复制**：文件系统都是写时复制的，速度快，占用磁盘空间更少。\n* **日志收集**：容器产生的stdin，stdout，stderr日志都会被收集并记录日志。\n* **交互式shell**：用户可以创建一个伪tty终端，将其连接到stdin，为容器提供一个交互式的shell。\n","source":"_posts/[Docker学习一]Docker简介.md","raw":"title: \"[Docker学习一]Docker简介\"\ntags: [Docker]\ncategories: [Docker]\ndate: 2015-08-01 09:40:51\n---\n## Docker简介\n\nDocker是一个能够把开发的应用程序很方便地部署到容器的开源引擎。由Docker公司团队编写，基于Apache 2.0开源授权协议发行。Docker的主要目的如下：\n<!--more-->\n### 提供一个简单的，轻量的建模方式\n\nDocker上手快，只需要几分钟就可以将自己的程序Docker化。Docker依赖写时复制技术，使修改应用程序非常迅速，达到“随心所至，代码即改”的境界。Docker启动速度非常快，大多数的Docker容器只需不到1秒钟的时间即可启动。由于除去了管理程序的开销，Docker容器拥有很高的性能，一台宿主机可以同时运行很多容器，要比虚拟机技术牛逼得多。\n\n### 职责的逻辑分离\n\n使用Docker，开发人员只需要关系容器中运行的应用程序，而运维人员只需要关心如何管理容器，分离职责。\n\n### 快速、高效的开发生命周期\n\nDocker的目标之一就是缩短代码从开发，测试到部署，上线运行的周期，让应用程序具备可移植性，易于构建，易于协作。\n\n### 鼓励使用面向服务的架构\n\nDocker鼓励面向服务的架构和微服务架构，推荐单个容器只运行一个进程或程序。这样就形成了一个分布式的应用程序模型，在这种情况下，应用程序或者服务都可以表示为一系列内部互联的容器，从而使分布式部署应用程序，扩展或调试应用程序变得非常简单，同时也提高了程序的内省性。\n\n## Docker组件\n\nDocker包含如下组件：\n\nDocker客户端和服务器\nDocker镜像（image）\nDocker容器\nRegistry\n至于这些名词具体表示什么意思，后面会有文章做详细的介绍。\n\n## Docker能做什么\n\n我们可以使用Docker做如下一些事情：\n\n加速本地开发和构建流程，使其更加高效，更加轻量化。\n能够让独立服务或者应用程序在不同的环境红，得到相同的运行结果。\n用Docker创建隔离的环境来进行测试。\nDocker可以让开发者很简单地在本机构建一个复杂的环境进行测试。\n构建一个多用户的平台即服务（PaaS）基础设施。\n为开发，测试提供一个轻量级的独立沙盒测试环境。\n提供软件即服务(SaaS)应用程序，如Memcached即服务。\n高性能，超大规模的宿主机部署。\n\n## Docker的核心技术\n\n* **文件系统隔离**：每个容器都拥有自己的root文件系统。\n* **进程隔离**：每个容器都运行在自己的进程环境中。\n* **网络隔离**：容器的虚拟网络接口和IP都是分开的。\n* **资源隔离和分组**：使用cgroups将CPU和内存资源独立分配给每个 Docker容器。\n* **写时复制**：文件系统都是写时复制的，速度快，占用磁盘空间更少。\n* **日志收集**：容器产生的stdin，stdout，stderr日志都会被收集并记录日志。\n* **交互式shell**：用户可以创建一个伪tty终端，将其连接到stdin，为容器提供一个交互式的shell。\n","slug":"[Docker学习一]Docker简介","published":1,"updated":"2015-08-21T07:50:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovcf003zlo6bqvs2c5ap"},{"title":"ZooKeeper使用场景","date":"2015-10-10T04:53:14.000Z","_content":"\n# 概述\nZooKeeper是一个高可用的分布式数据管理与系统协调框架。基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基于这样的特性，使得ZooKeeper解决很多分布式问题。网上对ZK的应用场景也有不少介绍，本文将结合作者身边的项目例子，系统地对ZK的应用场景进行一个分门归类的介绍。\n\n值得注意的是，ZK并非天生就是为这些应用场景设计的，都是后来众多开发者根据其框架的特性，利用其提供的一系列API接口（或者称为原语集），摸索出来的典型使用方法。因此，也非常欢迎读者分享你在ZK使用上的奇技淫巧。\n<!--more-->\n\n# ZooKeeper应用场景\n\n## 数据发布与订阅（配置中心）\n发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。\n应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。\n分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在ZK的一些指定节点，供各个客户端订阅使用。分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用来分配收集任务单元，因此需要在ZK上创建一个以应用名作为path的节点P，并将这个应用的所有机器ip，以子节点的形式注册到节点P上，这样一来就能够实现机器变动的时候，能够实时通知到收集器调整任务分配。\n系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息的发问。通常是暴露出接口，例如JMX接口，来获取一些运行时的信息。引入ZK之后，就不用自己实现一套方案了，只要将这些信息存放到指定的ZK节点上即可。  \n**注意：在上面提到的应用场景中，有个默认前提是：数据量很小，但是数据更新可能会比较快的场景。**\n\n## 负载均衡\n这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。\n消息中间件中发布者和订阅者的负载均衡，linkedin开源的KafkaMQ和阿里开源的 metaq都是通过zookeeper来做到生产者、消费者的负载均衡。这里以metaq为例讲下： \n\n### 生产者负载均衡\nmetaq发送消息的时候，生产者在发送消息的时候必须选择一台broker上的一个分区来发送消息，因此metaq在运行过程中，会把所有broker和对应的分区信息全部注册到ZK指定节点上，默认的策略是一个依次轮询的过程，生产者在通过ZK获取分区列表之后，会按照brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。\n \n### 消费负载均衡：\n\n在消费过程中，一个消费者会消费一个或多个分区中的消息，但是一个分区只会由一个消费者来消费。MetaQ的消费策略是：\n\n* 每个分区针对同一个group只挂载一个消费者。\n* 如果同一个group的消费者数目大于分区数目，则多出来的消费者将不参与消费。\n* 如果同一个group的消费者数目小于分区数目，则有部分消费者需要额外承担消费任务。\n* 在某个消费者故障或者重启等情况下，其他消费者会感知到这一变化（通过 zookeeper watch消费者列表），然后重新进行负载均衡，保证所有的分区都有消费者进行消费。\n\n## 命名服务(Naming Service)\n命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。\n阿里巴巴集团开源的分布式服务框架Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表， 点击这里查看Dubbo开源项目。在Dubbo实现中：\n\n>服务提供者在启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。\n服务消费者启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。\n注意，所有向ZK上注册的地址都是临时节点，这样就能够保证服务提供者和消费者能够自动感应资源的变化。\n另外，Dubbo还有针对服务粒度的监控，方法是订阅/dubbo/${serviceName}目录下所有提供者和消费者的信息。\n\n## 分布式通知/协调\nZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理\n另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。\n另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。\n另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。\n总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合\n\n## 集群管理\n集群机器监控通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：\n\n* 集群中机器有变动的时候，牵连修改的东西比较多。\n* 有一定的延时。\n\n利用ZooKeeper的两个特性，就可以实时另一种集群机器存活性监控系统：\n\n>客户端在节点x上注册一个Watcher，那么如果x的子节点变化了，会通知该客户端。\n创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。\n例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。\n\n## Master选举\nMaster选举是zookeeper中最为经典的应用场景了。在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。\n\n利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。\n\n另外，这种场景演化一下，就是动态Master选举。这就要用到?EPHEMERAL_SEQUENTIAL类型节点的特性了。\n\n上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 ,?/currentMaster/{sessionId}-2 ,?/currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。\n\n在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。\n在Hbase中，也是使用ZooKeeper来实现动态HMaster的选举。在Hbase实现中，会在ZK上存储一些ROOT表的地址和HMaster的地址，HRegionServer也会把自己以临时节点（Ephemeral）的方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的存活状态，同时，一旦HMaster出现问题，会重新选举出一个HMaster来运行，从而避免了HMaster的单点问题。\n\n## 分布式锁\n分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是 保持独占，另一个是 控制时序。\n所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。\n控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。\n\n## 分布式队列\n队列方面，简单地讲有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第一种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。\n第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。\n\n# 声明\n本文非原创，原文链接：[http://itindex.net/detail/53886-zookeeper](http://itindex.net/detail/53886-zookeeper)，尊重原创，转载请注明出处。\n","source":"_posts/ZooKeeper使用场景.md","raw":"title: ZooKeeper使用场景\ntags: [ZooKeeper]\ncategories: [ZooKeeper]\ndate: 2015-10-10 12:53:14\n---\n\n# 概述\nZooKeeper是一个高可用的分布式数据管理与系统协调框架。基于对Paxos算法的实现，使该框架保证了分布式环境中数据的强一致性，也正是基于这样的特性，使得ZooKeeper解决很多分布式问题。网上对ZK的应用场景也有不少介绍，本文将结合作者身边的项目例子，系统地对ZK的应用场景进行一个分门归类的介绍。\n\n值得注意的是，ZK并非天生就是为这些应用场景设计的，都是后来众多开发者根据其框架的特性，利用其提供的一系列API接口（或者称为原语集），摸索出来的典型使用方法。因此，也非常欢迎读者分享你在ZK使用上的奇技淫巧。\n<!--more-->\n\n# ZooKeeper应用场景\n\n## 数据发布与订阅（配置中心）\n发布与订阅模型，即所谓的配置中心，顾名思义就是发布者将数据发布到ZK节点上，供订阅者动态获取数据，实现配置信息的集中式管理和动态更新。例如全局的配置信息，服务式服务框架的服务地址列表等就非常适合使用。\n应用中用到的一些配置信息放到ZK上进行集中管理。这类场景通常是这样：应用在启动的时候会主动来获取一次配置，同时，在节点上注册一个Watcher，这样一来，以后每次配置有更新的时候，都会实时通知到订阅的客户端，从来达到获取最新配置信息的目的。\n分布式搜索服务中，索引的元信息和服务器集群机器的节点状态存放在ZK的一些指定节点，供各个客户端订阅使用。分布式日志收集系统。这个系统的核心工作是收集分布在不同机器的日志。收集器通常是按照应用来分配收集任务单元，因此需要在ZK上创建一个以应用名作为path的节点P，并将这个应用的所有机器ip，以子节点的形式注册到节点P上，这样一来就能够实现机器变动的时候，能够实时通知到收集器调整任务分配。\n系统中有些信息需要动态获取，并且还会存在人工手动去修改这个信息的发问。通常是暴露出接口，例如JMX接口，来获取一些运行时的信息。引入ZK之后，就不用自己实现一套方案了，只要将这些信息存放到指定的ZK节点上即可。  \n**注意：在上面提到的应用场景中，有个默认前提是：数据量很小，但是数据更新可能会比较快的场景。**\n\n## 负载均衡\n这里说的负载均衡是指软负载均衡。在分布式环境中，为了保证高可用性，通常同一个应用或同一个服务的提供方都会部署多份，达到对等服务。而消费者就须要在这些对等的服务器中选择一个来执行相关的业务逻辑，其中比较典型的是消息中间件中的生产者，消费者负载均衡。\n消息中间件中发布者和订阅者的负载均衡，linkedin开源的KafkaMQ和阿里开源的 metaq都是通过zookeeper来做到生产者、消费者的负载均衡。这里以metaq为例讲下： \n\n### 生产者负载均衡\nmetaq发送消息的时候，生产者在发送消息的时候必须选择一台broker上的一个分区来发送消息，因此metaq在运行过程中，会把所有broker和对应的分区信息全部注册到ZK指定节点上，默认的策略是一个依次轮询的过程，生产者在通过ZK获取分区列表之后，会按照brokerId和partition的顺序排列组织成一个有序的分区列表，发送的时候按照从头到尾循环往复的方式选择一个分区来发送消息。\n \n### 消费负载均衡：\n\n在消费过程中，一个消费者会消费一个或多个分区中的消息，但是一个分区只会由一个消费者来消费。MetaQ的消费策略是：\n\n* 每个分区针对同一个group只挂载一个消费者。\n* 如果同一个group的消费者数目大于分区数目，则多出来的消费者将不参与消费。\n* 如果同一个group的消费者数目小于分区数目，则有部分消费者需要额外承担消费任务。\n* 在某个消费者故障或者重启等情况下，其他消费者会感知到这一变化（通过 zookeeper watch消费者列表），然后重新进行负载均衡，保证所有的分区都有消费者进行消费。\n\n## 命名服务(Naming Service)\n命名服务也是分布式系统中比较常见的一类场景。在分布式系统中，通过使用命名服务，客户端应用能够根据指定名字来获取资源或服务的地址，提供者等信息。被命名的实体通常可以是集群中的机器，提供的服务地址，远程对象等等——这些我们都可以统称他们为名字（Name）。其中较为常见的就是一些分布式服务框架中的服务地址列表。通过调用ZK提供的创建节点的API，能够很容易创建一个全局唯一的path，这个path就可以作为一个名称。\n阿里巴巴集团开源的分布式服务框架Dubbo中使用ZooKeeper来作为其命名服务，维护全局的服务地址列表， 点击这里查看Dubbo开源项目。在Dubbo实现中：\n\n>服务提供者在启动的时候，向ZK上的指定节点/dubbo/${serviceName}/providers目录下写入自己的URL地址，这个操作就完成了服务的发布。\n服务消费者启动的时候，订阅/dubbo/${serviceName}/providers目录下的提供者URL地址， 并向/dubbo/${serviceName} /consumers目录下写入自己的URL地址。\n注意，所有向ZK上注册的地址都是临时节点，这样就能够保证服务提供者和消费者能够自动感应资源的变化。\n另外，Dubbo还有针对服务粒度的监控，方法是订阅/dubbo/${serviceName}目录下所有提供者和消费者的信息。\n\n## 分布式通知/协调\nZooKeeper中特有watcher注册与异步通知机制，能够很好的实现分布式环境下不同系统之间的通知与协调，实现对数据变更的实时处理。使用方法通常是不同系统都对ZK上同一个znode进行注册，监听znode的变化（包括znode本身内容及子节点的），其中一个系统update了znode，那么另一个系统能够收到通知，并作出相应处理\n另一种心跳检测机制：检测系统和被检测系统之间并不直接关联起来，而是通过zk上某个节点关联，大大减少系统耦合。\n另一种系统调度模式：某系统有控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台作的一些操作，实际上是修改了ZK上某些节点的状态，而ZK就把这些变化通知给他们注册Watcher的客户端，即推送系统，于是，作出相应的推送任务。\n另一种工作汇报模式：一些类似于任务分发系统，子任务启动后，到zk来注册一个临时节点，并且定时将自己的进度进行汇报（将进度写回这个临时节点），这样任务管理者就能够实时知道任务进度。\n总之，使用zookeeper来进行分布式通知和协调能够大大降低系统之间的耦合\n\n## 集群管理\n集群机器监控通常用于那种对集群中机器状态，机器在线率有较高要求的场景，能够快速对集群中机器变化作出响应。这样的场景中，往往有一个监控系统，实时检测集群机器是否存活。过去的做法通常是：监控系统通过某种手段（比如ping）定时检测每个机器，或者每个机器自己定时向监控系统汇报“我还活着”。 这种做法可行，但是存在两个比较明显的问题：\n\n* 集群中机器有变动的时候，牵连修改的东西比较多。\n* 有一定的延时。\n\n利用ZooKeeper的两个特性，就可以实时另一种集群机器存活性监控系统：\n\n>客户端在节点x上注册一个Watcher，那么如果x的子节点变化了，会通知该客户端。\n创建EPHEMERAL类型的节点，一旦客户端和服务器的会话结束或过期，那么该节点就会消失。\n例如，监控系统在 /clusterServers 节点上注册一个Watcher，以后每动态加机器，那么就往 /clusterServers 下创建一个 EPHEMERAL类型的节点：/clusterServers/{hostname}. 这样，监控系统就能够实时知道机器的增减情况，至于后续处理就是监控系统的业务了。\n\n## Master选举\nMaster选举是zookeeper中最为经典的应用场景了。在分布式环境中，相同的业务应用分布在不同的机器上，有些业务逻辑（例如一些耗时的计算，网络I/O处理），往往只需要让整个集群中的某一台机器进行执行，其余机器可以共享这个结果，这样可以大大减少重复劳动，提高性能，于是这个master选举便是这种场景下的碰到的主要问题。\n\n利用ZooKeeper的强一致性，能够保证在分布式高并发情况下节点创建的全局唯一性，即：同时有多个客户端请求创建 /currentMaster 节点，最终一定只有一个客户端请求能够创建成功。利用这个特性，就能很轻易的在分布式环境中进行集群选取了。\n\n另外，这种场景演化一下，就是动态Master选举。这就要用到?EPHEMERAL_SEQUENTIAL类型节点的特性了。\n\n上文中提到，所有客户端创建请求，最终只有一个能够创建成功。在这里稍微变化下，就是允许所有请求都能够创建成功，但是得有个创建顺序，于是所有的请求最终在ZK上创建结果的一种可能情况是这样： /currentMaster/{sessionId}-1 ,?/currentMaster/{sessionId}-2 ,?/currentMaster/{sessionId}-3 ….. 每次选取序列号最小的那个机器作为Master，如果这个机器挂了，由于他创建的节点会马上小时，那么之后最小的那个机器就是Master了。\n\n在搜索系统中，如果集群中每个机器都生成一份全量索引，不仅耗时，而且不能保证彼此之间索引数据一致。因此让集群中的Master来进行全量索引的生成，然后同步到集群中其它机器。另外，Master选举的容灾措施是，可以随时进行手动指定master，就是说应用在zk在无法获取master信息时，可以通过比如http方式，向一个地方获取master。\n在Hbase中，也是使用ZooKeeper来实现动态HMaster的选举。在Hbase实现中，会在ZK上存储一些ROOT表的地址和HMaster的地址，HRegionServer也会把自己以临时节点（Ephemeral）的方式注册到Zookeeper中，使得HMaster可以随时感知到各个HRegionServer的存活状态，同时，一旦HMaster出现问题，会重新选举出一个HMaster来运行，从而避免了HMaster的单点问题。\n\n## 分布式锁\n分布式锁，这个主要得益于ZooKeeper为我们保证了数据的强一致性。锁服务可以分为两类，一个是 保持独占，另一个是 控制时序。\n所谓保持独占，就是所有试图来获取这个锁的客户端，最终只有一个可以成功获得这把锁。通常的做法是把zk上的一个znode看作是一把锁，通过create znode的方式来实现。所有客户端都去创建 /distribute_lock 节点，最终成功创建的那个客户端也即拥有了这把锁。\n控制时序，就是所有视图来获取这个锁的客户端，最终都是会被安排执行，只是有个全局时序了。做法和上面基本类似，只是这里 /distribute_lock 已经预先存在，客户端在它下面创建临时有序节点（这个可以通过节点的属性控制：CreateMode.EPHEMERAL_SEQUENTIAL来指定）。Zk的父节点（/distribute_lock）维持一份sequence,保证子节点创建的时序性，从而也形成了每个客户端的全局时序。\n\n## 分布式队列\n队列方面，简单地讲有两种，一种是常规的先进先出队列，另一种是要等到队列成员聚齐之后的才统一按序执行。对于第一种先进先出队列，和分布式锁服务中的控制时序场景基本原理一致，这里不再赘述。\n第二种队列其实是在FIFO队列的基础上作了一个增强。通常可以在 /queue 这个znode下预先建立一个/queue/num 节点，并且赋值为n（或者直接给/queue赋值n），表示队列大小，之后每次有队列成员加入后，就判断下是否已经到达队列大小，决定是否可以开始执行了。这种用法的典型场景是，分布式环境中，一个大任务Task A，需要在很多子任务完成（或条件就绪）情况下才能进行。这个时候，凡是其中一个子任务完成（就绪），那么就去 /taskList 下建立自己的临时时序节点（CreateMode.EPHEMERAL_SEQUENTIAL），当 /taskList 发现自己下面的子节点满足指定个数，就可以进行下一步按序进行处理了。\n\n# 声明\n本文非原创，原文链接：[http://itindex.net/detail/53886-zookeeper](http://itindex.net/detail/53886-zookeeper)，尊重原创，转载请注明出处。\n","slug":"ZooKeeper使用场景","published":1,"updated":"2015-10-10T04:54:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovch0042lo6bi0qw2k9e"},{"title":"UTF8编码","date":"2015-09-07T16:07:17.000Z","_content":"# 编码\n大家都知道，计算机中的数据都是以二进制的形式保存的，所以如果需要在计算机中存储或者在网络上传输一些字符的话，就需要用某种规则将这些字符编排成一串串的二进制数据，就像011010101011110101101这样，这个编排的过程就叫做“字符编码”。\n\n<!--more-->\n# Unicode编码\nUnicode出现之前，各个国家或地区都有自己的编码方式，非常混乱，这极大地阻碍了网络信息在全世界范围内的传播与交流。所以有有一个叫ISO的牛逼组织做了一个伟大的创想：**统一天下编码方式，让信息传播归一化。**这个创想的结果就是制定了Unicode编码规则。\n\nUnicode 是为了解决传统的字符编码方案的局限而产生的，例如ISO 8859所定义的字符虽然在不同的国家中广泛地使用，可是在不同国家间却经常出现不兼容的情况。很多传统的编码方式都有一个共同的问题，即容许电脑处理双语环境（通常使用拉丁字母以及其本地语言），但却无法同时支持多语言环境（指可同时处理多种语言混合的情况）。\n\nUnicode可以容纳世界上所有的文字和字符。Unicode目有两套编码方法,UCS-2(Unicode-16)用2个字节表示一个字符,UCS-4(Unicode-32)用4个字节表示一个字符。UCS-4是由USC-2扩展来的,增加了2字节的高位。即使是老UCS-2,它也可以表示2^16=65535个字符,基本上可以容纳所有常用各国字符,所以目前基本都使用UCS-2。\n\n# UTF8编码\nUnicode使用2个字节表示一个字符，ASCII码使用1个字节，所以在很多方面产生了冲突，以前处理ASCII的方法都必须重写。而且C语言用\\0作为字符串结束标志,但Unicode中很多字符都含\\0,C语言的字符串函数也无法正常处理Unicode。为了把unicode投入实用,出现了UTF,最常见的是UTF-8和UTF-16。\n其中UTF-16和Unicode本身的编码是一致的，都是使用两个字节编码字符，但是因为ASCII本身只需要一个字节，这就会造成空间的浪费。UTF-32和UCS-4也是相同的。\n\n主角该出场了：UTF8是一种变长的编码，它的字节数是不固定的,使用第一个字节确定字节数。第一个字节首为0即一个字节，110即2字节，1110即3字节，字符后续字节都用10开始，这样不会混淆且单字节英文字符可仍用ASCII编码。理论上UTF-8最大可以用6字节表示一个字符，但Unicode目前没有用大于0xffff的字符，实际UTF-8最多使用了3个字节。Unicode到UTF8的转换规则如下表：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/UTF8编码/utf8.png)\n\n举个栗子：\n\n'强'字的unicode编码为：`5F3A`，我们对照上表将其转换成UTF8编码：\n\n1. 5F3A在区间[0800,07FF]，所以转换成UTF8之后应该是3个字节。\n2. 5F3A写成二进制形式是：0101 1111 0011 1010。\n3. 按照UTF8的模板依次从高位取4/6/6位二进制数填入模板，得到11100101 10111100 10111010。\n4. 转成16进制之后得到: E5 BC BA，这就是'强'字的UTF8编码。\n5. Java程序验证一把，程序如下：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/6 23:37\n */\npublic class TestEncode {\n    public static void main(String[] args) throws Exception {\n        byte[] utf8s = \"强\".getBytes(\"utf-8\");\n        System.out.println(\"编码字节数：\" + utf8s.length);\n        System.out.print(\"编码结果：\");\n        for (int i = 0; i < utf8s.length; i++) {\n            System.out.print(String.format(\"%x\", utf8s[i]));\n        }\n        System.out.println();\n    }\n}\n\n```\n\n程序输出结果为：\n> \n编码字节数：3  \n编码结果：e5bcba\n\n\n可见，整个编码过程就是这样的，没错！\n","source":"_posts/UTF8编码.md","raw":"title: UTF8编码\ntags: [编码]\ncategories: [编码]\ndate: 2015-09-08 00:07:17\n---\n# 编码\n大家都知道，计算机中的数据都是以二进制的形式保存的，所以如果需要在计算机中存储或者在网络上传输一些字符的话，就需要用某种规则将这些字符编排成一串串的二进制数据，就像011010101011110101101这样，这个编排的过程就叫做“字符编码”。\n\n<!--more-->\n# Unicode编码\nUnicode出现之前，各个国家或地区都有自己的编码方式，非常混乱，这极大地阻碍了网络信息在全世界范围内的传播与交流。所以有有一个叫ISO的牛逼组织做了一个伟大的创想：**统一天下编码方式，让信息传播归一化。**这个创想的结果就是制定了Unicode编码规则。\n\nUnicode 是为了解决传统的字符编码方案的局限而产生的，例如ISO 8859所定义的字符虽然在不同的国家中广泛地使用，可是在不同国家间却经常出现不兼容的情况。很多传统的编码方式都有一个共同的问题，即容许电脑处理双语环境（通常使用拉丁字母以及其本地语言），但却无法同时支持多语言环境（指可同时处理多种语言混合的情况）。\n\nUnicode可以容纳世界上所有的文字和字符。Unicode目有两套编码方法,UCS-2(Unicode-16)用2个字节表示一个字符,UCS-4(Unicode-32)用4个字节表示一个字符。UCS-4是由USC-2扩展来的,增加了2字节的高位。即使是老UCS-2,它也可以表示2^16=65535个字符,基本上可以容纳所有常用各国字符,所以目前基本都使用UCS-2。\n\n# UTF8编码\nUnicode使用2个字节表示一个字符，ASCII码使用1个字节，所以在很多方面产生了冲突，以前处理ASCII的方法都必须重写。而且C语言用\\0作为字符串结束标志,但Unicode中很多字符都含\\0,C语言的字符串函数也无法正常处理Unicode。为了把unicode投入实用,出现了UTF,最常见的是UTF-8和UTF-16。\n其中UTF-16和Unicode本身的编码是一致的，都是使用两个字节编码字符，但是因为ASCII本身只需要一个字节，这就会造成空间的浪费。UTF-32和UCS-4也是相同的。\n\n主角该出场了：UTF8是一种变长的编码，它的字节数是不固定的,使用第一个字节确定字节数。第一个字节首为0即一个字节，110即2字节，1110即3字节，字符后续字节都用10开始，这样不会混淆且单字节英文字符可仍用ASCII编码。理论上UTF-8最大可以用6字节表示一个字符，但Unicode目前没有用大于0xffff的字符，实际UTF-8最多使用了3个字节。Unicode到UTF8的转换规则如下表：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/UTF8编码/utf8.png)\n\n举个栗子：\n\n'强'字的unicode编码为：`5F3A`，我们对照上表将其转换成UTF8编码：\n\n1. 5F3A在区间[0800,07FF]，所以转换成UTF8之后应该是3个字节。\n2. 5F3A写成二进制形式是：0101 1111 0011 1010。\n3. 按照UTF8的模板依次从高位取4/6/6位二进制数填入模板，得到11100101 10111100 10111010。\n4. 转成16进制之后得到: E5 BC BA，这就是'强'字的UTF8编码。\n5. Java程序验证一把，程序如下：\n\n```\npackage com.winwill.test;\n\n/**\n * @author qifuguang\n * @date 15/9/6 23:37\n */\npublic class TestEncode {\n    public static void main(String[] args) throws Exception {\n        byte[] utf8s = \"强\".getBytes(\"utf-8\");\n        System.out.println(\"编码字节数：\" + utf8s.length);\n        System.out.print(\"编码结果：\");\n        for (int i = 0; i < utf8s.length; i++) {\n            System.out.print(String.format(\"%x\", utf8s[i]));\n        }\n        System.out.println();\n    }\n}\n\n```\n\n程序输出结果为：\n> \n编码字节数：3  \n编码结果：e5bcba\n\n\n可见，整个编码过程就是这样的，没错！\n","slug":"UTF8编码","published":1,"updated":"2015-10-13T06:01:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovck0047lo6bmsqctfhn"},{"title":"Thrift入门教程","date":"2015-09-11T08:42:30.000Z","_content":"# 概述\nThrift最初由Facebook研发，主要用于各个服务之间的RPC通信，支持跨语言，常用的语言比如C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml都支持。Thrift是一个典型的CS（客户端/服务端）结构，客户端和服务端可以使用不同的语言开发。既然客户端和服务端能使用不同的语言开发，那么一定就要有一种中间语言来关联客户端和服务端的语言，没错，这种语言就是IDL（Interface Description Language）。\n<!--more-->\n# Thrift IDL\n本节介绍Thrift的接口定义语言，Thrift IDL支持的数据类型包含：\n\n## 基本类型\n\nthrift不支持无符号类型，因为很多编程语言不存在无符号类型，比如java\n   \n   * byte: 有符号字节\n   * i16: 16位有符号整数\n   * i32: 32位有符号整数\n   * i64: 64位有符号整数\n   * double: 64位浮点数\n   * string: 字符串  \n\n## 容器类型\n\n集合中的元素可以是除了service之外的任何类型，包括exception。\n   \n   * list<T>: 一系列由T类型的数据组成的有序列表，元素可以重复\n   * set<T>:  一系列由T类型的数据组成的无序集合，元素不可重复\n   * map<K, V>: 一个字典结构，key为K类型，value为V类型，相当于Java中的HMap<K,V>  \n   \n## 结构体(struct) \n   \n就像C语言一样，thrift也支持struct类型，目的就是将一些数据聚合在一起，方便传输管理。struct的定       义形式如下：  \n \n```\nstruct People {\n     1: string name;\n     2: i32 age;\n     3: string sex;\n}\n```\n   \n## 枚举(enum)  \n\n枚举的定义形式和Java的Enum定义差不多，例如：\n   \n``` \nenum Sex {\n    MALE,\n    FEMALE\n}\n```\n   \n## 异常(exception)    \n\nthrift支持自定义exception，规则和struct一样，如下：\n   \n```\nexception RequestException {\n    1: i32 code;\n    2: string reason;\n}\n```\n   \n## 服务(service)  \n\nthrift定义服务相当于Java中创建Interface一样，创建的service经过代码生成命令之后就会生成客户端和服务端的框架代码。定义形式如下：\n   \n```\nservice HelloWordService {\n     // service中定义的函数，相当于Java interface中定义的函数\n     string doAction(1: string name, 2: i32 age);\n }\n```\n   \n## 类型定义  \n\nthrift支持类似C++一样的typedef定义，比如：\n\n```\ntypedef i32 Integer\ntypedef i64 Long\n```\n**注意，末尾没有逗号或者分号**\n\n## 常量(const) \n \nthrift也支持常量定义，使用const关键字，例如：\n    \n```\nconst i32 MAX_RETRIES_TIME = 10\nconst string MY_WEBSITE = \"http://qifuguang.me\";\n```\n \n**末尾的分号是可选的，可有可无，并且支持16进制赋值**\n\n## 命名空间\n\nthrift的命名空间相当于Java中的package的意思，主要目的是组织代码。thrift使用关键字namespace定义命名空间，例如：\n    \n```\nnamespace java com.winwill.thrift\n```\n\n**格式是：namespace 语言名 路径， 注意末尾不能有分号。**\n\n## 文件包含\n\nthrift也支持文件包含，相当于C/C++中的include，Java中的import。使用关键字include定义，例 如：\n    \n```\ninclude \"global.thrift\"\n```\n\n## 注释\n\nthrift注释方式支持shell风格的注释，支持C/C++风格的注释，即#和//开头的语句都单当做注释，/**/包裹的语句也是注释。\n    \n## 可选与必选\n\nthrift提供两个关键字required，optional，分别用于表示对应的字段时必填的还是可选的。例如：\n    \n```\nstruct People {\n    1: required string name;\n    2: optional i32 age;\n}\n```\n\n表示name是必填的，age是可选的。\n    \n# 生成代码\n 知道了怎么定义thirtf文件之后，我们需要用定义好的thrift文件生成我们需要的目标语言的源码，本文以生成java源码为例。假设现在定义了如下一个thrift文件：\n \n ```\nnamespace java com.winwill.thrift\n \nenum RequestType {\n    SAY_HELLO,   //问好\n    QUERY_TIME,  //询问时间\n}\n\nstruct Request {\n    1: required RequestType type;  // 请求的类型，必选\n    2: required string name;       // 发起请求的人的名字，必选\n    3: optional i32 age;           // 发起请求的人的年龄，可选\n}\n\nexception RequestException {\n    1: required i32 code;\n    2: optional string reason;\n}\n\n// 服务名\nservice HelloWordService {\n    string doAction(1: Request request) throws (1:RequestException qe); // 可能抛出异常。\n}\n ```\n \n 在终端运行如下命令(前提是已经安装thrift)：\n \n ```\n thrift --gen java Test.thrift\n ```\n 则在当前目录会生成一个gen-java目录，该目录下会按照namespace定义的路径名一次一层层生成文件夹，到gen-java/com/winwill/thrift/目录下可以看到生成的4个Java类：\n ![目录结构](http://7xlune.com1.z0.glb.clouddn.com/images/Thrift入门教程/thrift-gen-java.png)\n 可以看到，thrift文件中定义的enum，struct，exception，service都相应地生成了一个Java类，这就是能支持Java语言的基本的框架代码。\n \n# 服务端实现\n上面代码生成这一步已经将接口代码生成了，现在需要做的是实现HelloWordService的具体逻辑，实现的方式就是创建一个Java类，implements com.winwill.thrift.HelloWordService，例如：\n\n```\npackage com.winwill.thrift;\n\n\nimport org.apache.commons.lang3.StringUtils;\nimport org.apache.thrift.TException;\n\nimport java.util.Date;\n\n/**\n * @author qifuguang\n * @date 15/9/11 15:53\n */\npublic class HelloWordServiceImpl implements com.winwill.thrift.HelloWordService.Iface {\n    // 实现这个方法完成具体的逻辑。\n    public String doAction(com.winwill.thrift.Request request) throws com.winwill.thrift.RequestException, TException {\n        System.out.println(\"Get request: \" + request);\n        if (StringUtils.isBlank(request.getName()) || request.getType() == null) {\n            throw new com.winwill.thrift.RequestException();\n        }\n        String result = \"Hello, \" + request.getName();\n        if (request.getType() == com.winwill.thrift.RequestType.SAY_HELLO) {\n            result += \", Welcome!\";\n        } else {\n            result += \", Now is \" + new Date().toLocaleString();\n        }\n        return result;\n    }\n}\n\n```\n\n# 启动服务\n上面这个就是服务端的具体实现类，现在需要启动这个服务，所以需要一个启动类，启动类的代码如下：\n\n```\npackage com.winwill.thrift;\n\nimport org.apache.thrift.server.TServer;\nimport org.apache.thrift.server.TSimpleServer;\nimport org.apache.thrift.transport.TServerSocket;\n\nimport java.net.ServerSocket;\n\n/**\n * @author qifuguang\n * @date 15/9/11 16:07\n */\npublic class HelloWordServer {\n    public static void main(String[] args) throws Exception {\n        ServerSocket socket = new ServerSocket(7912);\n        TServerSocket serverTransport = new TServerSocket(socket);\n        com.winwill.thrift.HelloWordService.Processor processor = new com.winwill.thrift.HelloWordService.Processor(new HelloWordServiceImpl());\n        TServer server = new TSimpleServer(processor, serverTransport);\n        System.out.println(\"Running server...\");\n        server.serve();\n    }\n}\n\n```\n运行之后看到控制台的输出为：\n>Running server...\n\n# 客户端请求\n现在服务已经启动，可以通过客户端向服务端发送请求了，客户端的代码如下：\n\n```\npackage com.winwill.thrift;\n\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.protocol.TProtocol;\nimport org.apache.thrift.transport.TSocket;\nimport org.apache.thrift.transport.TTransport;\n\n/**\n * @author qifuguang\n * @date 15/9/11 16:13\n */\npublic class HelloWordClient {\n    public static void main(String[] args) throws Exception {\n        TTransport transport = new TSocket(\"localhost\", 8888);\n        TProtocol protocol = new TBinaryProtocol(transport);\n\n        // 创建client\n        com.winwill.thrift.HelloWordService.Client client = new com.winwill.thrift.HelloWordService.Client(protocol);\n\n        transport.open();  // 建立连接\n\n        // 第一种请求类型\n        com.winwill.thrift.Request request = new com.winwill.thrift.Request()\n                .setType(com.winwill.thrift.RequestType.SAY_HELLO).setName(\"winwill2012\").setAge(24);\n        System.out.println(client.doAction(request));\n\n        // 第二种请求类型\n        request.setType(com.winwill.thrift.RequestType.QUERY_TIME).setName(\"winwill2012\");\n        System.out.println(client.doAction(request));\n\n        transport.close();  // 请求结束，断开连接\n    }\n}\n```\n运行客户端代码，得到结果：\n> Hello, winwill2012, Welcome!  \nHello, winwill2012, Now is 2015-9-11 16:37:22\n\n并且此时，服务端会有请求日志：\n> Running server...  \nGet request: Request(type:SAY_HELLO, name:winwill2012, age:24)  \nGet request: Request(type:QUERY_TIME, name:winwill2012, age:24)  \n\n可以看到，客户端成功将请求发到了服务端，服务端成功地将请求结果返回给客户端，整个通信过程完成。\n\n\n# 注意事项\n* 本文为作者个人理解，如理解有误，请留言相告，感激不尽；\n* 本文为作者原创，转载请注明出处，原文地址：[http://qifuguang.me/2015/09/11/Thrift入门教程/](http://qifuguang.me/2015/09/11/Thrift入门教程/)\n\n","source":"_posts/Thrift入门教程.md","raw":"title: Thrift入门教程\ntags: [thrift]\ncategories: [thrift]\ndate: 2015-09-11 16:42:30\n---\n# 概述\nThrift最初由Facebook研发，主要用于各个服务之间的RPC通信，支持跨语言，常用的语言比如C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, and OCaml都支持。Thrift是一个典型的CS（客户端/服务端）结构，客户端和服务端可以使用不同的语言开发。既然客户端和服务端能使用不同的语言开发，那么一定就要有一种中间语言来关联客户端和服务端的语言，没错，这种语言就是IDL（Interface Description Language）。\n<!--more-->\n# Thrift IDL\n本节介绍Thrift的接口定义语言，Thrift IDL支持的数据类型包含：\n\n## 基本类型\n\nthrift不支持无符号类型，因为很多编程语言不存在无符号类型，比如java\n   \n   * byte: 有符号字节\n   * i16: 16位有符号整数\n   * i32: 32位有符号整数\n   * i64: 64位有符号整数\n   * double: 64位浮点数\n   * string: 字符串  \n\n## 容器类型\n\n集合中的元素可以是除了service之外的任何类型，包括exception。\n   \n   * list<T>: 一系列由T类型的数据组成的有序列表，元素可以重复\n   * set<T>:  一系列由T类型的数据组成的无序集合，元素不可重复\n   * map<K, V>: 一个字典结构，key为K类型，value为V类型，相当于Java中的HMap<K,V>  \n   \n## 结构体(struct) \n   \n就像C语言一样，thrift也支持struct类型，目的就是将一些数据聚合在一起，方便传输管理。struct的定       义形式如下：  \n \n```\nstruct People {\n     1: string name;\n     2: i32 age;\n     3: string sex;\n}\n```\n   \n## 枚举(enum)  \n\n枚举的定义形式和Java的Enum定义差不多，例如：\n   \n``` \nenum Sex {\n    MALE,\n    FEMALE\n}\n```\n   \n## 异常(exception)    \n\nthrift支持自定义exception，规则和struct一样，如下：\n   \n```\nexception RequestException {\n    1: i32 code;\n    2: string reason;\n}\n```\n   \n## 服务(service)  \n\nthrift定义服务相当于Java中创建Interface一样，创建的service经过代码生成命令之后就会生成客户端和服务端的框架代码。定义形式如下：\n   \n```\nservice HelloWordService {\n     // service中定义的函数，相当于Java interface中定义的函数\n     string doAction(1: string name, 2: i32 age);\n }\n```\n   \n## 类型定义  \n\nthrift支持类似C++一样的typedef定义，比如：\n\n```\ntypedef i32 Integer\ntypedef i64 Long\n```\n**注意，末尾没有逗号或者分号**\n\n## 常量(const) \n \nthrift也支持常量定义，使用const关键字，例如：\n    \n```\nconst i32 MAX_RETRIES_TIME = 10\nconst string MY_WEBSITE = \"http://qifuguang.me\";\n```\n \n**末尾的分号是可选的，可有可无，并且支持16进制赋值**\n\n## 命名空间\n\nthrift的命名空间相当于Java中的package的意思，主要目的是组织代码。thrift使用关键字namespace定义命名空间，例如：\n    \n```\nnamespace java com.winwill.thrift\n```\n\n**格式是：namespace 语言名 路径， 注意末尾不能有分号。**\n\n## 文件包含\n\nthrift也支持文件包含，相当于C/C++中的include，Java中的import。使用关键字include定义，例 如：\n    \n```\ninclude \"global.thrift\"\n```\n\n## 注释\n\nthrift注释方式支持shell风格的注释，支持C/C++风格的注释，即#和//开头的语句都单当做注释，/**/包裹的语句也是注释。\n    \n## 可选与必选\n\nthrift提供两个关键字required，optional，分别用于表示对应的字段时必填的还是可选的。例如：\n    \n```\nstruct People {\n    1: required string name;\n    2: optional i32 age;\n}\n```\n\n表示name是必填的，age是可选的。\n    \n# 生成代码\n 知道了怎么定义thirtf文件之后，我们需要用定义好的thrift文件生成我们需要的目标语言的源码，本文以生成java源码为例。假设现在定义了如下一个thrift文件：\n \n ```\nnamespace java com.winwill.thrift\n \nenum RequestType {\n    SAY_HELLO,   //问好\n    QUERY_TIME,  //询问时间\n}\n\nstruct Request {\n    1: required RequestType type;  // 请求的类型，必选\n    2: required string name;       // 发起请求的人的名字，必选\n    3: optional i32 age;           // 发起请求的人的年龄，可选\n}\n\nexception RequestException {\n    1: required i32 code;\n    2: optional string reason;\n}\n\n// 服务名\nservice HelloWordService {\n    string doAction(1: Request request) throws (1:RequestException qe); // 可能抛出异常。\n}\n ```\n \n 在终端运行如下命令(前提是已经安装thrift)：\n \n ```\n thrift --gen java Test.thrift\n ```\n 则在当前目录会生成一个gen-java目录，该目录下会按照namespace定义的路径名一次一层层生成文件夹，到gen-java/com/winwill/thrift/目录下可以看到生成的4个Java类：\n ![目录结构](http://7xlune.com1.z0.glb.clouddn.com/images/Thrift入门教程/thrift-gen-java.png)\n 可以看到，thrift文件中定义的enum，struct，exception，service都相应地生成了一个Java类，这就是能支持Java语言的基本的框架代码。\n \n# 服务端实现\n上面代码生成这一步已经将接口代码生成了，现在需要做的是实现HelloWordService的具体逻辑，实现的方式就是创建一个Java类，implements com.winwill.thrift.HelloWordService，例如：\n\n```\npackage com.winwill.thrift;\n\n\nimport org.apache.commons.lang3.StringUtils;\nimport org.apache.thrift.TException;\n\nimport java.util.Date;\n\n/**\n * @author qifuguang\n * @date 15/9/11 15:53\n */\npublic class HelloWordServiceImpl implements com.winwill.thrift.HelloWordService.Iface {\n    // 实现这个方法完成具体的逻辑。\n    public String doAction(com.winwill.thrift.Request request) throws com.winwill.thrift.RequestException, TException {\n        System.out.println(\"Get request: \" + request);\n        if (StringUtils.isBlank(request.getName()) || request.getType() == null) {\n            throw new com.winwill.thrift.RequestException();\n        }\n        String result = \"Hello, \" + request.getName();\n        if (request.getType() == com.winwill.thrift.RequestType.SAY_HELLO) {\n            result += \", Welcome!\";\n        } else {\n            result += \", Now is \" + new Date().toLocaleString();\n        }\n        return result;\n    }\n}\n\n```\n\n# 启动服务\n上面这个就是服务端的具体实现类，现在需要启动这个服务，所以需要一个启动类，启动类的代码如下：\n\n```\npackage com.winwill.thrift;\n\nimport org.apache.thrift.server.TServer;\nimport org.apache.thrift.server.TSimpleServer;\nimport org.apache.thrift.transport.TServerSocket;\n\nimport java.net.ServerSocket;\n\n/**\n * @author qifuguang\n * @date 15/9/11 16:07\n */\npublic class HelloWordServer {\n    public static void main(String[] args) throws Exception {\n        ServerSocket socket = new ServerSocket(7912);\n        TServerSocket serverTransport = new TServerSocket(socket);\n        com.winwill.thrift.HelloWordService.Processor processor = new com.winwill.thrift.HelloWordService.Processor(new HelloWordServiceImpl());\n        TServer server = new TSimpleServer(processor, serverTransport);\n        System.out.println(\"Running server...\");\n        server.serve();\n    }\n}\n\n```\n运行之后看到控制台的输出为：\n>Running server...\n\n# 客户端请求\n现在服务已经启动，可以通过客户端向服务端发送请求了，客户端的代码如下：\n\n```\npackage com.winwill.thrift;\n\nimport org.apache.thrift.protocol.TBinaryProtocol;\nimport org.apache.thrift.protocol.TProtocol;\nimport org.apache.thrift.transport.TSocket;\nimport org.apache.thrift.transport.TTransport;\n\n/**\n * @author qifuguang\n * @date 15/9/11 16:13\n */\npublic class HelloWordClient {\n    public static void main(String[] args) throws Exception {\n        TTransport transport = new TSocket(\"localhost\", 8888);\n        TProtocol protocol = new TBinaryProtocol(transport);\n\n        // 创建client\n        com.winwill.thrift.HelloWordService.Client client = new com.winwill.thrift.HelloWordService.Client(protocol);\n\n        transport.open();  // 建立连接\n\n        // 第一种请求类型\n        com.winwill.thrift.Request request = new com.winwill.thrift.Request()\n                .setType(com.winwill.thrift.RequestType.SAY_HELLO).setName(\"winwill2012\").setAge(24);\n        System.out.println(client.doAction(request));\n\n        // 第二种请求类型\n        request.setType(com.winwill.thrift.RequestType.QUERY_TIME).setName(\"winwill2012\");\n        System.out.println(client.doAction(request));\n\n        transport.close();  // 请求结束，断开连接\n    }\n}\n```\n运行客户端代码，得到结果：\n> Hello, winwill2012, Welcome!  \nHello, winwill2012, Now is 2015-9-11 16:37:22\n\n并且此时，服务端会有请求日志：\n> Running server...  \nGet request: Request(type:SAY_HELLO, name:winwill2012, age:24)  \nGet request: Request(type:QUERY_TIME, name:winwill2012, age:24)  \n\n可以看到，客户端成功将请求发到了服务端，服务端成功地将请求结果返回给客户端，整个通信过程完成。\n\n\n# 注意事项\n* 本文为作者个人理解，如理解有误，请留言相告，感激不尽；\n* 本文为作者原创，转载请注明出处，原文地址：[http://qifuguang.me/2015/09/11/Thrift入门教程/](http://qifuguang.me/2015/09/11/Thrift入门教程/)\n\n","slug":"Thrift入门教程","published":1,"updated":"2015-10-13T06:04:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovcm004clo6bqdw585rt"},{"title":"Shell特殊字符简介","date":"2015-09-22T16:07:02.000Z","_content":"# 概述\nlinux shell中有很多特殊的字符，本文简单介绍常用的特殊字符的含义：\n<!--more-->\n* **$0** 表示当前运行的脚本的名字\n* **$#** 表示当前运行的脚本的参数个数\n* **$\\*** 表示当前运行的脚本的参数列表，如果有三个参数：a b c，则$*为 \"a b c\"\n* **$@** 表示当前运行的脚本的参数列表，如果有三个参数：a b c，则$@为 \"a\" \"b\" \"c\"，可以理解为参数数组\n* **$$** 当前运行的脚本的PID\n* **$n** n为一个整数(1 <= n <= 脚本参数个数)，表示当前脚本接收到的第n个参数\n* **$?** 表示目前为止执行的最后一条命令的返回值，返回0表示成功，返回1表示失败\n* **$-** 表示当前shell的设置选项\n\n# 代码演示\n如下是一个简单的脚本test.sh，用于演示上面提到的各种特殊字符的效果：\n\n```\n#!/bin/bash\necho \"脚本名字:\"$0\necho \"脚本参数:\"$*\necho \"脚本参数:\"$@\necho \"脚本参数个数:\"$#\necho \"脚本第一个参数:\"$1\necho \"脚本第二个参数:\"$2\necho \"本脚本运行PID:\"$$\necho \"当前shell选项:\"$-\necho \"test text\" | grep \"test\" 1>/dev/null\necho \"上一条命令执行结果:\"$?\n```\n\n使用如下命令运行上面的脚本：\n\n```\n[qifuguang@Mac~/shell]$ ./test.sh a b c\n```\n\n输出如下：\n\n>脚本名字:./test.sh  \n脚本参数:a b c  \n脚本参数:a b c  \n脚本参数个数:3  \n脚本第一个参数:a  \n脚本第二个参数:b  \n本脚本运行PID:37073  \n当前shell选项:hB  \n上一条命令执行结果:0  \n\n# 声明\n本文原创，转载请注明出处，本文链接[http://qifuguang.me/2015/09/23/Shell特殊字符简介](http://qifuguang.me/2015/09/23/Shell特殊字符简介)\n","source":"_posts/Shell特殊字符简介.md","raw":"title: Shell特殊字符简介\ntags: [linux shell]\ncategories: [linux shell]\ndate: 2015-09-23 00:07:02\n---\n# 概述\nlinux shell中有很多特殊的字符，本文简单介绍常用的特殊字符的含义：\n<!--more-->\n* **$0** 表示当前运行的脚本的名字\n* **$#** 表示当前运行的脚本的参数个数\n* **$\\*** 表示当前运行的脚本的参数列表，如果有三个参数：a b c，则$*为 \"a b c\"\n* **$@** 表示当前运行的脚本的参数列表，如果有三个参数：a b c，则$@为 \"a\" \"b\" \"c\"，可以理解为参数数组\n* **$$** 当前运行的脚本的PID\n* **$n** n为一个整数(1 <= n <= 脚本参数个数)，表示当前脚本接收到的第n个参数\n* **$?** 表示目前为止执行的最后一条命令的返回值，返回0表示成功，返回1表示失败\n* **$-** 表示当前shell的设置选项\n\n# 代码演示\n如下是一个简单的脚本test.sh，用于演示上面提到的各种特殊字符的效果：\n\n```\n#!/bin/bash\necho \"脚本名字:\"$0\necho \"脚本参数:\"$*\necho \"脚本参数:\"$@\necho \"脚本参数个数:\"$#\necho \"脚本第一个参数:\"$1\necho \"脚本第二个参数:\"$2\necho \"本脚本运行PID:\"$$\necho \"当前shell选项:\"$-\necho \"test text\" | grep \"test\" 1>/dev/null\necho \"上一条命令执行结果:\"$?\n```\n\n使用如下命令运行上面的脚本：\n\n```\n[qifuguang@Mac~/shell]$ ./test.sh a b c\n```\n\n输出如下：\n\n>脚本名字:./test.sh  \n脚本参数:a b c  \n脚本参数:a b c  \n脚本参数个数:3  \n脚本第一个参数:a  \n脚本第二个参数:b  \n本脚本运行PID:37073  \n当前shell选项:hB  \n上一条命令执行结果:0  \n\n# 声明\n本文原创，转载请注明出处，本文链接[http://qifuguang.me/2015/09/23/Shell特殊字符简介](http://qifuguang.me/2015/09/23/Shell特殊字符简介)\n","slug":"Shell特殊字符简介","published":1,"updated":"2015-09-22T16:15:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovcp004hlo6bsbhggedq"},{"title":"Redis过期机制介绍","date":"2015-09-30T03:38:17.000Z","_content":"\n# 概述\n在实际开发过程中经常会遇到一些有时效性数据，比如限时优惠活动，缓存或者验证码之类的。过了一段时间就需要删除这些数据。在关系型数据库中一般都要增加一个字段记录数据的到期时间，然后周期性地检查过期数据然后删除。Redis本身就对键过期提供了很好的支持。\n\n<!--more-->\n# Redis过期机制\n在Redis中可以使用**EXPIRE**命令设置一个键的存活时间(ttl: time to live)，过了这段时间，该键就会自动被删除，EXPIRE命令的使用方法如下：\n\n```\nEXPIRE key ttl(单位秒)\n```\n命令返回1表示设置ttl成功，返回0表示键不存在或者设置失败。\n\n举个例子：\n\n```\n127.0.0.1:6379> set session 100\nOK\n127.0.0.1:6379> EXPIRE session 5\n(integer) 1\n127.0.0.1:6379> get session\n\"100\"\n127.0.0.1:6379> get session\n\"100\"\n127.0.0.1:6379> get session\n(nil)\n127.0.0.1:6379>\n```\n上例可见，先设置session的值为100，然后设置他的ttl为5s，之后连续几次使用get命令获取session，5s之后将获取不到session，因为ttl时间已到，session被删除。\n\n如果想知道一个键还有多长时间被删除，则可以使用**TTL**命令查看，使用方法如下：\n\n```\nTTL key\n```\n返回值是键的剩余时间，单位秒。\n\n比如：\n\n```\n127.0.0.1:6379> set session 100\nOK\n127.0.0.1:6379> EXPIRE session 10\n(integer) 1\n127.0.0.1:6379> TTL session\n(integer) 7\n127.0.0.1:6379> TTL session\n(integer) 5\n127.0.0.1:6379> TTL session\n(integer) 2\n127.0.0.1:6379> TTL session\n(integer) 0\n127.0.0.1:6379> TTL session\n(integer) -2\n127.0.0.1:6379> TTL session\n(integer) -2\n127.0.0.1:6379>\n```\n可见，TTL的返回值会随着时间的流逝慢慢减少，10s之后键会被删除，键不存在时TTL会返回-2，**当没有为键设置过期时间时，使用TTL获取键的剩余时间将会返回-1**，比如\n\n```\n127.0.0.1:6379> set url http://qifuguang.me\nOK\n127.0.0.1:6379> ttl url\n(integer) -1\n127.0.0.1:6379>\n```\n\n如果想取消某个键的过期时间，可以使用**PERSIST**命令，用法如下：\n\n```\nPERSIST key\n```\n\n清除成功返回1，失败返回0.\n\n例如：\n\n```\n127.0.0.1:6379> set title winwill2012\nOK\n127.0.0.1:6379> EXPIRE title 100\n(integer) 1\n127.0.0.1:6379> ttl title\n(integer) 97\n127.0.0.1:6379> PERSIST title\n(integer) 1\n127.0.0.1:6379> ttl title\n(integer) -1\n127.0.0.1:6379>\n```\n除了PERSIST命令会清除键的过期时间之外，SET,GETSET命令也能清除键的过期时间，但是只对键进行操作的命令（比如INCR,LPUSH等等）不会清除键的过期时间。\n\n**EXPIRE命令的单位是秒，如果想要更精确的过期时间，则可以使用PEXPIRE命令，该命令的单位是毫秒，相应地可以使用PTTL看剩余时间。**\n\n**如果[WATCH](http://qifuguang.me/2015/09/30/Redis%E4%BA%8B%E5%8A%A1%E4%BB%8B%E7%BB%8D/)命令监控了一个具有过期时间的键，如果监控期间这个键过期被自动删除，WATCH并不认为该键被改变**\n\n# Redis过期机制的用途\n有了过期机制就能实现很多跟时间相关的功能了，比如访问频率限制，作为缓存等等，具体细节就不展开了，有疑问的可以留言。\n\n# 声明\n本文原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/30/Redis过期机制介绍/](http://qifuguang.me/2015/09/30/Redis过期机制介绍/)\n","source":"_posts/Redis过期机制介绍.md","raw":"title: Redis过期机制介绍\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-09-30 11:38:17\n---\n\n# 概述\n在实际开发过程中经常会遇到一些有时效性数据，比如限时优惠活动，缓存或者验证码之类的。过了一段时间就需要删除这些数据。在关系型数据库中一般都要增加一个字段记录数据的到期时间，然后周期性地检查过期数据然后删除。Redis本身就对键过期提供了很好的支持。\n\n<!--more-->\n# Redis过期机制\n在Redis中可以使用**EXPIRE**命令设置一个键的存活时间(ttl: time to live)，过了这段时间，该键就会自动被删除，EXPIRE命令的使用方法如下：\n\n```\nEXPIRE key ttl(单位秒)\n```\n命令返回1表示设置ttl成功，返回0表示键不存在或者设置失败。\n\n举个例子：\n\n```\n127.0.0.1:6379> set session 100\nOK\n127.0.0.1:6379> EXPIRE session 5\n(integer) 1\n127.0.0.1:6379> get session\n\"100\"\n127.0.0.1:6379> get session\n\"100\"\n127.0.0.1:6379> get session\n(nil)\n127.0.0.1:6379>\n```\n上例可见，先设置session的值为100，然后设置他的ttl为5s，之后连续几次使用get命令获取session，5s之后将获取不到session，因为ttl时间已到，session被删除。\n\n如果想知道一个键还有多长时间被删除，则可以使用**TTL**命令查看，使用方法如下：\n\n```\nTTL key\n```\n返回值是键的剩余时间，单位秒。\n\n比如：\n\n```\n127.0.0.1:6379> set session 100\nOK\n127.0.0.1:6379> EXPIRE session 10\n(integer) 1\n127.0.0.1:6379> TTL session\n(integer) 7\n127.0.0.1:6379> TTL session\n(integer) 5\n127.0.0.1:6379> TTL session\n(integer) 2\n127.0.0.1:6379> TTL session\n(integer) 0\n127.0.0.1:6379> TTL session\n(integer) -2\n127.0.0.1:6379> TTL session\n(integer) -2\n127.0.0.1:6379>\n```\n可见，TTL的返回值会随着时间的流逝慢慢减少，10s之后键会被删除，键不存在时TTL会返回-2，**当没有为键设置过期时间时，使用TTL获取键的剩余时间将会返回-1**，比如\n\n```\n127.0.0.1:6379> set url http://qifuguang.me\nOK\n127.0.0.1:6379> ttl url\n(integer) -1\n127.0.0.1:6379>\n```\n\n如果想取消某个键的过期时间，可以使用**PERSIST**命令，用法如下：\n\n```\nPERSIST key\n```\n\n清除成功返回1，失败返回0.\n\n例如：\n\n```\n127.0.0.1:6379> set title winwill2012\nOK\n127.0.0.1:6379> EXPIRE title 100\n(integer) 1\n127.0.0.1:6379> ttl title\n(integer) 97\n127.0.0.1:6379> PERSIST title\n(integer) 1\n127.0.0.1:6379> ttl title\n(integer) -1\n127.0.0.1:6379>\n```\n除了PERSIST命令会清除键的过期时间之外，SET,GETSET命令也能清除键的过期时间，但是只对键进行操作的命令（比如INCR,LPUSH等等）不会清除键的过期时间。\n\n**EXPIRE命令的单位是秒，如果想要更精确的过期时间，则可以使用PEXPIRE命令，该命令的单位是毫秒，相应地可以使用PTTL看剩余时间。**\n\n**如果[WATCH](http://qifuguang.me/2015/09/30/Redis%E4%BA%8B%E5%8A%A1%E4%BB%8B%E7%BB%8D/)命令监控了一个具有过期时间的键，如果监控期间这个键过期被自动删除，WATCH并不认为该键被改变**\n\n# Redis过期机制的用途\n有了过期机制就能实现很多跟时间相关的功能了，比如访问频率限制，作为缓存等等，具体细节就不展开了，有疑问的可以留言。\n\n# 声明\n本文原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/30/Redis过期机制介绍/](http://qifuguang.me/2015/09/30/Redis过期机制介绍/)\n","slug":"Redis过期机制介绍","published":1,"updated":"2015-09-30T03:40:23.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovcs004klo6b6fsz863w"},{"title":"Redis持久化","date":"2015-10-12T16:16:02.000Z","_content":"\n# 概述\nRedis的强大性能很大程度上都是因为所有数据都是存储在内存中的，然而当Redis重启后，所有存储在内存中的数据将会丢失，在很多情况下是无法容忍这样的事情的。所以，我们需要将内存中的数据持久化！典型的需要持久化数据的场景如下：\n\n* 将Redis作为数据库使用；\n* 将Redis作为缓存服务器使用，但是缓存miss后会对性能造成很大影响，所有缓存同时失效时会造成服务雪崩，无法响应。\n\n<!--more-->\n本文介绍Redis所支持的两种数据持久化方式。\n\n# Redis数据持久化\nRedis支持两种数据持久化方式：RDB方式和AOF方式。前者会根据配置的规则定时将内存中的数据持久化到硬盘上，后者则是在每次执行写命令之后将命令记录下来。两种持久化方式可以单独使用，但是通常会将两者结合使用。\n\n## RDB方式\nRDB方式的持久化是通过快照的方式完成的。当符合某种规则时，会将内存中的数据全量生成一份副本存储到硬盘上，这个过程称作\"快照\"，Redis会在以下几种情况下对数据进行快照：\n\n* 根据配置规则进行自动快照；\n* 用户执行SAVE, BGSAVE命令；\n* 执行FLUSHALL命令；\n* 执行复制（replication）时。\n\n### 执行快照的场景\n#### 根据配置自动快照\nRedis允许用户自定义快照条件，当满足条件时自动执行快照，快照规则的配置方式如下：\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n每个快照条件独占一行，他们之间是或（||）关系，只要满足任何一个就进行快照。上面配置save后的第一个参数T是时间，单位是秒，第二个参数M是更改的键的个数，含义是：当时间T内被更改的键的个数大于M时，自动进行快照。比如`save 900 1`的含义是15分钟内(900s)被更改的键的个数大于1时，自动进行快照操作。\n\n#### 执行SAVE或BGSAVE命令\n除了让Redis自动进行快照外，当我们需要重启，迁移，备份Redis时，我们也可以手动执行SAVE或BGSAVE命令主动进行快照操作。\n\n* **SAVE命令：**当执行SAVE命令时，Redis同步进行快照操作，期间会阻塞所有来自客户端的请求，所以放数据库数据较多时，应该避免使用该命令；\n* **BGSAVE命令：** 从命令名字就能看出来，这个命令与SAVE命令的区别就在于该命令的快照操作是在后台异步进行的，进行快照操作的同时还能处理来自客户端的请求。执行BGSAVE命令后Redis会马上返回OK表示开始进行快照操作，如果想知道快照操作是否已经完成，可以使用LASTSAVE命令返回最近一次成功执行快照的时间，返回结果是一个Unix时间戳。\n\n#### 执行FLUSHALL命令\n当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是：**不论清空数据库的过程是否触发 了自动快照的条件，只要自动快照条件不为空，Redis就会执行一次快照操作，当没有定义自动快照条件时，执行FLUSHALL命令不会进行快照操作。**\n\n#### 执行复制\n当设置了主从模式时，Redis会在复制初始化是进行自动快照。\n\n### 快照原理\nRedis默认会将快照文件存储在Redis当前进程的工作目录的dump.rdb文件中，可以通过配置文件中的dir和dbfilename两个参数分别指定快照文件的存储路径和文件名，例如：\n\n```\ndbfilename dump.rdb\ndir /opt/soft/redis-3.0.4/cache\n```\n快照执行的过程如下：\n\n1. Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；\n2. 父进程继续处理来自客户端的请求，子进程开始将内存中的数据写入硬盘中的临时文件；\n3. 当子进程写完所有的数据后，用该临时文件替换旧的RDB文件，至此，一次快照操作完成。\n\n需要注意的是：  \n\n>**在执行fork是时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻，父进程和子进程共享同一块内存数据，当父进程需要修改其中的某片数据（如执行写命令）时，操作系统会将该片数据复制一份以保证子进程不受影响，所以RDB文件存储的是执行fork操作那一刻的内存数据。所以RDB方式理论上是会存在丢数据的情况的(fork之后修改的的那些没有写进RDB文件)。**\n\n通过上述的介绍可以知道，快照进行时时不会修改RDB文件的，只有完成的时候才会用临时文件替换老的RDB文件，所以就保证任何时候RDB文件的都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据的备份。RDB文件是经过压缩处理的二进制文件，所以占用的空间会小于内存中数据的大小，更有利于传输。\n\nRedis启动时会自动读取RDB快照文件，将数据从硬盘载入到内存，根据数量的不同，这个过程持续的时间也不尽相同，通常来讲，一个记录1000万个字符串类型键，大小为1GB的快照文件载入到内存需要20-30秒的时间。\n\n### 示例\n下面演示RDB方式持久化，首先使用配置有如下快照规则：\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\ndbfilename dump.rdb\ndir /opt/soft/redis-3.0.4/cache\n```\n的配置文件`/opt/soft/redis-3.0.4/conf/redis.conf`启动Redis服务：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/start-redis.png)  \n\n然后通过客户端设置一个键值：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> set test-rdb HelloWorld\nOK\n127.0.0.1:6379> get test-rdb\n\"HelloWorld\"\n127.0.0.1:6379>\n```\n现在强行kill Redis服务：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/stop-redis.png)  \n现在到`/opt/soft/redis-3.0.4/cache`目录看，目录下出现了Redis的快照文件dump.rdb：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4/cache]$ ls\ndump.rdb\n```\n现在重新启动Redis：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/start-redis.png)  \n\n然后再用客户端连接，检查之前设置的key是否还存在：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> get test-rdb\n\"HelloWorld\"\n127.0.0.1:6379>\n```\n可以发现，之前设置的key在Redis重启之后又通过快照文件dump.rdb恢复了。\n\n## AOF方式\n在使用Redis存储非临时数据时，一般都需要打开AOF持久化来降低进程终止导致的数据丢失，AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这已过程显然会降低Redis的性能，但是大部分情况下这个影响是可以接受的，另外，使用较快的硬盘能提高AOF的性能。\n\n### 开启AOF\n默认情况下，Redis没有开启AOF（append only file）持久化功能，可以通过在配置文件中作如下配置启用：\n\n```\nappendonly yes\n```\n开启之后，Redis每执行一条写命令就会将该命令写入硬盘中的AOF文件。AOF文件保存路径和RDB文件路径是一致的，都是通过dir参数配置，默认文件名是：appendonly.aof，可以通过配置appendonlyfilename参数修改，例如：\n\n```\nappendonlyfilename appendonly.aof\n```\n\n### AOF持久化的实现\nAOF纯文本的形式记录了Redis执行的写命令，例如在开启AOF持久化的情况下执行如下命令：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ ./src/redis-cli\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379> set aof1 value1\nOK\n127.0.0.1:6379> set aof2 value2\nOK\n127.0.0.1:6379>\n```\n然后查看`/opt/soft/redis-3.0.4/cache/appendonly.aof`文件：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4/cache]$ cat appendonly.aof\n*2\n$6\nSELECT\n$1\n0\n*3\n$3\nset\n$4\naof1\n$6\nvalue1\n*3\n$3\nset\n$4\naof2\n$6\nvalue2\n```\n文件中的内容正是Redis刚才执行的命令的内容，内容的格式就先不展开叙述了。\n\n### AOF文件重写\n假设Redis执行了如下命令：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ ./src/redis-cli\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379> set k v1\nOK\n127.0.0.1:6379> set k v2\nOK\n127.0.0.1:6379> set k v3\nOK\n127.0.0.1:6379>\n```\n如果这所有的命令都写到AOF文件的话，将是一个比较蠢行为，因为前面两个命令会被第三个命令覆盖，所以AOF文件完全不需要保存前面两个文件，事实上Redis确实就是这么做的。删除AOF文件中无用的命令的过程成为\"AOF重写\"，AOF重写可以在配置文件中做相应的配置，当满足配置的条件时，自动进行AOF重写操作。配置如下：\n\n```\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n第一行的意思是，目前的AOF文件的大小超过上一次重写时的AOF文件的百分之多少时再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据。\n第二行的意思是，当AOF文件的大小大于64MB时才进行重写，因为如果AOF文件本来就很小时，有几个无效的命令也是无伤大雅的事情。\n这两个配置项通常一起使用。\n\n我们还可以手动执行BDREWRITEAOF命令主动让Redis重写AOF文件，执行重写命令之后查看现在的AOF文件：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ cat cache/appendonly.aof\n*2\n$6\nSELECT\n$1\n0\n*3\n$3\nSET\n$4\naof2\n$6\nvalue2\n*3\n$3\nSET\n$1\nk\n$2\nv3\n*3\n$3\nSET\n$4\naof1\n$6\nvalue1\n```\n可以看到，文件中并没有再记录`set k v1`这样的无效命令。\n\n### 同步硬盘数据\n虽然每次执行更改数据库的内容时，AOF都会记录执行的命令，但是由于操作系统本身的硬盘缓存的缘故，AOF文件的内容并没有真正地写入硬盘，在默认情况下，操作系统会每隔30s将硬盘缓存中的数据同步到硬盘，但是为了防止系统异常退出而导致丢数据的情况发生，我们还可以在Redis的配置文件中配置这个同步的频率：\n\n```\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n```\n第一行表示每次AOF写入一个命令都会执行同步操作，这是最安全也是最慢的方式；\n第二行表示每秒钟进行一次同步操作，一般来说使用这种方式已经足够；\n第三行表示不主动进行同步操作，这是最不安全的方式。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/13/Redis持久化](http://qifuguang.me/2015/10/13/Redis持久化)\n","source":"_posts/Redis持久化.md","raw":"title: Redis持久化\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-10-13 00:16:02\n---\n\n# 概述\nRedis的强大性能很大程度上都是因为所有数据都是存储在内存中的，然而当Redis重启后，所有存储在内存中的数据将会丢失，在很多情况下是无法容忍这样的事情的。所以，我们需要将内存中的数据持久化！典型的需要持久化数据的场景如下：\n\n* 将Redis作为数据库使用；\n* 将Redis作为缓存服务器使用，但是缓存miss后会对性能造成很大影响，所有缓存同时失效时会造成服务雪崩，无法响应。\n\n<!--more-->\n本文介绍Redis所支持的两种数据持久化方式。\n\n# Redis数据持久化\nRedis支持两种数据持久化方式：RDB方式和AOF方式。前者会根据配置的规则定时将内存中的数据持久化到硬盘上，后者则是在每次执行写命令之后将命令记录下来。两种持久化方式可以单独使用，但是通常会将两者结合使用。\n\n## RDB方式\nRDB方式的持久化是通过快照的方式完成的。当符合某种规则时，会将内存中的数据全量生成一份副本存储到硬盘上，这个过程称作\"快照\"，Redis会在以下几种情况下对数据进行快照：\n\n* 根据配置规则进行自动快照；\n* 用户执行SAVE, BGSAVE命令；\n* 执行FLUSHALL命令；\n* 执行复制（replication）时。\n\n### 执行快照的场景\n#### 根据配置自动快照\nRedis允许用户自定义快照条件，当满足条件时自动执行快照，快照规则的配置方式如下：\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\n```\n每个快照条件独占一行，他们之间是或（||）关系，只要满足任何一个就进行快照。上面配置save后的第一个参数T是时间，单位是秒，第二个参数M是更改的键的个数，含义是：当时间T内被更改的键的个数大于M时，自动进行快照。比如`save 900 1`的含义是15分钟内(900s)被更改的键的个数大于1时，自动进行快照操作。\n\n#### 执行SAVE或BGSAVE命令\n除了让Redis自动进行快照外，当我们需要重启，迁移，备份Redis时，我们也可以手动执行SAVE或BGSAVE命令主动进行快照操作。\n\n* **SAVE命令：**当执行SAVE命令时，Redis同步进行快照操作，期间会阻塞所有来自客户端的请求，所以放数据库数据较多时，应该避免使用该命令；\n* **BGSAVE命令：** 从命令名字就能看出来，这个命令与SAVE命令的区别就在于该命令的快照操作是在后台异步进行的，进行快照操作的同时还能处理来自客户端的请求。执行BGSAVE命令后Redis会马上返回OK表示开始进行快照操作，如果想知道快照操作是否已经完成，可以使用LASTSAVE命令返回最近一次成功执行快照的时间，返回结果是一个Unix时间戳。\n\n#### 执行FLUSHALL命令\n当执行FLUSHALL命令时，Redis会清除数据库中的所有数据。需要注意的是：**不论清空数据库的过程是否触发 了自动快照的条件，只要自动快照条件不为空，Redis就会执行一次快照操作，当没有定义自动快照条件时，执行FLUSHALL命令不会进行快照操作。**\n\n#### 执行复制\n当设置了主从模式时，Redis会在复制初始化是进行自动快照。\n\n### 快照原理\nRedis默认会将快照文件存储在Redis当前进程的工作目录的dump.rdb文件中，可以通过配置文件中的dir和dbfilename两个参数分别指定快照文件的存储路径和文件名，例如：\n\n```\ndbfilename dump.rdb\ndir /opt/soft/redis-3.0.4/cache\n```\n快照执行的过程如下：\n\n1. Redis使用fork函数复制一份当前进程（父进程）的副本（子进程）；\n2. 父进程继续处理来自客户端的请求，子进程开始将内存中的数据写入硬盘中的临时文件；\n3. 当子进程写完所有的数据后，用该临时文件替换旧的RDB文件，至此，一次快照操作完成。\n\n需要注意的是：  \n\n>**在执行fork是时候操作系统（类Unix操作系统）会使用写时复制（copy-on-write）策略，即fork函数发生的一刻，父进程和子进程共享同一块内存数据，当父进程需要修改其中的某片数据（如执行写命令）时，操作系统会将该片数据复制一份以保证子进程不受影响，所以RDB文件存储的是执行fork操作那一刻的内存数据。所以RDB方式理论上是会存在丢数据的情况的(fork之后修改的的那些没有写进RDB文件)。**\n\n通过上述的介绍可以知道，快照进行时时不会修改RDB文件的，只有完成的时候才会用临时文件替换老的RDB文件，所以就保证任何时候RDB文件的都是完整的。这使得我们可以通过定时备份RDB文件来实现Redis数据的备份。RDB文件是经过压缩处理的二进制文件，所以占用的空间会小于内存中数据的大小，更有利于传输。\n\nRedis启动时会自动读取RDB快照文件，将数据从硬盘载入到内存，根据数量的不同，这个过程持续的时间也不尽相同，通常来讲，一个记录1000万个字符串类型键，大小为1GB的快照文件载入到内存需要20-30秒的时间。\n\n### 示例\n下面演示RDB方式持久化，首先使用配置有如下快照规则：\n\n```\nsave 900 1\nsave 300 10\nsave 60 10000\ndbfilename dump.rdb\ndir /opt/soft/redis-3.0.4/cache\n```\n的配置文件`/opt/soft/redis-3.0.4/conf/redis.conf`启动Redis服务：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/start-redis.png)  \n\n然后通过客户端设置一个键值：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> set test-rdb HelloWorld\nOK\n127.0.0.1:6379> get test-rdb\n\"HelloWorld\"\n127.0.0.1:6379>\n```\n现在强行kill Redis服务：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/stop-redis.png)  \n现在到`/opt/soft/redis-3.0.4/cache`目录看，目录下出现了Redis的快照文件dump.rdb：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4/cache]$ ls\ndump.rdb\n```\n现在重新启动Redis：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis持久化/start-redis.png)  \n\n然后再用客户端连接，检查之前设置的key是否还存在：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> get test-rdb\n\"HelloWorld\"\n127.0.0.1:6379>\n```\n可以发现，之前设置的key在Redis重启之后又通过快照文件dump.rdb恢复了。\n\n## AOF方式\n在使用Redis存储非临时数据时，一般都需要打开AOF持久化来降低进程终止导致的数据丢失，AOF可以将Redis执行的每一条写命令追加到硬盘文件中，这已过程显然会降低Redis的性能，但是大部分情况下这个影响是可以接受的，另外，使用较快的硬盘能提高AOF的性能。\n\n### 开启AOF\n默认情况下，Redis没有开启AOF（append only file）持久化功能，可以通过在配置文件中作如下配置启用：\n\n```\nappendonly yes\n```\n开启之后，Redis每执行一条写命令就会将该命令写入硬盘中的AOF文件。AOF文件保存路径和RDB文件路径是一致的，都是通过dir参数配置，默认文件名是：appendonly.aof，可以通过配置appendonlyfilename参数修改，例如：\n\n```\nappendonlyfilename appendonly.aof\n```\n\n### AOF持久化的实现\nAOF纯文本的形式记录了Redis执行的写命令，例如在开启AOF持久化的情况下执行如下命令：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ ./src/redis-cli\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379> set aof1 value1\nOK\n127.0.0.1:6379> set aof2 value2\nOK\n127.0.0.1:6379>\n```\n然后查看`/opt/soft/redis-3.0.4/cache/appendonly.aof`文件：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4/cache]$ cat appendonly.aof\n*2\n$6\nSELECT\n$1\n0\n*3\n$3\nset\n$4\naof1\n$6\nvalue1\n*3\n$3\nset\n$4\naof2\n$6\nvalue2\n```\n文件中的内容正是Redis刚才执行的命令的内容，内容的格式就先不展开叙述了。\n\n### AOF文件重写\n假设Redis执行了如下命令：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ ./src/redis-cli\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379>\n127.0.0.1:6379> set k v1\nOK\n127.0.0.1:6379> set k v2\nOK\n127.0.0.1:6379> set k v3\nOK\n127.0.0.1:6379>\n```\n如果这所有的命令都写到AOF文件的话，将是一个比较蠢行为，因为前面两个命令会被第三个命令覆盖，所以AOF文件完全不需要保存前面两个文件，事实上Redis确实就是这么做的。删除AOF文件中无用的命令的过程成为\"AOF重写\"，AOF重写可以在配置文件中做相应的配置，当满足配置的条件时，自动进行AOF重写操作。配置如下：\n\n```\nauto-aof-rewrite-percentage 100\nauto-aof-rewrite-min-size 64mb\n```\n第一行的意思是，目前的AOF文件的大小超过上一次重写时的AOF文件的百分之多少时再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据。\n第二行的意思是，当AOF文件的大小大于64MB时才进行重写，因为如果AOF文件本来就很小时，有几个无效的命令也是无伤大雅的事情。\n这两个配置项通常一起使用。\n\n我们还可以手动执行BDREWRITEAOF命令主动让Redis重写AOF文件，执行重写命令之后查看现在的AOF文件：\n\n```\n[qifuguang@Mac/opt/soft/redis-3.0.4]$ cat cache/appendonly.aof\n*2\n$6\nSELECT\n$1\n0\n*3\n$3\nSET\n$4\naof2\n$6\nvalue2\n*3\n$3\nSET\n$1\nk\n$2\nv3\n*3\n$3\nSET\n$4\naof1\n$6\nvalue1\n```\n可以看到，文件中并没有再记录`set k v1`这样的无效命令。\n\n### 同步硬盘数据\n虽然每次执行更改数据库的内容时，AOF都会记录执行的命令，但是由于操作系统本身的硬盘缓存的缘故，AOF文件的内容并没有真正地写入硬盘，在默认情况下，操作系统会每隔30s将硬盘缓存中的数据同步到硬盘，但是为了防止系统异常退出而导致丢数据的情况发生，我们还可以在Redis的配置文件中配置这个同步的频率：\n\n```\n# appendfsync always\nappendfsync everysec\n# appendfsync no\n```\n第一行表示每次AOF写入一个命令都会执行同步操作，这是最安全也是最慢的方式；\n第二行表示每秒钟进行一次同步操作，一般来说使用这种方式已经足够；\n第三行表示不主动进行同步操作，这是最不安全的方式。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/13/Redis持久化](http://qifuguang.me/2015/10/13/Redis持久化)\n","slug":"Redis持久化","published":1,"updated":"2015-10-15T02:54:55.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovd7004tlo6btks5twdv"},{"title":"Redis五种数据类型介绍","date":"2015-09-28T16:19:31.000Z","_content":"# 概述\nRedis的键值可以使用物种数据类型：**字符串，散列表，列表，集合，有序集合**。本文详细介绍这五种数据类型的使用方法。本文命令介绍部分只是列举了基本的命令，至于具体的使用示例，可以参考Redis官方文档：[Redis命令大全](http://redis.readthedocs.org/en/latest/)\n<!--more-->\n\n# 字符串类型\n字符串是Redis中最基本的数据类型，它能够存储任何类型的字符串，包含二进制数据。可以用于存储邮箱，JSON化的对象，甚至是一张图片，一个字符串允许存储的最大容量为**512MB**。字符串是其他四种类型的基础，与其他几种类型的区别从本质上来说只是组织字符串的方式不同而已。\n\n## 基本命令\n\n### 字符串操作\n1. **SET** 赋值，用法： `SET key value`\n2. **GET** 取值，用法： `GET key`\n3. **INCR** 递增数字，仅仅对数字类型的键有用，相当于Java的i++运算，用法： `INCR key`\n4. **INCRBY** 增加指定的数字，仅仅对数字类型的键有用，相当于Java的i+=3，用法：`INCRBY key increment`，意思是key自增increment，increment可以为负数，表示减少。\n5. **DECR** 递减数字，仅仅对数字类型的键有用，相当于Java的i--，用法：`DECR key`\n6. **DECRBY** 减少指定的数字，仅仅对数字类型的键有用，相当于Java的i-=3，用法：`DECRBY key decrement`，意思是key自减decrement，decrement可以为正数，表示增加。\n7. **INCRBYFLOAT** 增加指定浮点数，仅仅对数字类型的键有用，用法：`INCRBYFLOAT key increment`\n8. **APPEND** 向尾部追加值，相当于Java中的\"hello\".append(\" world\")，用法：`APPEND key value`\n9. **STRLEN** 获取字符串长度，用法：`STRLEN key`\n10. **MSET** 同时设置多个key的值，用法：`MSET key1 value1 [key2 value2 ...]`\n11. **MGET** 同时获取多个key的值，用法：`MGET key1 [key2 ...]`\n\n### 位操作\n\n1. **GETBIT** 获取一个键值的二进制位的指定位置的值(0/1)，用法：`GETBIT key offset`\n2. **SETBIT** 设置一个键值的二进制位的指定位置的值(0/1)，用法：`SETBIT key offset value`\n3. **BITCOUNT** 获取一个键值的一个范围内的二进制表示的1的个数，用法：`BITCOUNT key [start end]`\n4. **BITOP** 该命令可以对多个字符串类型键进行位运算，并将结果存储到指定的键中，BITOP支持的运算包含：**OR,AND,XOR,NOT**，用法：`BITOP OP desKey key1 key2`\n5. **BITPOS** 获取指定键的第一个位值为0或者1的位置，用法：`BITPOS key 0/1 [start， end]`\n\n# 散列类型\n散列类型相当于Java中的HashMap，他的值是一个字典，保存很多key，value对，每对key，value的值个键都是字符串类型，换句话说，散列类型不能嵌套其他数据类型。一个散列类型键最多可以包含2的32次方-1个字段。\n\n## 基本命令\n\n1. **HSET** 赋值，用法：`HSET key field value`\n2. **HMSET** 一次赋值多个字段，用法：`HMSET key field1 value1 [field2 values]`\n3. **HGET** 取值，用法：`HSET key field`\n4. **HMGET** 一次取多个字段的值，用法：`HMSET key field1 [field2]`\n5. **HGETALL** 一次取所有字段的值，用法：`HGETALL key`\n6. **HEXISTS** 判断字段是否存在，用法：`HEXISTS key field`\n7. **HSETNX** 当字段不存在时赋值，用法：`HSETNX key field value`\n8. **HINCRBY** 增加数字，仅对数字类型的值有用，用法：`HINCRBY key field increment`\n9. **HDEL** 删除字段，用法：`HDEL key field`\n10. **HKEYS** 获取所有字段名，用法：`HKEYS key`\n11. **HVALS** 获取所有字段值，用法：`HVALS key`\n12. **HLEN** 获取字段数量，用法：`HLEN key`\n\n# 列表类型\n列表类型(list)用于存储一个有序的字符串列表，常用的操作是向队列两端添加元素或者获得列表的某一片段。列表内部使用的是双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度是O(1),获取越接近列表两端的元素的速度越快。但是缺点是使用列表通过索引访问元素的效率太低（需要从端点开始遍历元素）。所以列表的使用场景一般如：朋友圈新鲜事，只关心最新的一些内容。借助列表类型，Redis还可以作为消息队列使用。\n\n## 基本命令\n\n1. **LPUSH** 向列表左端添加元素，用法：`LPUSH key value`\n2. **RPUSH** 向列表右端添加元素，用法：`RPUSH key value`\n3. **LPOP** 从列表左端弹出元素，用法：`LPOP key`\n4. **RPOP** 从列表右端弹出元素，用法：`RPOP key`\n5. **LLEN** 获取列表中元素个数，用法：`LLEN key`\n6. **LRANGE** 获取列表中某一片段的元素，用法：`LRANGE key start stop`，index从0开始，-1表示最后一个元素\n7. **LREM** 删除列表中指定的值，用法：`LREM key count value`，删除列表中前count个值为value的元素，当count>0时从左边开始数，count<0时从右边开始数，count=0时会删除所有值为value的元素\n8. **LINDEX** 获取指定索引的元素值，用法：`LINDEX key index`\n9. **LSET** 设置指定索引的元素值，用法：`LSET key index value`\n10. **LTRIM** 只保留列表指定片段，用法：`LTRIM key start stop`，包含start和stop\n11. **LINSERT** 像列表中插入元素，用法：`LINSERT key BEFORE|AFTER privot value`，从左边开始寻找值为privot的第一个元素，然后根据第二个参数是BEFORE还是AFTER决定在该元素的前面还是后面插入value\n12. **RPOPLPUSH** 将元素从一个列表转义到另一个列表，用法：`RPOPLPUSH source destination`\n\n\n# 集合类型\n集合在概念在高中课本就学过，集合中每个元素都是不同的，集合中的元素个数最多为2的32次方-1个，集合中的元素师没有顺序的。\n\n## 基本命令\n\n1. **SADD** 添加元素，用法：`SADD key value1 [value2 value3 ...]`\n2. **SREM** 删除元素，用法：`SREM key value2 [value2 value3 ...]`\n3. **SMEMBERS** 获得集合中所有元素，用法：`SMEMBERS key`\n4. **SISMEMBER** 判断元素是否在集合中，用法：`SISMEMBER key value`\n5. **SDIFF** 对集合做差集运算，用法：`SDIFF key1 key2 [key3 ...]`，先计算key1和key2的差集，然后再用结果与key3做差集\n6. **SINTER** 对集合做交集运算，用法：`SINTER key1 key2 [key3 ...]`\n7. **SUNION** 对集合做并集运算，用法：`SUNION key1 key2 [key3 ...]`\n8. **SCARD** 获得集合中元素的个数，用法：`SCARD key`\n9. **SDIFFSTORE** 对集合做差集并将结果存储，用法：`SDIFFSTORE destination key1 key2 [key3 ...]`\n10. **SINTERSTORE** 对集合做交集运算并将结果存储，用法：`SINTERSTORE destination key1 key2 [key3 ...]`\n11. **SUNIONSTORE** 对集合做并集运算并将结果存储，用法：`SUNIONSTORE destination key1 key2 [key3 ...]`\n12. **SRANDMEMBER** 随机获取集合中的元素，用法：`SRANDMEMBER key [count]`，当count>0时，会随机中集合中获取count个不重复的元素，当count<0时，随机中集合中获取|count|和可能重复的元素。\n13. **SPOP** 从集合中随机弹出一个元素，用法：`SPOP key`\n\n# 有序集合类型\n有序集合类型与集合类型的区别就是他是有序的。有序集合是在集合的基础上为每一个元素关联一个分数，这就让有序集合不仅支持插入，删除，判断元素是否存在等操作外，还支持获取分数最高/最低的前N个元素。有序集合中的每个元素是不同的，但是分数却可以相同。有序集合使用散列表和跳跃表实现，即使读取位于中间部分的数据也很快，时间复杂度为O(log(N))，有序集合比列表更费内存。\n\n## 基本命令\n\n1. **ZADD** 添加元素，用法：`ZADD key score1 value1 [score2 value2 score3 value3 ...]`\n2. **ZSCORE** 获取元素的分数，用法：`ZSCORE key value`\n3. **ZRANGE** 获取排名在某个范围的元素，用法：`ZRANGE key start stop [WITHSCORE]`，按照元素从小到大的顺序排序，从0开始编号，包含start和stop对应的元素，WITHSCORE选项表示是否返回元素分数\n4. **ZREVRANGE** 获取排名在某个范围的元素，用法：`ZREVRANGE key start stop [WITHSCORE]`，和上一个命令用法一样，只是这个倒序排序的。\n5. **ZRANGEBYSCORE** 获取指定分数范围内的元素，用法：`ZRANGEBYSCORE key min max`，包含min和max，`(min`表示不包含min，`(max`表示不包含max，`+inf`表示无穷大\n6. **ZINCRBY** 增加某个元素的分数，用法：`ZINCRBY key increment value`\n7. **ZCARD** 获取集合中元素的个数，用法：`ZCARD key`\n8. **ZCOUNT** 获取指定分数范围内的元素个数，用法：`ZCOUNT key min max`，min和max的用法和5中的一样\n9. **ZREM** 删除一个或多个元素，用法：`ZREM key value1 [value2 ...]`\n10. **ZREMRANGEBYRANK** 按照排名范围删除元素，用法：`ZREMRANGEBYRANK key start stop`\n11. **ZREMRANGEBYSCORE** 按照分数范围删除元素，用法：`ZREMRANGEBYSCORE key min max`，min和max的用法和4中的一样\n12. **ZRANK** 获取正序排序的元素的排名，用法：`ZRANK key value`\n13. **ZREVRANK** 获取逆序排序的元素的排名，用法：`ZREVRANK key value`\n14. **ZINTERSTORE** 计算有序集合的交集并存储结果，用法：`ZINTERSTORE destination numbers key1 key2 [key3 key4 ...] WEIGHTS weight1 weight2 [weight3 weight4 ...] AGGREGATE SUM | MIN | MAX`，numbers表示参加运算的集合个数，weight表示权重，aggregate表示结果取值\n15. **ZUNIONSTORE** 计算有序几个的并集并存储结果，用法和14一样，不再赘述。\n\n# 声明\n本文为原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/29/Redis五种数据类型介绍/](http://qifuguang.me/2015/09/29/Redis五种数据类型介绍/)\n","source":"_posts/Redis五种数据类型介绍.md","raw":"title: Redis五种数据类型介绍\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-09-29 00:19:31\n---\n# 概述\nRedis的键值可以使用物种数据类型：**字符串，散列表，列表，集合，有序集合**。本文详细介绍这五种数据类型的使用方法。本文命令介绍部分只是列举了基本的命令，至于具体的使用示例，可以参考Redis官方文档：[Redis命令大全](http://redis.readthedocs.org/en/latest/)\n<!--more-->\n\n# 字符串类型\n字符串是Redis中最基本的数据类型，它能够存储任何类型的字符串，包含二进制数据。可以用于存储邮箱，JSON化的对象，甚至是一张图片，一个字符串允许存储的最大容量为**512MB**。字符串是其他四种类型的基础，与其他几种类型的区别从本质上来说只是组织字符串的方式不同而已。\n\n## 基本命令\n\n### 字符串操作\n1. **SET** 赋值，用法： `SET key value`\n2. **GET** 取值，用法： `GET key`\n3. **INCR** 递增数字，仅仅对数字类型的键有用，相当于Java的i++运算，用法： `INCR key`\n4. **INCRBY** 增加指定的数字，仅仅对数字类型的键有用，相当于Java的i+=3，用法：`INCRBY key increment`，意思是key自增increment，increment可以为负数，表示减少。\n5. **DECR** 递减数字，仅仅对数字类型的键有用，相当于Java的i--，用法：`DECR key`\n6. **DECRBY** 减少指定的数字，仅仅对数字类型的键有用，相当于Java的i-=3，用法：`DECRBY key decrement`，意思是key自减decrement，decrement可以为正数，表示增加。\n7. **INCRBYFLOAT** 增加指定浮点数，仅仅对数字类型的键有用，用法：`INCRBYFLOAT key increment`\n8. **APPEND** 向尾部追加值，相当于Java中的\"hello\".append(\" world\")，用法：`APPEND key value`\n9. **STRLEN** 获取字符串长度，用法：`STRLEN key`\n10. **MSET** 同时设置多个key的值，用法：`MSET key1 value1 [key2 value2 ...]`\n11. **MGET** 同时获取多个key的值，用法：`MGET key1 [key2 ...]`\n\n### 位操作\n\n1. **GETBIT** 获取一个键值的二进制位的指定位置的值(0/1)，用法：`GETBIT key offset`\n2. **SETBIT** 设置一个键值的二进制位的指定位置的值(0/1)，用法：`SETBIT key offset value`\n3. **BITCOUNT** 获取一个键值的一个范围内的二进制表示的1的个数，用法：`BITCOUNT key [start end]`\n4. **BITOP** 该命令可以对多个字符串类型键进行位运算，并将结果存储到指定的键中，BITOP支持的运算包含：**OR,AND,XOR,NOT**，用法：`BITOP OP desKey key1 key2`\n5. **BITPOS** 获取指定键的第一个位值为0或者1的位置，用法：`BITPOS key 0/1 [start， end]`\n\n# 散列类型\n散列类型相当于Java中的HashMap，他的值是一个字典，保存很多key，value对，每对key，value的值个键都是字符串类型，换句话说，散列类型不能嵌套其他数据类型。一个散列类型键最多可以包含2的32次方-1个字段。\n\n## 基本命令\n\n1. **HSET** 赋值，用法：`HSET key field value`\n2. **HMSET** 一次赋值多个字段，用法：`HMSET key field1 value1 [field2 values]`\n3. **HGET** 取值，用法：`HSET key field`\n4. **HMGET** 一次取多个字段的值，用法：`HMSET key field1 [field2]`\n5. **HGETALL** 一次取所有字段的值，用法：`HGETALL key`\n6. **HEXISTS** 判断字段是否存在，用法：`HEXISTS key field`\n7. **HSETNX** 当字段不存在时赋值，用法：`HSETNX key field value`\n8. **HINCRBY** 增加数字，仅对数字类型的值有用，用法：`HINCRBY key field increment`\n9. **HDEL** 删除字段，用法：`HDEL key field`\n10. **HKEYS** 获取所有字段名，用法：`HKEYS key`\n11. **HVALS** 获取所有字段值，用法：`HVALS key`\n12. **HLEN** 获取字段数量，用法：`HLEN key`\n\n# 列表类型\n列表类型(list)用于存储一个有序的字符串列表，常用的操作是向队列两端添加元素或者获得列表的某一片段。列表内部使用的是双向链表（double linked list）实现的，所以向列表两端添加元素的时间复杂度是O(1),获取越接近列表两端的元素的速度越快。但是缺点是使用列表通过索引访问元素的效率太低（需要从端点开始遍历元素）。所以列表的使用场景一般如：朋友圈新鲜事，只关心最新的一些内容。借助列表类型，Redis还可以作为消息队列使用。\n\n## 基本命令\n\n1. **LPUSH** 向列表左端添加元素，用法：`LPUSH key value`\n2. **RPUSH** 向列表右端添加元素，用法：`RPUSH key value`\n3. **LPOP** 从列表左端弹出元素，用法：`LPOP key`\n4. **RPOP** 从列表右端弹出元素，用法：`RPOP key`\n5. **LLEN** 获取列表中元素个数，用法：`LLEN key`\n6. **LRANGE** 获取列表中某一片段的元素，用法：`LRANGE key start stop`，index从0开始，-1表示最后一个元素\n7. **LREM** 删除列表中指定的值，用法：`LREM key count value`，删除列表中前count个值为value的元素，当count>0时从左边开始数，count<0时从右边开始数，count=0时会删除所有值为value的元素\n8. **LINDEX** 获取指定索引的元素值，用法：`LINDEX key index`\n9. **LSET** 设置指定索引的元素值，用法：`LSET key index value`\n10. **LTRIM** 只保留列表指定片段，用法：`LTRIM key start stop`，包含start和stop\n11. **LINSERT** 像列表中插入元素，用法：`LINSERT key BEFORE|AFTER privot value`，从左边开始寻找值为privot的第一个元素，然后根据第二个参数是BEFORE还是AFTER决定在该元素的前面还是后面插入value\n12. **RPOPLPUSH** 将元素从一个列表转义到另一个列表，用法：`RPOPLPUSH source destination`\n\n\n# 集合类型\n集合在概念在高中课本就学过，集合中每个元素都是不同的，集合中的元素个数最多为2的32次方-1个，集合中的元素师没有顺序的。\n\n## 基本命令\n\n1. **SADD** 添加元素，用法：`SADD key value1 [value2 value3 ...]`\n2. **SREM** 删除元素，用法：`SREM key value2 [value2 value3 ...]`\n3. **SMEMBERS** 获得集合中所有元素，用法：`SMEMBERS key`\n4. **SISMEMBER** 判断元素是否在集合中，用法：`SISMEMBER key value`\n5. **SDIFF** 对集合做差集运算，用法：`SDIFF key1 key2 [key3 ...]`，先计算key1和key2的差集，然后再用结果与key3做差集\n6. **SINTER** 对集合做交集运算，用法：`SINTER key1 key2 [key3 ...]`\n7. **SUNION** 对集合做并集运算，用法：`SUNION key1 key2 [key3 ...]`\n8. **SCARD** 获得集合中元素的个数，用法：`SCARD key`\n9. **SDIFFSTORE** 对集合做差集并将结果存储，用法：`SDIFFSTORE destination key1 key2 [key3 ...]`\n10. **SINTERSTORE** 对集合做交集运算并将结果存储，用法：`SINTERSTORE destination key1 key2 [key3 ...]`\n11. **SUNIONSTORE** 对集合做并集运算并将结果存储，用法：`SUNIONSTORE destination key1 key2 [key3 ...]`\n12. **SRANDMEMBER** 随机获取集合中的元素，用法：`SRANDMEMBER key [count]`，当count>0时，会随机中集合中获取count个不重复的元素，当count<0时，随机中集合中获取|count|和可能重复的元素。\n13. **SPOP** 从集合中随机弹出一个元素，用法：`SPOP key`\n\n# 有序集合类型\n有序集合类型与集合类型的区别就是他是有序的。有序集合是在集合的基础上为每一个元素关联一个分数，这就让有序集合不仅支持插入，删除，判断元素是否存在等操作外，还支持获取分数最高/最低的前N个元素。有序集合中的每个元素是不同的，但是分数却可以相同。有序集合使用散列表和跳跃表实现，即使读取位于中间部分的数据也很快，时间复杂度为O(log(N))，有序集合比列表更费内存。\n\n## 基本命令\n\n1. **ZADD** 添加元素，用法：`ZADD key score1 value1 [score2 value2 score3 value3 ...]`\n2. **ZSCORE** 获取元素的分数，用法：`ZSCORE key value`\n3. **ZRANGE** 获取排名在某个范围的元素，用法：`ZRANGE key start stop [WITHSCORE]`，按照元素从小到大的顺序排序，从0开始编号，包含start和stop对应的元素，WITHSCORE选项表示是否返回元素分数\n4. **ZREVRANGE** 获取排名在某个范围的元素，用法：`ZREVRANGE key start stop [WITHSCORE]`，和上一个命令用法一样，只是这个倒序排序的。\n5. **ZRANGEBYSCORE** 获取指定分数范围内的元素，用法：`ZRANGEBYSCORE key min max`，包含min和max，`(min`表示不包含min，`(max`表示不包含max，`+inf`表示无穷大\n6. **ZINCRBY** 增加某个元素的分数，用法：`ZINCRBY key increment value`\n7. **ZCARD** 获取集合中元素的个数，用法：`ZCARD key`\n8. **ZCOUNT** 获取指定分数范围内的元素个数，用法：`ZCOUNT key min max`，min和max的用法和5中的一样\n9. **ZREM** 删除一个或多个元素，用法：`ZREM key value1 [value2 ...]`\n10. **ZREMRANGEBYRANK** 按照排名范围删除元素，用法：`ZREMRANGEBYRANK key start stop`\n11. **ZREMRANGEBYSCORE** 按照分数范围删除元素，用法：`ZREMRANGEBYSCORE key min max`，min和max的用法和4中的一样\n12. **ZRANK** 获取正序排序的元素的排名，用法：`ZRANK key value`\n13. **ZREVRANK** 获取逆序排序的元素的排名，用法：`ZREVRANK key value`\n14. **ZINTERSTORE** 计算有序集合的交集并存储结果，用法：`ZINTERSTORE destination numbers key1 key2 [key3 key4 ...] WEIGHTS weight1 weight2 [weight3 weight4 ...] AGGREGATE SUM | MIN | MAX`，numbers表示参加运算的集合个数，weight表示权重，aggregate表示结果取值\n15. **ZUNIONSTORE** 计算有序几个的并集并存储结果，用法和14一样，不再赘述。\n\n# 声明\n本文为原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/29/Redis五种数据类型介绍/](http://qifuguang.me/2015/09/29/Redis五种数据类型介绍/)\n","slug":"Redis五种数据类型介绍","published":1,"updated":"2015-09-28T16:22:14.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovdc004ylo6b27l13kgi"},{"title":"Redis事务介绍","date":"2015-09-29T16:38:48.000Z","_content":"\n# 概述\n相信学过Mysql等其他数据库的同学对事务这个词都不陌生，事务表示的是一组动作，这组动作要么全部执行，要么全部不执行。为什么会有这样的需求呢？看看下面的场景：\n\n> * 微博是一个弱关系型社交网络，用户之间有关注和被关注两种关系，比如两个用户A和B，如果A关注B，则B的粉丝中就应该有A。关注这个动作需要两个步骤完成：在A的关注者中添加B；在B的粉丝中添加A。 这两个动作要么都执行成功，要么都不执行。否则就可能会出现A关注了B，但是B的粉丝中没有A的不可容忍的情况。\n> * 转账汇款，假设现在有两个账户A和B，现在需要将A中的一万块大洋转到B的账户中，这个动作也需要两个步骤完成：从A的账户中划走一万块；在B的账户中增加一万块。这两个动作要么全部执行成功，要么全部不执行，否则自会有人问候你的！！！\n\n<!--more-->\nRedis作为一种高效的分布式数据库，同样支持事务。\n\n# Redis事务\nRedis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。Redis事务的实现需要用到** MULTI **和** EXEC **两个命令，事务开始的时候先向Redis服务器发送** MULTI **命令，然后依次发送需要在本次事务中处理的命令，最后再发送** EXEC **命令表示事务命令结束。\n\n举个例子，使用redis-cli连接redis，然后在命令行工具中输入如下命令：\n\n```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set url http://qifuguang.me\nQUEUED\n127.0.0.1:6379> set title winwill2012\nQUEUED\n127.0.0.1:6379> set desc java\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) OK\n3) OK\n127.0.0.1:6379>\n127.0.0.1:6379> get url\n\"http://qifuguang.me\"\n127.0.0.1:6379> get title\n\"winwill2012\"\n127.0.0.1:6379> get desc\n\"java\"\n127.0.0.1:6379>\n```\n从输出中可以看到，当输入MULTI命令后，服务器返回OK表示事务开始成功，然后依次输入需要在本次事务中执行的所有命令，每次输入一个命令服务器并不会马上执行，而是返回\"QUEUED\"，这表示命令已经被服务器接受并且暂时保存起来，最后输入EXEC命令后，本次事务中的所有命令才会被依次执行，可以看到最后服务器一次性返回了三个OK，这里返回的结果与发送的命令是按顺序一一对应的，这说明这次事务中的命令全都执行成功了。\n\n再举个例子，在命令行工具中输入如下命令：\n\n```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set a a\nQUEUED\n127.0.0.1:6379> sett b b\n(error) ERR unknown command 'sett'\n127.0.0.1:6379> set c c\nQUEUED\n127.0.0.1:6379> EXEC\n(error) EXECABORT Transaction discarded because of previous errors.\n127.0.0.1:6379> get a\n(nil)\n127.0.0.1:6379> get b\n(nil)\n127.0.0.1:6379> get c\n(nil)\n127.0.0.1:6379>\n```\n和前面的例子一样，先输入MULTI最后输入EXEC表示中间的命令属于一个事务，不同的是中间输入的命令有一个错误(set写成了sett)，这样因为有一个错误的命令导致事务中的其他命令都不执行了(通过后续的get命令可以验证)，可见事务中的所有命令式同呼吸共命运的。\n\n如果客户端在发送EXEC命令之前断线了，则服务器会清空事务队列，事务中的所有命令都不会被执行。而一旦客户端发送了EXEC命令之后，事务中的所有命令都会被执行，即使此后客户端断线也没关系，因为服务器已经保存了事务中的所有命令。\n\n除了保证事务中的所有命令要么全执行要么全不执行外，Redis的事务还能保证一个事务中的命令依次执行而不会被其他命令插入。试想一个客户端A需要执行几条命令，同时客户端B发送了几条命令，如果不使用事务，则客户端B的命令有可能会插入到客户端A的几条命令中，如果想避免这种情况发生，也可以使用事务。\n\n# Redis事务错误处理\n如果一个事务中的某个命令执行出错，Redis会怎样处理呢？要回答这个问题，首先要搞清楚是什么原因导致命令执行出错：\n\n1. **语法错误** 就像上面的例子一样，语法错误表示命令不存在或者参数错误  \n   这种情况需要区分Redis的版本，Redis 2.6.5之前的版本会忽略错误的命令，执行其他正确的命令，2.6.5之后的版本会忽略这个事务中的所有命令，都不执行，就比如上面的例子(使用的Redis版本是2.8的)\n\n2. **运行错误** 运行错误表示命令在执行过程中出现错误，比如用GET命令获取一个散列表类型的键值。  \n   这种错误在命令执行之前Redis是无法发现的，所以在事务里这样的命令会被Redis接受并执行。如果食物里有一条命令执行错误，其他命令依旧会执行（包括出错之后的命令）。比如下例：\n\n   ```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set key 1\nQUEUED\n127.0.0.1:6379> SADD key 2\nQUEUED\n127.0.0.1:6379> set key 3\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) (error) WRONGTYPE Operation against a key holding the wrong kind of value\n3) OK\n127.0.0.1:6379> get key\n\"3\"\n   ```\n   **Redis中的事务并没有关系型数据库中的事务回滚(rollback)功能，因此使用者必须自己收拾剩下的烂摊子。**不过由于Redis不支持事务回滚功能，这也使得Redis的事务简洁快速。\n\n回顾上面两种类型的错误，语法错误完全可以在开发的时候发现并作出处理，另外如果能很好地规划Redis数据的键的使用，也是不会出现命令和键不匹配的问题的。\n\n# WATCH命令\n从上面的例子我们可以看到，事务中的命令要全部执行完之后才能获取每个命令的结果，但是如果一个事务中的命令B依赖于他上一个命令A的结果的话该怎么办呢？就比如说实现类似Java中的i++的功能，先要获取当前值，才能在当前值的基础上做加一操作。这种场合仅仅使用上面介绍的MULTI和EXEC是不能实现的，因为MULTI和EXEC中的命令是一起执行的，并不能将其中一条命令的执行结果作为另一条命令的执行参数，所以这个时候就需要引进Redis事务家族中的另一成员：**WATCH命令**\n\n换个角度思考上面说到的实现i++的方法，可以这样实现：\n> 1. 监控i的值，保证i的值不被修改\n2. 获取i的原值\n3. 如果过程中i的值没有被修改，则将当前的i值+1，否则不执行\n\n这样就能够避免竞态条件，保证i++能够正确执行。\n\nWATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，EXEC命令执行完之后被监控的键会自动被UNWATCH）\n\n举个例子：\n\n```\n127.0.0.1:6379> set mykey 1\nOK\n127.0.0.1:6379> WATCH mykey\nOK\n127.0.0.1:6379> set mykey 2\nOK\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set mykey 3\nQUEUED\n127.0.0.1:6379> EXEC\n(nil)\n127.0.0.1:6379> get mykey\n\"2\"\n127.0.0.1:6379>\n```\n上面的例子中，首先设置mykey的键值为1，然后使用WATCH命令监控mykey，随后更改mykey的值为2，然后进入事务，事务中设置mykey的值为3，然后执行EXEC运行事务中的命令，最后使用get命令查看mykey的值，发现mykey的值还是2，也就是说事务中的命令根本没有执行（因为WATCH监控mykey的过程中，mykey被修改了，所以随后的事务便会被取消）。\n\n有了WATCH命令，我们就可以自己实现i++功能了，伪代码如下：\n\n```\ndef incr($key):\n    WATCH $key\n    $value = GET $key\n    if not $value\n        $value = 0\n    $value = $value + 1\n    \n    MULTI\n    SET $key $value\n        result = EXEC\n    return result[0]\n```\n\n因为EXEC返回的是多行字符串，使用result[0]表示返回值的第一个字符串。\n\n**注意：由于WATCH命令的作用只是当被监控的键被修改后取消之后的事务，并不能保证其他客户端不修改监控的值，所以当EXEC命令执行失败之后需要手动重新执行整个事务。**\n\n执行EXEC命令之后会取消监控使用WATCH命令监控的键，如果不想执行事务中的命令，也可以使用UNWATCH命令来取消监控。\n\n# 声明\n本文为原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/30/Redis事务介绍/](http://qifuguang.me/2015/09/30/Redis事务介绍/)\n\n","source":"_posts/Redis事务介绍.md","raw":"title: Redis事务介绍\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-09-30 00:38:48\n---\n\n# 概述\n相信学过Mysql等其他数据库的同学对事务这个词都不陌生，事务表示的是一组动作，这组动作要么全部执行，要么全部不执行。为什么会有这样的需求呢？看看下面的场景：\n\n> * 微博是一个弱关系型社交网络，用户之间有关注和被关注两种关系，比如两个用户A和B，如果A关注B，则B的粉丝中就应该有A。关注这个动作需要两个步骤完成：在A的关注者中添加B；在B的粉丝中添加A。 这两个动作要么都执行成功，要么都不执行。否则就可能会出现A关注了B，但是B的粉丝中没有A的不可容忍的情况。\n> * 转账汇款，假设现在有两个账户A和B，现在需要将A中的一万块大洋转到B的账户中，这个动作也需要两个步骤完成：从A的账户中划走一万块；在B的账户中增加一万块。这两个动作要么全部执行成功，要么全部不执行，否则自会有人问候你的！！！\n\n<!--more-->\nRedis作为一种高效的分布式数据库，同样支持事务。\n\n# Redis事务\nRedis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。Redis事务的实现需要用到** MULTI **和** EXEC **两个命令，事务开始的时候先向Redis服务器发送** MULTI **命令，然后依次发送需要在本次事务中处理的命令，最后再发送** EXEC **命令表示事务命令结束。\n\n举个例子，使用redis-cli连接redis，然后在命令行工具中输入如下命令：\n\n```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set url http://qifuguang.me\nQUEUED\n127.0.0.1:6379> set title winwill2012\nQUEUED\n127.0.0.1:6379> set desc java\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) OK\n3) OK\n127.0.0.1:6379>\n127.0.0.1:6379> get url\n\"http://qifuguang.me\"\n127.0.0.1:6379> get title\n\"winwill2012\"\n127.0.0.1:6379> get desc\n\"java\"\n127.0.0.1:6379>\n```\n从输出中可以看到，当输入MULTI命令后，服务器返回OK表示事务开始成功，然后依次输入需要在本次事务中执行的所有命令，每次输入一个命令服务器并不会马上执行，而是返回\"QUEUED\"，这表示命令已经被服务器接受并且暂时保存起来，最后输入EXEC命令后，本次事务中的所有命令才会被依次执行，可以看到最后服务器一次性返回了三个OK，这里返回的结果与发送的命令是按顺序一一对应的，这说明这次事务中的命令全都执行成功了。\n\n再举个例子，在命令行工具中输入如下命令：\n\n```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set a a\nQUEUED\n127.0.0.1:6379> sett b b\n(error) ERR unknown command 'sett'\n127.0.0.1:6379> set c c\nQUEUED\n127.0.0.1:6379> EXEC\n(error) EXECABORT Transaction discarded because of previous errors.\n127.0.0.1:6379> get a\n(nil)\n127.0.0.1:6379> get b\n(nil)\n127.0.0.1:6379> get c\n(nil)\n127.0.0.1:6379>\n```\n和前面的例子一样，先输入MULTI最后输入EXEC表示中间的命令属于一个事务，不同的是中间输入的命令有一个错误(set写成了sett)，这样因为有一个错误的命令导致事务中的其他命令都不执行了(通过后续的get命令可以验证)，可见事务中的所有命令式同呼吸共命运的。\n\n如果客户端在发送EXEC命令之前断线了，则服务器会清空事务队列，事务中的所有命令都不会被执行。而一旦客户端发送了EXEC命令之后，事务中的所有命令都会被执行，即使此后客户端断线也没关系，因为服务器已经保存了事务中的所有命令。\n\n除了保证事务中的所有命令要么全执行要么全不执行外，Redis的事务还能保证一个事务中的命令依次执行而不会被其他命令插入。试想一个客户端A需要执行几条命令，同时客户端B发送了几条命令，如果不使用事务，则客户端B的命令有可能会插入到客户端A的几条命令中，如果想避免这种情况发生，也可以使用事务。\n\n# Redis事务错误处理\n如果一个事务中的某个命令执行出错，Redis会怎样处理呢？要回答这个问题，首先要搞清楚是什么原因导致命令执行出错：\n\n1. **语法错误** 就像上面的例子一样，语法错误表示命令不存在或者参数错误  \n   这种情况需要区分Redis的版本，Redis 2.6.5之前的版本会忽略错误的命令，执行其他正确的命令，2.6.5之后的版本会忽略这个事务中的所有命令，都不执行，就比如上面的例子(使用的Redis版本是2.8的)\n\n2. **运行错误** 运行错误表示命令在执行过程中出现错误，比如用GET命令获取一个散列表类型的键值。  \n   这种错误在命令执行之前Redis是无法发现的，所以在事务里这样的命令会被Redis接受并执行。如果食物里有一条命令执行错误，其他命令依旧会执行（包括出错之后的命令）。比如下例：\n\n   ```\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set key 1\nQUEUED\n127.0.0.1:6379> SADD key 2\nQUEUED\n127.0.0.1:6379> set key 3\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) (error) WRONGTYPE Operation against a key holding the wrong kind of value\n3) OK\n127.0.0.1:6379> get key\n\"3\"\n   ```\n   **Redis中的事务并没有关系型数据库中的事务回滚(rollback)功能，因此使用者必须自己收拾剩下的烂摊子。**不过由于Redis不支持事务回滚功能，这也使得Redis的事务简洁快速。\n\n回顾上面两种类型的错误，语法错误完全可以在开发的时候发现并作出处理，另外如果能很好地规划Redis数据的键的使用，也是不会出现命令和键不匹配的问题的。\n\n# WATCH命令\n从上面的例子我们可以看到，事务中的命令要全部执行完之后才能获取每个命令的结果，但是如果一个事务中的命令B依赖于他上一个命令A的结果的话该怎么办呢？就比如说实现类似Java中的i++的功能，先要获取当前值，才能在当前值的基础上做加一操作。这种场合仅仅使用上面介绍的MULTI和EXEC是不能实现的，因为MULTI和EXEC中的命令是一起执行的，并不能将其中一条命令的执行结果作为另一条命令的执行参数，所以这个时候就需要引进Redis事务家族中的另一成员：**WATCH命令**\n\n换个角度思考上面说到的实现i++的方法，可以这样实现：\n> 1. 监控i的值，保证i的值不被修改\n2. 获取i的原值\n3. 如果过程中i的值没有被修改，则将当前的i值+1，否则不执行\n\n这样就能够避免竞态条件，保证i++能够正确执行。\n\nWATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行，监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，EXEC命令执行完之后被监控的键会自动被UNWATCH）\n\n举个例子：\n\n```\n127.0.0.1:6379> set mykey 1\nOK\n127.0.0.1:6379> WATCH mykey\nOK\n127.0.0.1:6379> set mykey 2\nOK\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set mykey 3\nQUEUED\n127.0.0.1:6379> EXEC\n(nil)\n127.0.0.1:6379> get mykey\n\"2\"\n127.0.0.1:6379>\n```\n上面的例子中，首先设置mykey的键值为1，然后使用WATCH命令监控mykey，随后更改mykey的值为2，然后进入事务，事务中设置mykey的值为3，然后执行EXEC运行事务中的命令，最后使用get命令查看mykey的值，发现mykey的值还是2，也就是说事务中的命令根本没有执行（因为WATCH监控mykey的过程中，mykey被修改了，所以随后的事务便会被取消）。\n\n有了WATCH命令，我们就可以自己实现i++功能了，伪代码如下：\n\n```\ndef incr($key):\n    WATCH $key\n    $value = GET $key\n    if not $value\n        $value = 0\n    $value = $value + 1\n    \n    MULTI\n    SET $key $value\n        result = EXEC\n    return result[0]\n```\n\n因为EXEC返回的是多行字符串，使用result[0]表示返回值的第一个字符串。\n\n**注意：由于WATCH命令的作用只是当被监控的键被修改后取消之后的事务，并不能保证其他客户端不修改监控的值，所以当EXEC命令执行失败之后需要手动重新执行整个事务。**\n\n执行EXEC命令之后会取消监控使用WATCH命令监控的键，如果不想执行事务中的命令，也可以使用UNWATCH命令来取消监控。\n\n# 声明\n本文为原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/30/Redis事务介绍/](http://qifuguang.me/2015/09/30/Redis事务介绍/)\n\n","slug":"Redis事务介绍","published":1,"updated":"2015-09-29T16:45:15.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovdf0053lo6bqn23a9ln"},{"title":"Redis主从复制","date":"2015-10-18T05:41:12.000Z","_content":"\n# 概述\n一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的，原因如下：  \n\n1. 从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大；\n2. 从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内容容量为256G，也不能将所有内容用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过**20G**。\n\n本文先讨论第一点的解决方案：**Redis主从复制**，第二点可以使用Redis集群解决，下一篇文章将介绍Redis集群。\n<!--more-->\n\n# 主从复制\n考虑如下一种场景：\n\n> 电子商务网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是\"多读少写\"。\n\n对于这种场景，我们可以使如下这种架构：\n![Redis主从复制结构图](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/主从复制架构.png)\n\n如图中所示，我们将一台Redis服务器作主库(Matser)，其他三台作为从库(Slave)，主库只负责写数据，每次有数据更新都将更新的数据同步到它所有的从库，而从库只负责读数据。这样一来，就有了两个好处：\n\n1. 读写分离，不仅可以提高服务器的负载能力，并且可以根据读请求的规模自由增加或者减少从库的数量，棒极了；\n2. 数据被复制成了了好几份，就算有一台机器出现故障，也可以使用其他机器的数据快速恢复。\n\n需要注意的是：在Redis主从模式中，一台主库可以拥有多个从库，但是一个从库只能隶属于一个主库。\n\n\n# 配置\n在Redis中，要实现主从复制架构非常简单，只需要在从数据库的配置文件中加上如下命令即可：\n\n```\nslaveof 主数据库地址  主数据库端口\n```\n主数据库不需要任何配置。\n\n# 示例\n下面将演示怎么实现一个简单的复制系统。我们在一台机器上起两个Redis实例，监听不同的端口，其中一个作为主库，另外一个作为从库。首先不加任何参数来启动一个Redis实例作为主数据库：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/启动主库.png)\n可以看到，主库监听的是6379端口。\n\n然后加上slaveof参数启动另一个Redis实例作为从库，并且监听6380端口：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/启动从库.png)\n从控制台输出中可以看到，从库已经连接到主库：126.0.0.1:6379了，看样子主从复制系统配置成功。我们可以分别在主库和从库中使用如下命令看一看当前实例在复制系统中的相关信息：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/Redis角色.png)\n\n接下来验证一把。\n\n首先在主库中设置一个键值：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> set test-sync winwill2012\nOK\n127.0.0.1:6379>\n```\n现在到从库中检查该值是否已经自动同步到了从库：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6380\n127.0.0.1:6380> get test-sync\n\"winwill2012\"\n127.0.0.1:6380>\n```\n\n可以看到，数据确实从主库同步到了从库.\n\n在默认情况下，从库是只读的，如果在从库中写数据将会报错：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6380\n127.0.0.1:6380> set x y\n(error) READONLY You can't write against a read only slave.\n127.0.0.1:6380>\n```\n但是可以在从库的配置文件中加上如下的配置项允许从库写数据：\n\n```\nslave-read-only no\n```\n但是，因为从库中修改的数据不会被同步到任何其他数据库，并且一旦主库修改了数据，从库的数据就会因为自动同步被覆盖，所以一般情况下，不建议将从库设置为可写。\n\n相同的道理，配置多台从库也使用相同的方法，都在从库的配置文件中加上slaveof参数即可。\n\n此外，我们可以在客户端使用命令\n\n```\nSLAVEOF 新主库地址  新主库端口\n```\n来修改当前数据库的主库，如果当前数据库已经是其他库的从库， 则当前数据库会停止和原来的数据库的同步而和新的数据库同步。\n\n最后，从数据库还可以通过运行命令：\n\n```\nSLAVEOF NO ONE\n```\n来停止接受来自其他数据库的同步而升级成为主库。\n\n# 原理\n上面说了配置主从复制系统的方法，并且举例例子详细说明，本节将介绍Redis主从复制的实现原理。\n\n当一个从数据库启动时，会向主数据库发送SYNC命令，主数据库收到命令后会开始在后台保存快照（即RDB持久化过程），并将保存快照期间接收到的命令缓存起来。当快照完成后，Redis会将快照文件和缓存的命令发给从数据库，从数据库收到数据后，会载入快照文件并执行缓存的命令。以上过程称为**复制初始化**。复制初始化之结束后，主数据库每收到写命令时就会将命令同步给从数据库，从而保证主从数据库数据一致，这一过程称为**复制同步阶段**。\n\n有两点需要注意：\n\n1. 当主从数据库之间的连接断开后，Redis2.8之前的版本会重新进行复制初始化过程，这样就使得主从数据库断开连接后数据恢复的过程的效率很低下。Redis2.8版本的一个重要改进就是断线支持有条件的增量数据传输，当从数据库再次连接到主数据库时，主数据库只需要将断线期间执行的命令发给从数据库即可，大大提高了Redis主从复制的实用性。\n2. 复制同步阶段贯穿整个主从同步过程的始终，直到主从关系终止为止。在复制过程中，即使关闭了RDB方式的持久化(删除所有save参数)，依旧会执行快照操作。\n\n# 乐观复制\nRedis采用了复制的策略。容忍在一定时间内主从数据库的内容是不同的，但是两者的数据最终会保持一致。具体来说，Redis主从数据库之间的复制数据的过程本身是异步的，这意味着，主数据库执行完客户端的写请求后会立即将命令在主数据库的执行结果返回给客户端，而不会等待从数据库收到该命令后再返回给客户端。这一特性保证了复制后主从数据库的性能不会受到影响，但另一方面也会产生一个主从数据库数据不一致的时间窗口，当主数据库执行一条写命令之后，主数据库的数据已经发生变动，然而在主数据库将该命令传送给从数据库之前，如果两个数据库之间的连接断开了，此时二者间的数据就不一致了。从这个角度看，主数据库无法得知命令最终同步给了几个从数据库，不过Redis提供了两个配置选项来限制只有至少同步给指定数量的数据库时，主数据库才是可写的：\n\n```\nmin-slaves-to-write 3\nmin-slave2-max-lag 10\n```\n第一个参数表示只有当3个或3个以上的从数据库连接到主库时，主数据库才是可写的，否则返回错误。\n第二个参数表示允许从数据库失去连接的最长时间，该选项默认是关闭的，在分布式系统中，打开并合理配置该选项可以降低主从架构因为网络分区导致的数据不一致问题。\n\n# 图结构\n从数据库不仅可以接收主数据库的数据，同时也可以作为主数据库存在，形成类似图的结构，如下图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/图结构.png)\nA中的数据会同步到B,C中，C中的数据会同步到D,E中。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/18/Redis主从复制](http://qifuguang.me/2015/10/18/Redis主从复制)\n","source":"_posts/Redis主从复制.md","raw":"title: Redis主从复制\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-10-18 13:41:12\n---\n\n# 概述\n一般来说，要将Redis运用于工程项目中，只使用一台Redis是万万不能的，原因如下：  \n\n1. 从结构上，单个Redis服务器会发生单点故障，并且一台服务器需要处理所有的请求负载，压力较大；\n2. 从容量上，单个Redis服务器内存容量有限，就算一台Redis服务器内容容量为256G，也不能将所有内容用作Redis存储内存，一般来说，单台Redis最大使用内存不应该超过**20G**。\n\n本文先讨论第一点的解决方案：**Redis主从复制**，第二点可以使用Redis集群解决，下一篇文章将介绍Redis集群。\n<!--more-->\n\n# 主从复制\n考虑如下一种场景：\n\n> 电子商务网站上的商品，一般都是一次上传，无数次浏览的，说专业点也就是\"多读少写\"。\n\n对于这种场景，我们可以使如下这种架构：\n![Redis主从复制结构图](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/主从复制架构.png)\n\n如图中所示，我们将一台Redis服务器作主库(Matser)，其他三台作为从库(Slave)，主库只负责写数据，每次有数据更新都将更新的数据同步到它所有的从库，而从库只负责读数据。这样一来，就有了两个好处：\n\n1. 读写分离，不仅可以提高服务器的负载能力，并且可以根据读请求的规模自由增加或者减少从库的数量，棒极了；\n2. 数据被复制成了了好几份，就算有一台机器出现故障，也可以使用其他机器的数据快速恢复。\n\n需要注意的是：在Redis主从模式中，一台主库可以拥有多个从库，但是一个从库只能隶属于一个主库。\n\n\n# 配置\n在Redis中，要实现主从复制架构非常简单，只需要在从数据库的配置文件中加上如下命令即可：\n\n```\nslaveof 主数据库地址  主数据库端口\n```\n主数据库不需要任何配置。\n\n# 示例\n下面将演示怎么实现一个简单的复制系统。我们在一台机器上起两个Redis实例，监听不同的端口，其中一个作为主库，另外一个作为从库。首先不加任何参数来启动一个Redis实例作为主数据库：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/启动主库.png)\n可以看到，主库监听的是6379端口。\n\n然后加上slaveof参数启动另一个Redis实例作为从库，并且监听6380端口：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/启动从库.png)\n从控制台输出中可以看到，从库已经连接到主库：126.0.0.1:6379了，看样子主从复制系统配置成功。我们可以分别在主库和从库中使用如下命令看一看当前实例在复制系统中的相关信息：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/Redis角色.png)\n\n接下来验证一把。\n\n首先在主库中设置一个键值：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6379\n127.0.0.1:6379> set test-sync winwill2012\nOK\n127.0.0.1:6379>\n```\n现在到从库中检查该值是否已经自动同步到了从库：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6380\n127.0.0.1:6380> get test-sync\n\"winwill2012\"\n127.0.0.1:6380>\n```\n\n可以看到，数据确实从主库同步到了从库.\n\n在默认情况下，从库是只读的，如果在从库中写数据将会报错：\n\n```\n[qifuguang@Mac~]$ /opt/soft/redis-3.0.4/src/redis-cli -p 6380\n127.0.0.1:6380> set x y\n(error) READONLY You can't write against a read only slave.\n127.0.0.1:6380>\n```\n但是可以在从库的配置文件中加上如下的配置项允许从库写数据：\n\n```\nslave-read-only no\n```\n但是，因为从库中修改的数据不会被同步到任何其他数据库，并且一旦主库修改了数据，从库的数据就会因为自动同步被覆盖，所以一般情况下，不建议将从库设置为可写。\n\n相同的道理，配置多台从库也使用相同的方法，都在从库的配置文件中加上slaveof参数即可。\n\n此外，我们可以在客户端使用命令\n\n```\nSLAVEOF 新主库地址  新主库端口\n```\n来修改当前数据库的主库，如果当前数据库已经是其他库的从库， 则当前数据库会停止和原来的数据库的同步而和新的数据库同步。\n\n最后，从数据库还可以通过运行命令：\n\n```\nSLAVEOF NO ONE\n```\n来停止接受来自其他数据库的同步而升级成为主库。\n\n# 原理\n上面说了配置主从复制系统的方法，并且举例例子详细说明，本节将介绍Redis主从复制的实现原理。\n\n当一个从数据库启动时，会向主数据库发送SYNC命令，主数据库收到命令后会开始在后台保存快照（即RDB持久化过程），并将保存快照期间接收到的命令缓存起来。当快照完成后，Redis会将快照文件和缓存的命令发给从数据库，从数据库收到数据后，会载入快照文件并执行缓存的命令。以上过程称为**复制初始化**。复制初始化之结束后，主数据库每收到写命令时就会将命令同步给从数据库，从而保证主从数据库数据一致，这一过程称为**复制同步阶段**。\n\n有两点需要注意：\n\n1. 当主从数据库之间的连接断开后，Redis2.8之前的版本会重新进行复制初始化过程，这样就使得主从数据库断开连接后数据恢复的过程的效率很低下。Redis2.8版本的一个重要改进就是断线支持有条件的增量数据传输，当从数据库再次连接到主数据库时，主数据库只需要将断线期间执行的命令发给从数据库即可，大大提高了Redis主从复制的实用性。\n2. 复制同步阶段贯穿整个主从同步过程的始终，直到主从关系终止为止。在复制过程中，即使关闭了RDB方式的持久化(删除所有save参数)，依旧会执行快照操作。\n\n# 乐观复制\nRedis采用了复制的策略。容忍在一定时间内主从数据库的内容是不同的，但是两者的数据最终会保持一致。具体来说，Redis主从数据库之间的复制数据的过程本身是异步的，这意味着，主数据库执行完客户端的写请求后会立即将命令在主数据库的执行结果返回给客户端，而不会等待从数据库收到该命令后再返回给客户端。这一特性保证了复制后主从数据库的性能不会受到影响，但另一方面也会产生一个主从数据库数据不一致的时间窗口，当主数据库执行一条写命令之后，主数据库的数据已经发生变动，然而在主数据库将该命令传送给从数据库之前，如果两个数据库之间的连接断开了，此时二者间的数据就不一致了。从这个角度看，主数据库无法得知命令最终同步给了几个从数据库，不过Redis提供了两个配置选项来限制只有至少同步给指定数量的数据库时，主数据库才是可写的：\n\n```\nmin-slaves-to-write 3\nmin-slave2-max-lag 10\n```\n第一个参数表示只有当3个或3个以上的从数据库连接到主库时，主数据库才是可写的，否则返回错误。\n第二个参数表示允许从数据库失去连接的最长时间，该选项默认是关闭的，在分布式系统中，打开并合理配置该选项可以降低主从架构因为网络分区导致的数据不一致问题。\n\n# 图结构\n从数据库不仅可以接收主数据库的数据，同时也可以作为主数据库存在，形成类似图的结构，如下图：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/Redis主从复制/图结构.png)\nA中的数据会同步到B,C中，C中的数据会同步到D,E中。\n\n# 声明\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/10/18/Redis主从复制](http://qifuguang.me/2015/10/18/Redis主从复制)\n","slug":"Redis主从复制","published":1,"updated":"2015-10-18T05:42:36.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovdl0058lo6bih8jg83x"},{"title":"Redis 3.0新特性","date":"2015-09-28T04:42:55.000Z","_content":"# Redis 3.0改进\nRedis 3.0.0 正式版终于到来了，与 RC6 版本比较，该版本改进包括：\n\n* 修复了无磁盘的复制问题 (Oran Agra)\n* 在角色变化后对 BLPOP 复制进行测试 (Salvatore Sanfilippo)\n* prepareClientToWrite() 错误处理方法的改进 (Salvatore Sanfilippo)\n* 移除 dict.c 中不再使用的函数(Salvatore Sanfilippo)\n<!--more-->\n\n# Redis 3.0新特性\nRedis 3.0 版本与 2.8 版本比较，主要新特性包括如下几个方面：\n\n* Redis Cluster —— 一个分布式的 Redis 实现\n* 全新的 \"embedded string\" 对象编码结果，更少的缓存丢失，在特定的工作负载下速度的大幅提升\n* AOF child -> parent 最终数据传输最小化延迟，通过在 AOF 重写过程中的  \"last write\" \n* 大幅提升 LRU 近似算法用于键的擦除\n* WAIT 命令堵塞等待写操作传输到指定数量的从节点\n* MIGRATE 连接缓存，大幅提升键移植的速度\n* MIGARTE 新的参数 COPY 和 REPLACE\n* CLIENT PAUSE 命令：在指定时间内停止处理客户端请求\n* BITCOUNT 性能提升\n* CONFIG SET 接受不同单位的内存值，例如 \"CONFIG SET maxmemory 1gb\".\n* Redis 日志格式小调整用于反应实例的角色 (master/slave) \n* INCR 性能提升\n\n下载地址：[http://download.redis.io/releases/redis-3.0.0.tar.gz](http://download.redis.io/releases/redis-3.0.0.tar.gz)\n\n# 参考\n1. [http://www.oschina.net/news/61115/redis-3-0-final](http://www.oschina.net/news/61115/redis-3-0-final)\n","source":"_posts/Redis-3-0新特性.md","raw":"title: Redis 3.0新特性\ntags: [Redis,NoSQL]\ncategories: [Redis,NoSQL]\ndate: 2015-09-28 12:42:55\n---\n# Redis 3.0改进\nRedis 3.0.0 正式版终于到来了，与 RC6 版本比较，该版本改进包括：\n\n* 修复了无磁盘的复制问题 (Oran Agra)\n* 在角色变化后对 BLPOP 复制进行测试 (Salvatore Sanfilippo)\n* prepareClientToWrite() 错误处理方法的改进 (Salvatore Sanfilippo)\n* 移除 dict.c 中不再使用的函数(Salvatore Sanfilippo)\n<!--more-->\n\n# Redis 3.0新特性\nRedis 3.0 版本与 2.8 版本比较，主要新特性包括如下几个方面：\n\n* Redis Cluster —— 一个分布式的 Redis 实现\n* 全新的 \"embedded string\" 对象编码结果，更少的缓存丢失，在特定的工作负载下速度的大幅提升\n* AOF child -> parent 最终数据传输最小化延迟，通过在 AOF 重写过程中的  \"last write\" \n* 大幅提升 LRU 近似算法用于键的擦除\n* WAIT 命令堵塞等待写操作传输到指定数量的从节点\n* MIGRATE 连接缓存，大幅提升键移植的速度\n* MIGARTE 新的参数 COPY 和 REPLACE\n* CLIENT PAUSE 命令：在指定时间内停止处理客户端请求\n* BITCOUNT 性能提升\n* CONFIG SET 接受不同单位的内存值，例如 \"CONFIG SET maxmemory 1gb\".\n* Redis 日志格式小调整用于反应实例的角色 (master/slave) \n* INCR 性能提升\n\n下载地址：[http://download.redis.io/releases/redis-3.0.0.tar.gz](http://download.redis.io/releases/redis-3.0.0.tar.gz)\n\n# 参考\n1. [http://www.oschina.net/news/61115/redis-3-0-final](http://www.oschina.net/news/61115/redis-3-0-final)\n","slug":"Redis-3-0新特性","published":1,"updated":"2015-09-28T05:18:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dovdp005dlo6bch4ofjy9"},{"title":"IntelliJ远程调试教程","date":"2015-09-18T08:08:56.000Z","_content":"# 概述\n\n对于分布式系统的调试不知道大家有什么好的方法。对于我来说，在知道远程调试这个方法之前就是在代码中打各种log，然后重新部署，上线，调试，这样比较费时。今天咱们来了解了解Java远程调试这个牛逼的功能，本文以Intellij IDEA为例讲解怎么使用远程调试。以[Thrift入门教程](http://qifuguang.me/2015/09/11/Thrift%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/)这篇文章中使用的程序作为例子。这个程序由Thrift服务端和客户端组成。描述一下远程调试需要解决的问题：\n\n<!--more-->\n>服务端程序运行在一台远程服务器上，我们可以在本地服务端的代码（前提是本地的代码必须和远程服务器运行的代码一致）中设置断点，每当有请求到远程服务器时时能够在本地知道远程服务端的此时的内部状态。\n\n下面按照步骤介绍怎么远程debug。\n\n# 使用特定JVM参数运行服务端代码\n要让远程服务器运行的代码支持远程调试，则启动的时候必须加上特定的JVM参数，这些参数是：\n\n```\n -Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=${debug_port}\n```\n\n其中的${debug_port}是用户自定义的，为debug端口，本例以5555端口为例。\n\n# 本地连接远程服务器debug端口\n打开Intellij IDEA，在顶部靠右的地方选择\"Edit Configurations...\"，进去之后点击+号，选择\"Remote\"，按照下图的只是填写红框内的内容，其中host为远程代码运行的机器的ip/hostname，port为上一步指定的debug_port，本例是5555\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/create_remote.png)\n然后点击Apply，最后点击OK即可\n\n# 启动debug模式\n 现在在上一步选择\"Edit Configurations...\"的下拉框的位置选择上一步创建的remote的名字，然后点击右边的debug按钮(长的像臭虫那个)，看控制台日志，如果出现类似**\"Connected to the target VM, address: 'xx.xx.xx.xx:5555', transport: 'socket'\"**的字样，就表示连接成功过了。\n ![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/start_remote.png)\n \n# 设置断点，开始调试\n远程debug模式已经开启，现在可以在需要调试的代码中打断点了，比如：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/create_debug_point.png)\n如图中所示，如果断点内有√，则表示选取的断点正确。\n\n\n现在在本地发送一个到远程服务器的请求，看本地控制台的bug界面，划到debugger这个标签，可以看到当前远程服务的内部状态（各种变量）已经全部显示出来了，并且在刚才设置了断点的地方，也显示了该行的变量值。\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/show_debug_result1.png)\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/show_debug_result2.png)\n\n# 注意事项\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/18/IntelliJ远程调试教程](http://qifuguang.me/2015/09/18/IntelliJ远程调试教程)\n\n","source":"_posts/IntelliJ远程调试教程.md","raw":"title: IntelliJ远程调试教程\ntags: [Java,工具]\ncategories: [Java,工具]\ndate: 2015-09-18 16:08:56\n---\n# 概述\n\n对于分布式系统的调试不知道大家有什么好的方法。对于我来说，在知道远程调试这个方法之前就是在代码中打各种log，然后重新部署，上线，调试，这样比较费时。今天咱们来了解了解Java远程调试这个牛逼的功能，本文以Intellij IDEA为例讲解怎么使用远程调试。以[Thrift入门教程](http://qifuguang.me/2015/09/11/Thrift%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/)这篇文章中使用的程序作为例子。这个程序由Thrift服务端和客户端组成。描述一下远程调试需要解决的问题：\n\n<!--more-->\n>服务端程序运行在一台远程服务器上，我们可以在本地服务端的代码（前提是本地的代码必须和远程服务器运行的代码一致）中设置断点，每当有请求到远程服务器时时能够在本地知道远程服务端的此时的内部状态。\n\n下面按照步骤介绍怎么远程debug。\n\n# 使用特定JVM参数运行服务端代码\n要让远程服务器运行的代码支持远程调试，则启动的时候必须加上特定的JVM参数，这些参数是：\n\n```\n -Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=${debug_port}\n```\n\n其中的${debug_port}是用户自定义的，为debug端口，本例以5555端口为例。\n\n# 本地连接远程服务器debug端口\n打开Intellij IDEA，在顶部靠右的地方选择\"Edit Configurations...\"，进去之后点击+号，选择\"Remote\"，按照下图的只是填写红框内的内容，其中host为远程代码运行的机器的ip/hostname，port为上一步指定的debug_port，本例是5555\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/create_remote.png)\n然后点击Apply，最后点击OK即可\n\n# 启动debug模式\n 现在在上一步选择\"Edit Configurations...\"的下拉框的位置选择上一步创建的remote的名字，然后点击右边的debug按钮(长的像臭虫那个)，看控制台日志，如果出现类似**\"Connected to the target VM, address: 'xx.xx.xx.xx:5555', transport: 'socket'\"**的字样，就表示连接成功过了。\n ![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/start_remote.png)\n \n# 设置断点，开始调试\n远程debug模式已经开启，现在可以在需要调试的代码中打断点了，比如：\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/create_debug_point.png)\n如图中所示，如果断点内有√，则表示选取的断点正确。\n\n\n现在在本地发送一个到远程服务器的请求，看本地控制台的bug界面，划到debugger这个标签，可以看到当前远程服务的内部状态（各种变量）已经全部显示出来了，并且在刚才设置了断点的地方，也显示了该行的变量值。\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/show_debug_result1.png)\n![](http://7xlune.com1.z0.glb.clouddn.com/images/IntelliJ远程调试教程/show_debug_result2.png)\n\n# 注意事项\n本文为作者原创，转载请注明出处，本文链接：[http://qifuguang.me/2015/09/18/IntelliJ远程调试教程](http://qifuguang.me/2015/09/18/IntelliJ远程调试教程)\n\n","slug":"IntelliJ远程调试教程","published":1,"updated":"2015-10-13T06:06:31.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dove1005llo6b7mdamhug"},{"title":"A记录和CNAME记录介绍","date":"2015-08-31T08:12:41.000Z","_content":"# 域名解析\n在互联网上访问网站的时候我们通常都是输入网址，比如[http://qifuguang.me](http://qifuguang.me)，通过这个网址怎么知道需要访问的资源是在哪里呢？答案就是域名解析，将一个网址映射到一个特定的IP地址的过程就叫做**域名解析**。域名的解析工作由DNS服务器完成。\n<!--more-->\n# A记录\nA记录即Address记录，字面意思就是地址记录，就是将一个域名或主机名解析成一个具体的IP地址。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的二级域名。\n\n# CNAME记录\nCNAME记录即别名记录。这种记录允许您将多个名字映射到另外一个域名。通常用于同时提供WWW和MAIL服务的计算机。例如，有一台计算机名为“host.mydomain.com”（A记录）。它同时提供WWW和MAIL服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW和MAIL。这两个别名的全称就 http://www.mydomain.com/和“mail.mydomain.com”。实际上他们都指向 “host.mydomain.com”。\n\n# A记录和CNAME记录的比较\nA记录就是把一个域名解析到一个IP地址（Address，特制数字IP地址），而CNAME记录就是把域名解析到另外一个域名。其功能是差不多，CNAME将几个主机名指向一个别名，其实跟指向IP地址是一样的，因为这个别名也要做一个A记录的。但是使用CNAME记录可以很方便地变更IP地址。如果一台服务器有100个网站，他们都做了别名，该台服务器变更IP时，只需要变更别名的A记录就可以了。\n\n# 使用哪种方式更好\n域名解析CNAME记录A记录哪一种比较好？如果论对网站的影响，就没有多大区别。但是：CNAME有一个好处就是稳定，就好像一个IP与一个域名的区别。服务商从方便维护的角度，一般也建议用户使用CNAME记录绑定域名的。如果主机使用了双线IP，显然使用CNAME也要方便一些。\nA记录也有一些好处，例如可以在输入域名时不用输入WWW.来访问网站哦！从SEO优化角度来看，一些搜索引擎如alex或一些搜索查询工具网站等等则默认是自动去掉WWW.来辨别网站，CNAME记录是必须有如：WWW(别名)前缀的域名，有时候会遇到这样的麻烦，前缀去掉了默认网站无法访问。\n有人认为，在SEO优化网站的时候，由于搜索引擎找不到去掉WWW.的域名时，对网站权重也会有些影响。因为有些网民客户也是不喜欢多写三个W来访问网站的，网站无法访问有少量网民客户会放弃继续尝试加WWW.访问域名了，因此网站访问浏览量也会减少一些。\n也有人认为同一个域名加WWW.和不加WWW.访问网站也会使网站权重分散，这也是个问题。但是可以使用301跳转把不加WWW.跳转到加WWW.的域名，问题就解决了。\n\n# 参考资料\n\n* [http://blog.xieyc.com/differences-between-a-record-and-cname-record/](http://blog.xieyc.com/differences-between-a-record-and-cname-record/)\n\n","source":"_posts/A记录与CNAME记录介绍.md","raw":"title: 'A记录和CNAME记录介绍'\ntags: [域名解析]\ncategories: [域名解析]\ndate: 2015-08-31 16:12:41\n---\n# 域名解析\n在互联网上访问网站的时候我们通常都是输入网址，比如[http://qifuguang.me](http://qifuguang.me)，通过这个网址怎么知道需要访问的资源是在哪里呢？答案就是域名解析，将一个网址映射到一个特定的IP地址的过程就叫做**域名解析**。域名的解析工作由DNS服务器完成。\n<!--more-->\n# A记录\nA记录即Address记录，字面意思就是地址记录，就是将一个域名或主机名解析成一个具体的IP地址。用户可以将该域名下的网站服务器指向到自己的web server上。同时也可以设置您域名的二级域名。\n\n# CNAME记录\nCNAME记录即别名记录。这种记录允许您将多个名字映射到另外一个域名。通常用于同时提供WWW和MAIL服务的计算机。例如，有一台计算机名为“host.mydomain.com”（A记录）。它同时提供WWW和MAIL服务，为了便于用户访问服务。可以为该计算机设置两个别名（CNAME）：WWW和MAIL。这两个别名的全称就 http://www.mydomain.com/和“mail.mydomain.com”。实际上他们都指向 “host.mydomain.com”。\n\n# A记录和CNAME记录的比较\nA记录就是把一个域名解析到一个IP地址（Address，特制数字IP地址），而CNAME记录就是把域名解析到另外一个域名。其功能是差不多，CNAME将几个主机名指向一个别名，其实跟指向IP地址是一样的，因为这个别名也要做一个A记录的。但是使用CNAME记录可以很方便地变更IP地址。如果一台服务器有100个网站，他们都做了别名，该台服务器变更IP时，只需要变更别名的A记录就可以了。\n\n# 使用哪种方式更好\n域名解析CNAME记录A记录哪一种比较好？如果论对网站的影响，就没有多大区别。但是：CNAME有一个好处就是稳定，就好像一个IP与一个域名的区别。服务商从方便维护的角度，一般也建议用户使用CNAME记录绑定域名的。如果主机使用了双线IP，显然使用CNAME也要方便一些。\nA记录也有一些好处，例如可以在输入域名时不用输入WWW.来访问网站哦！从SEO优化角度来看，一些搜索引擎如alex或一些搜索查询工具网站等等则默认是自动去掉WWW.来辨别网站，CNAME记录是必须有如：WWW(别名)前缀的域名，有时候会遇到这样的麻烦，前缀去掉了默认网站无法访问。\n有人认为，在SEO优化网站的时候，由于搜索引擎找不到去掉WWW.的域名时，对网站权重也会有些影响。因为有些网民客户也是不喜欢多写三个W来访问网站的，网站无法访问有少量网民客户会放弃继续尝试加WWW.访问域名了，因此网站访问浏览量也会减少一些。\n也有人认为同一个域名加WWW.和不加WWW.访问网站也会使网站权重分散，这也是个问题。但是可以使用301跳转把不加WWW.跳转到加WWW.的域名，问题就解决了。\n\n# 参考资料\n\n* [http://blog.xieyc.com/differences-between-a-record-and-cname-record/](http://blog.xieyc.com/differences-between-a-record-and-cname-record/)\n\n","slug":"A记录与CNAME记录介绍","published":1,"updated":"2015-09-04T02:42:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cig3dove4005rlo6b6iydswzl"},{"title":"[Java并发包学习九]Java中的阻塞队列","date":"2015-10-23T08:09:55.000Z","_content":"# 什么是阻塞队列\n\n阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n\n<!--more-->\n阻塞队列提供了四种处理方法:\n![Java中阻塞队列方法](http://7xlune.com1.z0.glb.clouddn.com/images/Java阻塞队列/阻塞队列方法.png)\n\n* **抛出异常**：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(\"Queue full\")异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。\n* **返回特殊值**：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null\n* **一直阻塞**：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。\n* **超时退出**：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。\n\n# Java里的阻塞队列\n\nJDK7提供了7个阻塞队列。分别是\n\n1. ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。\n2. LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。\n3. PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。\n4. DelayQueue：一个使用优先级队列实现的无界阻塞队列。\n5. SynchronousQueue：一个不存储元素的阻塞队列。\n6. LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。\n7. LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。\n\n## ArrayBlockingQueue\nArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。我们可以使用以下代码创建一个公平的阻塞队列：\n\n```\nArrayBlockingQueue fairQueue = new  ArrayBlockingQueue(1000,true);\n```\n\n访问者的公平性是使用可重入锁实现的，代码如下：\n\n```\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        if (capacity <= 0)\n            throw new IllegalArgumentException();\n        this.items = new Object[capacity];\n        lock = new ReentrantLock(fair);\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n}\n```\n\n## LinkedBlockingQueue\nLinkedBlockingQueue是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为`Integer.MAX_VALUE`。此队列按照先进先出的原则对元素进行排序。\n\n## PriorityBlockingQueue\nPriorityBlockingQueue是一个支持优先级的无界队列。默认情况下元素采取自然顺序排列，也可以通过比较器comparator来指定元素的排序规则。元素按照升序排列。\n\n## DelayQueue\nDelayQueue是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将DelayQueue运用在以下应用场景：\n\n1. 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。\n2. 定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。\n队列中的Delayed必须实现compareTo来指定元素的顺序。比如让延时时间最长的放在队列的末尾。实现代码如下：\n\n```\npublic int compareTo(Delayed other) {\n           if (other == this) // compare zero ONLY if same object\n                return 0;\n            if (other instanceof ScheduledFutureTask) {\n                ScheduledFutureTask x = (ScheduledFutureTask)other;\n                long diff = time - x.time;\n                if (diff < 0)\n                    return -1;\n                else if (diff > 0)\n                    return 1;\n       else if (sequenceNumber < x.sequenceNumber)\n                    return -1;\n                else\n                    return 1;\n            }\n            long d = (getDelay(TimeUnit.NANOSECONDS) -\n                      other.getDelay(TimeUnit.NANOSECONDS));\n            return (d == 0) ? 0 : ((d < 0) ? -1 : 1);\n        }\n```\n### 如何实现Delayed接口\n\n我们可以参考ScheduledThreadPoolExecutor里ScheduledFutureTask类。这个类实现了Delayed接口。首先：在对象创建的时候，使用time记录前对象什么时候可以使用，代码如下：\n\n```\nScheduledFutureTask(Runnable r, V result, long ns, long period) {\n            super(r, result);\n            this.time = ns;\n            this.period = period;\n            this.sequenceNumber = sequencer.getAndIncrement();\n}\n```\n然后使用getDelay可以查询当前元素还需要延时多久，代码如下：\n\n```\npublic long getDelay(TimeUnit unit) {\n            return unit.convert(time - now(), TimeUnit.NANOSECONDS);\n        }\n```\n通过构造函数可以看出延迟时间参数ns的单位是纳秒，自己设计的时候最好使用纳秒，因为getDelay时可以指定任意单位，一旦以纳秒作为单位，而延时的时间又精确不到纳秒就麻烦了。使用时请注意当time小于当前时间时，getDelay会返回负数。\n\n#### 如何实现延时队列\n\n延时队列的实现很简单，当消费者从队列里获取元素时，如果元素没有达到延时时间，就阻塞当前线程。\n\n```\nlong delay = first.getDelay(TimeUnit.NANOSECONDS);\n                    if (delay <= 0)\n                        return q.poll();\n                    else if (leader != null)\n                        available.await();\n```\n\n## SynchronousQueue\nSynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue的吞吐量高于LinkedBlockingQueue 和 ArrayBlockingQueue。\n\n## LinkedTransferQueue\nLinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。\n\n### transfer方法\n如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。transfer方法的关键代码如下：\n\n```\nNode pred = tryAppend(s, haveData);\nreturn awaitMatch(s, pred, e, (how == TIMED), nanos);\n```\n第一行代码是试图把存放当前元素的s节点作为tail节点。第二行代码是让CPU自旋等待消费者消费元素。因为自旋会消耗CPU，所以自旋一定的次数后使用Thread.yield()方法来暂停当前正在执行的线程，并执行其他线程。\n\n### tryTransfer方法\ntryTransfer方法则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。\n\n对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。\n\n## LinkedBlockingDeque\nLinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法，以First单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是Jdk的bug，使用时还是用带有First和Last后缀的方法更清楚。\n\n在初始化LinkedBlockingDeque时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。\n\n# 阻塞队列的实现原理\n\n如果队列是空的，消费者会一直等待，当生产者添加元素时候，消费者是如何知道当前队列有元素的呢？如果让你来设计阻塞队列你会如何设计，让生产者和消费者能够高效率的进行通讯呢？让我们先来看看JDK是如何实现的。\n\n使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看JDK源码发现ArrayBlockingQueue使用了Condition来实现，代码如下：\n\n```\nprivate final Condition notFull;\nprivate final Condition notEmpty;\n\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        //省略其他代码\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n    }\n\npublic void put(E e) throws InterruptedException {\n        checkNotNull(e);\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == items.length)\n                notFull.await();\n            insert(e);\n        } finally {\n            lock.unlock();\n        }\n}\n\npublic E take() throws InterruptedException {\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == 0)\n                notEmpty.await();\n            return extract();\n  } finally {\n            lock.unlock();\n        }\n}\n\nprivate void insert(E x) {\n        items[putIndex] = x;\n        putIndex = inc(putIndex);\n        ++count;\n        notEmpty.signal();\n    }\n```\n当我们往队列里插入一个元素时，如果队列不可用，阻塞生产者主要通过LockSupport.park(this)来实现\n\n```\npublic final void await() throws InterruptedException {\n            if (Thread.interrupted())\n                throw new InterruptedException();\n            Node node = addConditionWaiter();\n            int savedState = fullyRelease(node);\n            int interruptMode = 0;\n            while (!isOnSyncQueue(node)) {\n                LockSupport.park(this);\n                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n                    break;\n            }\n            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n                interruptMode = REINTERRUPT;\n            if (node.nextWaiter != null) // clean up if cancelled\n                unlinkCancelledWaiters();\n            if (interruptMode != 0)\n\nreportInterruptAfterWait(interruptMode);\n        }\n```\n继续进入源码，发现调用setBlocker先保存下将要阻塞的线程，然后调用unsafe.park阻塞当前线程。\n\n```\npublic static void park(Object blocker) {\n        Thread t = Thread.currentThread();\n        setBlocker(t, blocker);\n        unsafe.park(false, 0L);\n        setBlocker(t, null);\n    }\n```\nunsafe.park是个native方法，代码如下：\n\n```\npublic native void park(boolean isAbsolute, long time);\n```\npark这个方法会阻塞当前线程，只有以下四种情况中的一种发生时，该方法才会返回。\n\n* 与park对应的unpark执行或已经执行时。注意：已经执行是指unpark先执行，然后再执行的park。\n* 线程被中断时。\n* 如果参数中的time不是零，等待了指定的毫秒数时。\n* 发生异常现象时。这些异常事先无法确定。\n\n我们继续看一下JVM是如何实现park方法的，park在不同的操作系统使用不同的方式实现，在linux下是使用的是系统方法pthread_cond_wait实现。实现代码在JVM源码路径src/os/linux/vm/os_linux.cpp里的 os::PlatformEvent::park方法，代码如下：\n\n```\nvoid os::PlatformEvent::park() {      \n             int v ;\n         for (;;) {\n        v = _Event ;\n         if (Atomic::cmpxchg (v-1, &_Event, v) == v) break ;\n         }\n         guarantee (v >= 0, \"invariant\") ;\n         if (v == 0) {\n         // Do this the hard way by blocking ...\n         int status = pthread_mutex_lock(_mutex);\n         assert_status(status == 0, status, \"mutex_lock\");\n         guarantee (_nParked == 0, \"invariant\") ;\n         ++ _nParked ;\n         while (_Event < 0) {\n         status = pthread_cond_wait(_cond, _mutex);\n         // for some reason, under 2.7 lwp_cond_wait() may return ETIME ...\n         // Treat this the same as if the wait was interrupted\n         if (status == ETIME) { status = EINTR; }\n         assert_status(status == 0 || status == EINTR, status, \"cond_wait\");\n         }\n         -- _nParked ;\n         \n         // In theory we could move the ST of 0 into _Event past the unlock(),\n         // but then we'd need a MEMBAR after the ST.\n         _Event = 0 ;\n         status = pthread_mutex_unlock(_mutex);\n         assert_status(status == 0, status, \"mutex_unlock\");\n         }\n         guarantee (_Event >= 0, \"invariant\") ;\n         }\n\n     }\n```\npthread_cond_wait是一个多线程的条件变量函数，cond是condition的缩写，字面意思可以理解为线程在等待一个条件发生，这个条件是一个全局变量。这个方法接收两个参数，一个共享变量_cond，一个互斥量_mutex。而unpark方法在linux下是使用pthread_cond_signal实现的。park 在windows下则是使用WaitForSingleObject实现的。\n\n当队列满时，生产者往阻塞队列里插入一个元素，生产者线程会进入WAITING (parking)状态。我们可以使用jstack dump阻塞的生产者线程看到这点：\n\n```\n\"main\" prio=5 tid=0x00007fc83c000000 nid=0x10164e000 waiting on condition [0x000000010164d000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000140559fe8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:324)\n        at blockingqueue.ArrayBlockingQueueTest.main(ArrayBlockingQueueTest.java:11)\n```\n\n# 声明\n本文转载自：[http://www.infoq.com/cn/articles/java-blocking-queue/](http://www.infoq.com/cn/articles/java-blocking-queue/)\n","source":"_posts/Java并发包学习九-Java中的阻塞队列.md","raw":"title: '[Java并发包学习九]Java中的阻塞队列'\ntags: [Java并发包学习]\ncategories: [Java并发包学习]\ndate: 2015-10-23 16:09:55\n---\n# 什么是阻塞队列\n\n阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。\n\n<!--more-->\n阻塞队列提供了四种处理方法:\n![Java中阻塞队列方法](http://7xlune.com1.z0.glb.clouddn.com/images/Java阻塞队列/阻塞队列方法.png)\n\n* **抛出异常**：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(\"Queue full\")异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。\n* **返回特殊值**：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null\n* **一直阻塞**：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。\n* **超时退出**：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。\n\n# Java里的阻塞队列\n\nJDK7提供了7个阻塞队列。分别是\n\n1. ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列。\n2. LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列。\n3. PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。\n4. DelayQueue：一个使用优先级队列实现的无界阻塞队列。\n5. SynchronousQueue：一个不存储元素的阻塞队列。\n6. LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。\n7. LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。\n\n## ArrayBlockingQueue\nArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。我们可以使用以下代码创建一个公平的阻塞队列：\n\n```\nArrayBlockingQueue fairQueue = new  ArrayBlockingQueue(1000,true);\n```\n\n访问者的公平性是使用可重入锁实现的，代码如下：\n\n```\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        if (capacity <= 0)\n            throw new IllegalArgumentException();\n        this.items = new Object[capacity];\n        lock = new ReentrantLock(fair);\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n}\n```\n\n## LinkedBlockingQueue\nLinkedBlockingQueue是一个用链表实现的有界阻塞队列。此队列的默认和最大长度为`Integer.MAX_VALUE`。此队列按照先进先出的原则对元素进行排序。\n\n## PriorityBlockingQueue\nPriorityBlockingQueue是一个支持优先级的无界队列。默认情况下元素采取自然顺序排列，也可以通过比较器comparator来指定元素的排序规则。元素按照升序排列。\n\n## DelayQueue\nDelayQueue是一个支持延时获取元素的无界阻塞队列。队列使用PriorityQueue来实现。队列中的元素必须实现Delayed接口，在创建元素时可以指定多久才能从队列中获取当前元素。只有在延迟期满时才能从队列中提取元素。我们可以将DelayQueue运用在以下应用场景：\n\n1. 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。\n2. 定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。\n队列中的Delayed必须实现compareTo来指定元素的顺序。比如让延时时间最长的放在队列的末尾。实现代码如下：\n\n```\npublic int compareTo(Delayed other) {\n           if (other == this) // compare zero ONLY if same object\n                return 0;\n            if (other instanceof ScheduledFutureTask) {\n                ScheduledFutureTask x = (ScheduledFutureTask)other;\n                long diff = time - x.time;\n                if (diff < 0)\n                    return -1;\n                else if (diff > 0)\n                    return 1;\n       else if (sequenceNumber < x.sequenceNumber)\n                    return -1;\n                else\n                    return 1;\n            }\n            long d = (getDelay(TimeUnit.NANOSECONDS) -\n                      other.getDelay(TimeUnit.NANOSECONDS));\n            return (d == 0) ? 0 : ((d < 0) ? -1 : 1);\n        }\n```\n### 如何实现Delayed接口\n\n我们可以参考ScheduledThreadPoolExecutor里ScheduledFutureTask类。这个类实现了Delayed接口。首先：在对象创建的时候，使用time记录前对象什么时候可以使用，代码如下：\n\n```\nScheduledFutureTask(Runnable r, V result, long ns, long period) {\n            super(r, result);\n            this.time = ns;\n            this.period = period;\n            this.sequenceNumber = sequencer.getAndIncrement();\n}\n```\n然后使用getDelay可以查询当前元素还需要延时多久，代码如下：\n\n```\npublic long getDelay(TimeUnit unit) {\n            return unit.convert(time - now(), TimeUnit.NANOSECONDS);\n        }\n```\n通过构造函数可以看出延迟时间参数ns的单位是纳秒，自己设计的时候最好使用纳秒，因为getDelay时可以指定任意单位，一旦以纳秒作为单位，而延时的时间又精确不到纳秒就麻烦了。使用时请注意当time小于当前时间时，getDelay会返回负数。\n\n#### 如何实现延时队列\n\n延时队列的实现很简单，当消费者从队列里获取元素时，如果元素没有达到延时时间，就阻塞当前线程。\n\n```\nlong delay = first.getDelay(TimeUnit.NANOSECONDS);\n                    if (delay <= 0)\n                        return q.poll();\n                    else if (leader != null)\n                        available.await();\n```\n\n## SynchronousQueue\nSynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。SynchronousQueue可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景,比如在一个线程中使用的数据，传递给另外一个线程使用，SynchronousQueue的吞吐量高于LinkedBlockingQueue 和 ArrayBlockingQueue。\n\n## LinkedTransferQueue\nLinkedTransferQueue是一个由链表结构组成的无界阻塞TransferQueue队列。相对于其他阻塞队列，LinkedTransferQueue多了tryTransfer和transfer方法。\n\n### transfer方法\n如果当前有消费者正在等待接收元素（消费者使用take()方法或带时间限制的poll()方法时），transfer方法可以把生产者传入的元素立刻transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer方法会将元素存放在队列的tail节点，并等到该元素被消费者消费了才返回。transfer方法的关键代码如下：\n\n```\nNode pred = tryAppend(s, haveData);\nreturn awaitMatch(s, pred, e, (how == TIMED), nanos);\n```\n第一行代码是试图把存放当前元素的s节点作为tail节点。第二行代码是让CPU自旋等待消费者消费元素。因为自旋会消耗CPU，所以自旋一定的次数后使用Thread.yield()方法来暂停当前正在执行的线程，并执行其他线程。\n\n### tryTransfer方法\ntryTransfer方法则是用来试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回false。和transfer方法的区别是tryTransfer方法无论消费者是否接收，方法立即返回。而transfer方法是必须等到消费者消费了才返回。\n\n对于带有时间限制的tryTransfer(E e, long timeout, TimeUnit unit)方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回false，如果在超时时间内消费了元素，则返回true。\n\n## LinkedBlockingDeque\nLinkedBlockingDeque是一个由链表结构组成的双向阻塞队列。所谓双向队列指的你可以从队列的两端插入和移出元素。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque多了addFirst，addLast，offerFirst，offerLast，peekFirst，peekLast等方法，以First单词结尾的方法，表示插入，获取（peek）或移除双端队列的第一个元素。以Last单词结尾的方法，表示插入，获取或移除双端队列的最后一个元素。另外插入方法add等同于addLast，移除方法remove等效于removeFirst。但是take方法却等同于takeFirst，不知道是不是Jdk的bug，使用时还是用带有First和Last后缀的方法更清楚。\n\n在初始化LinkedBlockingDeque时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。\n\n# 阻塞队列的实现原理\n\n如果队列是空的，消费者会一直等待，当生产者添加元素时候，消费者是如何知道当前队列有元素的呢？如果让你来设计阻塞队列你会如何设计，让生产者和消费者能够高效率的进行通讯呢？让我们先来看看JDK是如何实现的。\n\n使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中的元素后，会通知生产者当前队列可用。通过查看JDK源码发现ArrayBlockingQueue使用了Condition来实现，代码如下：\n\n```\nprivate final Condition notFull;\nprivate final Condition notEmpty;\n\npublic ArrayBlockingQueue(int capacity, boolean fair) {\n        //省略其他代码\n        notEmpty = lock.newCondition();\n        notFull =  lock.newCondition();\n    }\n\npublic void put(E e) throws InterruptedException {\n        checkNotNull(e);\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == items.length)\n                notFull.await();\n            insert(e);\n        } finally {\n            lock.unlock();\n        }\n}\n\npublic E take() throws InterruptedException {\n        final ReentrantLock lock = this.lock;\n        lock.lockInterruptibly();\n        try {\n            while (count == 0)\n                notEmpty.await();\n            return extract();\n  } finally {\n            lock.unlock();\n        }\n}\n\nprivate void insert(E x) {\n        items[putIndex] = x;\n        putIndex = inc(putIndex);\n        ++count;\n        notEmpty.signal();\n    }\n```\n当我们往队列里插入一个元素时，如果队列不可用，阻塞生产者主要通过LockSupport.park(this)来实现\n\n```\npublic final void await() throws InterruptedException {\n            if (Thread.interrupted())\n                throw new InterruptedException();\n            Node node = addConditionWaiter();\n            int savedState = fullyRelease(node);\n            int interruptMode = 0;\n            while (!isOnSyncQueue(node)) {\n                LockSupport.park(this);\n                if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)\n                    break;\n            }\n            if (acquireQueued(node, savedState) && interruptMode != THROW_IE)\n                interruptMode = REINTERRUPT;\n            if (node.nextWaiter != null) // clean up if cancelled\n                unlinkCancelledWaiters();\n            if (interruptMode != 0)\n\nreportInterruptAfterWait(interruptMode);\n        }\n```\n继续进入源码，发现调用setBlocker先保存下将要阻塞的线程，然后调用unsafe.park阻塞当前线程。\n\n```\npublic static void park(Object blocker) {\n        Thread t = Thread.currentThread();\n        setBlocker(t, blocker);\n        unsafe.park(false, 0L);\n        setBlocker(t, null);\n    }\n```\nunsafe.park是个native方法，代码如下：\n\n```\npublic native void park(boolean isAbsolute, long time);\n```\npark这个方法会阻塞当前线程，只有以下四种情况中的一种发生时，该方法才会返回。\n\n* 与park对应的unpark执行或已经执行时。注意：已经执行是指unpark先执行，然后再执行的park。\n* 线程被中断时。\n* 如果参数中的time不是零，等待了指定的毫秒数时。\n* 发生异常现象时。这些异常事先无法确定。\n\n我们继续看一下JVM是如何实现park方法的，park在不同的操作系统使用不同的方式实现，在linux下是使用的是系统方法pthread_cond_wait实现。实现代码在JVM源码路径src/os/linux/vm/os_linux.cpp里的 os::PlatformEvent::park方法，代码如下：\n\n```\nvoid os::PlatformEvent::park() {      \n             int v ;\n         for (;;) {\n        v = _Event ;\n         if (Atomic::cmpxchg (v-1, &_Event, v) == v) break ;\n         }\n         guarantee (v >= 0, \"invariant\") ;\n         if (v == 0) {\n         // Do this the hard way by blocking ...\n         int status = pthread_mutex_lock(_mutex);\n         assert_status(status == 0, status, \"mutex_lock\");\n         guarantee (_nParked == 0, \"invariant\") ;\n         ++ _nParked ;\n         while (_Event < 0) {\n         status = pthread_cond_wait(_cond, _mutex);\n         // for some reason, under 2.7 lwp_cond_wait() may return ETIME ...\n         // Treat this the same as if the wait was interrupted\n         if (status == ETIME) { status = EINTR; }\n         assert_status(status == 0 || status == EINTR, status, \"cond_wait\");\n         }\n         -- _nParked ;\n         \n         // In theory we could move the ST of 0 into _Event past the unlock(),\n         // but then we'd need a MEMBAR after the ST.\n         _Event = 0 ;\n         status = pthread_mutex_unlock(_mutex);\n         assert_status(status == 0, status, \"mutex_unlock\");\n         }\n         guarantee (_Event >= 0, \"invariant\") ;\n         }\n\n     }\n```\npthread_cond_wait是一个多线程的条件变量函数，cond是condition的缩写，字面意思可以理解为线程在等待一个条件发生，这个条件是一个全局变量。这个方法接收两个参数，一个共享变量_cond，一个互斥量_mutex。而unpark方法在linux下是使用pthread_cond_signal实现的。park 在windows下则是使用WaitForSingleObject实现的。\n\n当队列满时，生产者往阻塞队列里插入一个元素，生产者线程会进入WAITING (parking)状态。我们可以使用jstack dump阻塞的生产者线程看到这点：\n\n```\n\"main\" prio=5 tid=0x00007fc83c000000 nid=0x10164e000 waiting on condition [0x000000010164d000]\n   java.lang.Thread.State: WAITING (parking)\n        at sun.misc.Unsafe.park(Native Method)\n        - parking to wait for  <0x0000000140559fe8> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)\n        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:186)\n        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2043)\n        at java.util.concurrent.ArrayBlockingQueue.put(ArrayBlockingQueue.java:324)\n        at blockingqueue.ArrayBlockingQueueTest.main(ArrayBlockingQueueTest.java:11)\n```\n\n# 声明\n本文转载自：[http://www.infoq.com/cn/articles/java-blocking-queue/](http://www.infoq.com/cn/articles/java-blocking-queue/)\n","slug":"Java并发包学习九-Java中的阻塞队列","published":1,"updated":"2015-10-23T08:16:13.000Z","_id":"cig3dsxgd0000qb6be67qt79n","comments":1,"layout":"post","photos":[],"link":""}],"PostAsset":[],"PostCategory":[{"post_id":"cig3dov970003lo6bex6aqoe2","category_id":"cig3dov9b0004lo6bx0lzwww7","_id":"cig3dov9d0007lo6bvb2la9ui"},{"post_id":"cig3dov9e0008lo6bt0t16hhn","category_id":"cig3dov9b0004lo6bx0lzwww7","_id":"cig3dov9f0009lo6baq7xha6b"},{"post_id":"cig3dov9w000blo6bv6r0c547","category_id":"cig3dov9b0004lo6bx0lzwww7","_id":"cig3dov9x000clo6bd3qg5p21"},{"post_id":"cig3dov9y000elo6bqcr74kwf","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dov9z000ilo6b6xybb1dc"},{"post_id":"cig3dova0000jlo6bqnduy1ug","category_id":"cig3dova1000klo6bxtf67u6s","_id":"cig3dova2000nlo6b73z64y4p"},{"post_id":"cig3dova2000olo6bf6ab9nvl","category_id":"cig3dova3000plo6bwoo7df9q","_id":"cig3dova4000slo6b2ecwlvpm"},{"post_id":"cig3dova5000tlo6b4ou7hlcm","category_id":"cig3dova3000plo6bwoo7df9q","_id":"cig3dova6000ulo6bxehfktfa"},{"post_id":"cig3dova7000wlo6b41pfijeb","category_id":"cig3dova8000xlo6bs18in1it","_id":"cig3dova90010lo6bffcpdb41"},{"post_id":"cig3dovaa0011lo6b6npqq66o","category_id":"cig3dovab0012lo6bc2ew4jn5","_id":"cig3dovab0015lo6b5mkr7cej"},{"post_id":"cig3dovac0016lo6bx2d8kvi3","category_id":"cig3dovad0017lo6buac4e63z","_id":"cig3dovae001clo6b0xs4c1uq"},{"post_id":"cig3dovac0016lo6bx2d8kvi3","category_id":"cig3dovad001alo6b20gpqn3v","_id":"cig3dovae001elo6bwzc51fb4"},{"post_id":"cig3dovaf001flo6bivs6kwxz","category_id":"cig3dovag001glo6b32y4d3hq","_id":"cig3dovag001jlo6bowben3jy"},{"post_id":"cig3dovah001klo6bggacybgj","category_id":"cig3dovag001glo6b32y4d3hq","_id":"cig3dovai001llo6bd9xsvpcr"},{"post_id":"cig3dovaj001nlo6brprbyg3u","category_id":"cig3dovag001glo6b32y4d3hq","_id":"cig3dovak001olo6bz9kxraj5"},{"post_id":"cig3doval001qlo6bmn2o3yu7","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovan001ulo6b4yderoid"},{"post_id":"cig3dovao001vlo6b91g5tgte","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovap001wlo6b0n8kugr3"},{"post_id":"cig3dovaq001ylo6bwgf18qxw","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovar001zlo6biriaetll"},{"post_id":"cig3dovas0021lo6bv9lxi5f5","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovat0022lo6b51biebdn"},{"post_id":"cig3dovau0024lo6b193ot3dl","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovav0025lo6bcv6su5ji"},{"post_id":"cig3dovaw0027lo6bo8xk0ui7","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovaw0028lo6b4twozeno"},{"post_id":"cig3dovax002alo6b6zp6qu5q","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovay002blo6b9svijgqm"},{"post_id":"cig3dovay002dlo6b0befu9eo","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dovaz002elo6b4o1lef8v"},{"post_id":"cig3dovb1002glo6bksajfdoz","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovb3002hlo6by78iyyet"},{"post_id":"cig3dovb3002jlo6bq433xm1n","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovb4002klo6b5ktxpsni"},{"post_id":"cig3dovb5002mlo6bukl0v2xj","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovb6002nlo6bnbtc1x1a"},{"post_id":"cig3dovb7002plo6baq7cetj2","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovb8002qlo6bgzgjcjel"},{"post_id":"cig3dovb8002slo6bcb1epbea","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovba002tlo6b909i2jqs"},{"post_id":"cig3dovbb002vlo6b6g7z5wkc","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovbc002wlo6bujyhsaq4"},{"post_id":"cig3dovbd002ylo6bvhccls77","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovbe002zlo6b04son6qv"},{"post_id":"cig3dovbf0031lo6bnsb9k8ur","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dovbg0032lo6bikx1dg7f"},{"post_id":"cig3dovbj0034lo6bpe4uuk20","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbl0038lo6bvb6htk3x"},{"post_id":"cig3dovbm0039lo6bh3tr2yyd","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbn003alo6b0feo85x7"},{"post_id":"cig3dovbo003clo6bd4bukn6y","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbp003dlo6bkwqub72i"},{"post_id":"cig3dovbr003flo6by95eskxq","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbs003glo6bqywymwbu"},{"post_id":"cig3dovbt003ilo6b114veao2","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbu003jlo6becsec2zo"},{"post_id":"cig3dovbv003llo6bzev02id2","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovbw003mlo6b7xq8gsjt"},{"post_id":"cig3dovbz003olo6bexx0ezxk","category_id":"cig3dovbk0035lo6bbx4ffoc4","_id":"cig3dovc0003plo6bud0azm59"},{"post_id":"cig3dovc8003rlo6bu0p487k9","category_id":"cig3dovc9003slo6b96gb7kdo","_id":"cig3dovca003vlo6buu4xclhi"},{"post_id":"cig3dovcd003wlo6by5dwqn1g","category_id":"cig3dovc9003slo6b96gb7kdo","_id":"cig3dovcd003xlo6b3tfir49d"},{"post_id":"cig3dovcf003zlo6bqvs2c5ap","category_id":"cig3dovc9003slo6b96gb7kdo","_id":"cig3dovcg0040lo6bu8q6gnc9"},{"post_id":"cig3dovch0042lo6bi0qw2k9e","category_id":"cig3dovci0043lo6bupai1j7q","_id":"cig3dovci0046lo6bxj7u91ae"},{"post_id":"cig3dovck0047lo6bmsqctfhn","category_id":"cig3dovck0048lo6bfyhvc881","_id":"cig3dovcl004blo6bnufrq1qs"},{"post_id":"cig3dovcm004clo6bqdw585rt","category_id":"cig3dovcn004dlo6b4rzhpr6u","_id":"cig3dovco004glo6beny4w7la"},{"post_id":"cig3dovcp004hlo6bsbhggedq","category_id":"cig3dova1000klo6bxtf67u6s","_id":"cig3dovcq004ilo6b85ph7vnp"},{"post_id":"cig3dovcs004klo6b6fsz863w","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovcw004qlo6bt5qm2e8d"},{"post_id":"cig3dovcs004klo6b6fsz863w","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovcw004slo6bfra4f7tb"},{"post_id":"cig3dovd7004tlo6btks5twdv","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovd9004ulo6bm0bwl63r"},{"post_id":"cig3dovd7004tlo6btks5twdv","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovd9004wlo6bkbxbsbon"},{"post_id":"cig3dovdc004ylo6b27l13kgi","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovdd004zlo6bz7jvssxj"},{"post_id":"cig3dovdc004ylo6b27l13kgi","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovde0051lo6bdkm7g529"},{"post_id":"cig3dovdf0053lo6bqn23a9ln","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovdh0054lo6b58c5bhil"},{"post_id":"cig3dovdf0053lo6bqn23a9ln","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovdh0056lo6b4glyg4y0"},{"post_id":"cig3dovdl0058lo6bih8jg83x","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovdl0059lo6brh67w7mg"},{"post_id":"cig3dovdl0058lo6bih8jg83x","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovdm005blo6bcwnmesyj"},{"post_id":"cig3dovdp005dlo6bch4ofjy9","category_id":"cig3dovct004llo6bpustqsox","_id":"cig3dovdq005elo6bzs8njjbd"},{"post_id":"cig3dovdp005dlo6bch4ofjy9","category_id":"cig3dovcu004olo6burtkurop","_id":"cig3dovdq005glo6bghbmlxja"},{"post_id":"cig3dove1005llo6b7mdamhug","category_id":"cig3dov9y000flo6b1chgfkui","_id":"cig3dove2005plo6b2i7v7kn6"},{"post_id":"cig3dove1005llo6b7mdamhug","category_id":"cig3dove2005mlo6bgbnxpc5y","_id":"cig3dove2005qlo6b5wdbcj0n"},{"post_id":"cig3dove4005rlo6b6iydswzl","category_id":"cig3dove5005slo6bc685ykuf","_id":"cig3dove5005vlo6bx77ryr3x"},{"post_id":"cig3dsxgd0000qb6be67qt79n","category_id":"cig3dovam001rlo6b4bl5jd8g","_id":"cig3dvjty0000tm6bcg73alcb"}],"PostTag":[{"post_id":"cig3dov970003lo6bex6aqoe2","tag_id":"cig3dov9b0005lo6bjlnuiya9","_id":"cig3dov9d0006lo6buq72zu3r"},{"post_id":"cig3dov9e0008lo6bt0t16hhn","tag_id":"cig3dov9b0005lo6bjlnuiya9","_id":"cig3dov9f000alo6bft4peljf"},{"post_id":"cig3dov9w000blo6bv6r0c547","tag_id":"cig3dov9b0005lo6bjlnuiya9","_id":"cig3dov9x000dlo6b84x4zdzt"},{"post_id":"cig3dov9y000elo6bqcr74kwf","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dov9z000hlo6bafjxwj20"},{"post_id":"cig3dova0000jlo6bqnduy1ug","tag_id":"cig3dova1000llo6bss47r9wd","_id":"cig3dova2000mlo6bduqk5cux"},{"post_id":"cig3dova2000olo6bf6ab9nvl","tag_id":"cig3dova3000qlo6bvdmycx4s","_id":"cig3dova4000rlo6b6hc8xxr4"},{"post_id":"cig3dova5000tlo6b4ou7hlcm","tag_id":"cig3dova3000qlo6bvdmycx4s","_id":"cig3dova6000vlo6bkfdwi6i2"},{"post_id":"cig3dova7000wlo6b41pfijeb","tag_id":"cig3dova8000ylo6b1hh44959","_id":"cig3dova9000zlo6b81k8kl26"},{"post_id":"cig3dovaa0011lo6b6npqq66o","tag_id":"cig3dovab0013lo6bcznqntj7","_id":"cig3dovab0014lo6bqm65ra32"},{"post_id":"cig3dovac0016lo6bx2d8kvi3","tag_id":"cig3dovad0018lo6bhumprphn","_id":"cig3dovae001blo6bz09wddn2"},{"post_id":"cig3dovac0016lo6bx2d8kvi3","tag_id":"cig3dovad0019lo6b0hbogpqp","_id":"cig3dovae001dlo6b4gelmt60"},{"post_id":"cig3dovaf001flo6bivs6kwxz","tag_id":"cig3dovag001hlo6bqpumjaml","_id":"cig3dovag001ilo6bw7litlyv"},{"post_id":"cig3dovah001klo6bggacybgj","tag_id":"cig3dovag001hlo6bqpumjaml","_id":"cig3dovai001mlo6bf689n0e0"},{"post_id":"cig3dovaj001nlo6brprbyg3u","tag_id":"cig3dovag001hlo6bqpumjaml","_id":"cig3dovak001plo6bcv8idq6c"},{"post_id":"cig3doval001qlo6bmn2o3yu7","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovan001tlo6b7n747azu"},{"post_id":"cig3dovao001vlo6b91g5tgte","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovap001xlo6bkqb9rp1q"},{"post_id":"cig3dovaq001ylo6bwgf18qxw","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovar0020lo6bndjpgp55"},{"post_id":"cig3dovas0021lo6bv9lxi5f5","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovat0023lo6bgtsjbl96"},{"post_id":"cig3dovau0024lo6b193ot3dl","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovav0026lo6bksaendhz"},{"post_id":"cig3dovaw0027lo6bo8xk0ui7","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovaw0029lo6bwobhjx9i"},{"post_id":"cig3dovax002alo6b6zp6qu5q","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovay002clo6bx4ptuqhd"},{"post_id":"cig3dovay002dlo6b0befu9eo","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dovb0002flo6b43t21hdl"},{"post_id":"cig3dovb1002glo6bksajfdoz","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovb3002ilo6b7y2oqimm"},{"post_id":"cig3dovb3002jlo6bq433xm1n","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovb4002llo6bm09wpwun"},{"post_id":"cig3dovb5002mlo6bukl0v2xj","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovb6002olo6bjyyixnji"},{"post_id":"cig3dovb7002plo6baq7cetj2","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovb8002rlo6bkbzwrfkt"},{"post_id":"cig3dovb8002slo6bcb1epbea","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovba002ulo6bj7krro7j"},{"post_id":"cig3dovbb002vlo6b6g7z5wkc","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovbd002xlo6bkgvor4m5"},{"post_id":"cig3dovbd002ylo6bvhccls77","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovbe0030lo6bfnbur7l4"},{"post_id":"cig3dovbf0031lo6bnsb9k8ur","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dovbg0033lo6b595frx1r"},{"post_id":"cig3dovbj0034lo6bpe4uuk20","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbl0037lo6bcc5ni44x"},{"post_id":"cig3dovbm0039lo6bh3tr2yyd","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbn003blo6b5u95inw9"},{"post_id":"cig3dovbo003clo6bd4bukn6y","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbq003elo6b5e17mlau"},{"post_id":"cig3dovbr003flo6by95eskxq","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbs003hlo6bpa8q5ry2"},{"post_id":"cig3dovbt003ilo6b114veao2","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbu003klo6b4ccoh3k0"},{"post_id":"cig3dovbv003llo6bzev02id2","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovbw003nlo6bpfsygnm3"},{"post_id":"cig3dovbz003olo6bexx0ezxk","tag_id":"cig3dovbk0036lo6bvzmoff9v","_id":"cig3dovc0003qlo6bs2dz80xl"},{"post_id":"cig3dovc8003rlo6bu0p487k9","tag_id":"cig3dovc9003tlo6bb8dmg5kk","_id":"cig3dovca003ulo6bqlka1z47"},{"post_id":"cig3dovcd003wlo6by5dwqn1g","tag_id":"cig3dovc9003tlo6bb8dmg5kk","_id":"cig3dovce003ylo6bq5srx0oc"},{"post_id":"cig3dovcf003zlo6bqvs2c5ap","tag_id":"cig3dovc9003tlo6bb8dmg5kk","_id":"cig3dovcg0041lo6bjr55wvwu"},{"post_id":"cig3dovch0042lo6bi0qw2k9e","tag_id":"cig3dovci0044lo6bppc7qjww","_id":"cig3dovci0045lo6bzig2lynj"},{"post_id":"cig3dovck0047lo6bmsqctfhn","tag_id":"cig3dovck0049lo6b0rq1q643","_id":"cig3dovcl004alo6b69vvxfms"},{"post_id":"cig3dovcm004clo6bqdw585rt","tag_id":"cig3dovcn004elo6byzw72ezl","_id":"cig3dovcn004flo6bjdpyhcie"},{"post_id":"cig3dovcp004hlo6bsbhggedq","tag_id":"cig3dova1000llo6bss47r9wd","_id":"cig3dovcq004jlo6big8th44p"},{"post_id":"cig3dovcs004klo6b6fsz863w","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovcw004plo6bzyfjxkdm"},{"post_id":"cig3dovcs004klo6b6fsz863w","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovcw004rlo6bwbm5ajjj"},{"post_id":"cig3dovd7004tlo6btks5twdv","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovd9004vlo6bhfdyumhg"},{"post_id":"cig3dovd7004tlo6btks5twdv","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovd9004xlo6b5gpdeg8u"},{"post_id":"cig3dovdc004ylo6b27l13kgi","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovde0050lo6beg89yoi2"},{"post_id":"cig3dovdc004ylo6b27l13kgi","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovde0052lo6bsb5kla0y"},{"post_id":"cig3dovdf0053lo6bqn23a9ln","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovdh0055lo6b8wh3fgmo"},{"post_id":"cig3dovdf0053lo6bqn23a9ln","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovdh0057lo6b1jk7ca6z"},{"post_id":"cig3dovdl0058lo6bih8jg83x","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovdm005alo6b5xfzlfjd"},{"post_id":"cig3dovdl0058lo6bih8jg83x","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovdm005clo6bei0j87cz"},{"post_id":"cig3dovdp005dlo6bch4ofjy9","tag_id":"cig3dovct004mlo6bs9wf3vlc","_id":"cig3dovdq005flo6bnb477dpm"},{"post_id":"cig3dovdp005dlo6bch4ofjy9","tag_id":"cig3dovcu004nlo6b5ogdieac","_id":"cig3dovdq005hlo6b649xpk35"},{"post_id":"cig3dove1005llo6b7mdamhug","tag_id":"cig3dov9z000glo6bgdjc4zis","_id":"cig3dove2005nlo6b5lgbkozt"},{"post_id":"cig3dove1005llo6b7mdamhug","tag_id":"cig3dovad0019lo6b0hbogpqp","_id":"cig3dove2005olo6bw8lcrvs2"},{"post_id":"cig3dove4005rlo6b6iydswzl","tag_id":"cig3dove5005tlo6bryycp6mo","_id":"cig3dove5005ulo6b6arzgurc"},{"post_id":"cig3dsxgd0000qb6be67qt79n","tag_id":"cig3dovam001slo6bixr8bn92","_id":"cig3dsxgj0002qb6bqbn7abwx"}],"Tag":[{"name":"杂谈","_id":"cig3dov9b0005lo6bjlnuiya9"},{"name":"Java","_id":"cig3dov9z000glo6bgdjc4zis"},{"name":"linux shell","_id":"cig3dova1000llo6bss47r9wd"},{"name":"日志处理","_id":"cig3dova3000qlo6bvdmycx4s"},{"name":"数据库","_id":"cig3dova8000ylo6b1hh44959"},{"name":"git","_id":"cig3dovab0013lo6bcznqntj7"},{"name":"MarkDown","_id":"cig3dovad0018lo6bhumprphn"},{"name":"工具","_id":"cig3dovad0019lo6b0hbogpqp"},{"name":"Java锁学习","_id":"cig3dovag001hlo6bqpumjaml"},{"name":"Java并发包学习","_id":"cig3dovam001slo6bixr8bn92"},{"name":"JDK工具学习","_id":"cig3dovbk0036lo6bvzmoff9v"},{"name":"Docker","_id":"cig3dovc9003tlo6bb8dmg5kk"},{"name":"ZooKeeper","_id":"cig3dovci0044lo6bppc7qjww"},{"name":"编码","_id":"cig3dovck0049lo6b0rq1q643"},{"name":"thrift","_id":"cig3dovcn004elo6byzw72ezl"},{"name":"Redis","_id":"cig3dovct004mlo6bs9wf3vlc"},{"name":"NoSQL","_id":"cig3dovcu004nlo6b5ogdieac"},{"name":"域名解析","_id":"cig3dove5005tlo6bryycp6mo"}]}}